- en: Inside the V8 JavaScript Engine
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: V8 JavaScript å¼•æ“å†…éƒ¨
- en: åŸæ–‡ï¼š[https://www.thenodebook.com/node-arch/v8-engine-intro](https://www.thenodebook.com/node-arch/v8-engine-intro)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://www.thenodebook.com/node-arch/v8-engine-intro](https://www.thenodebook.com/node-arch/v8-engine-intro)
- en: â„¹ï¸Note
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: A quick word on this chapter. We're deliberately getting into some advanced
    territory here. I'll introduce some big ideas now that we'll explore in much more
    detail later in Volume 3 (Ch 21 onwards).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºæœ¬ç« çš„ç®€è¦è¯´æ˜ã€‚æˆ‘ä»¬æ•…æ„è¿›å…¥äº†ä¸€äº›é«˜çº§é¢†åŸŸã€‚ç°åœ¨æˆ‘ä¼šä»‹ç»ä¸€äº›å¤§æ¦‚å¿µï¼Œæˆ‘ä»¬å°†åœ¨ç¬¬ä¸‰å·ï¼ˆç¬¬ 21 ç« å¼€å§‹ï¼‰ä¸­æ›´è¯¦ç»†åœ°æ¢è®¨ã€‚
- en: Think of this as a quick overview - we're moving fast and focusing only on the
    most important points. Why? Because getting a strong understanding of how the
    v8 engine and memory works first is absolutely essential. It's the foundation
    that will make all the next lessons just click.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¿™è§†ä¸ºä¸€ä¸ªå¿«é€Ÿæ¦‚è¿°â€”â€”æˆ‘ä»¬è¿›å±•è¿…é€Ÿï¼Œåªå…³æ³¨æœ€é‡è¦çš„ç‚¹ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºé¦–å…ˆå¯¹ v8 å¼•æ“å’Œå†…å­˜çš„å·¥ä½œåŸç†æœ‰ä¸€ä¸ªæ·±å…¥çš„ç†è§£æ˜¯ç»å¯¹å¿…è¦çš„ã€‚è¿™æ˜¯æ‰€æœ‰åç»­è¯¾ç¨‹çš„åŸºç¡€ï¼Œå°†ä½¿æ‰€æœ‰è¯¾ç¨‹éƒ½å˜å¾—å®¹æ˜“ç†è§£ã€‚
- en: TL;DR
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TL;DR
- en: 'Let''s get one thing straight: **V8 is both an interpreter and a multi-tier
    JIT compiler**. When your Node.js application runs, your JavaScript is first interpreted
    by **Ignition**, which compiles it into bytecode and executes it directly. As
    your code warms up, it progresses through a sophisticated 4-tier compilation pipeline:
    **Sparkplug** (fast baseline compiler) â†’ **Maglev** (mid-tier optimizing compiler)
    â†’ **TurboFan** (advanced optimizing compiler). Each tier offers progressively
    better performance at the cost of compilation time. For code that matters (your
    "hot paths"), it''s ultimately compiled by TurboFan into highly optimized, speculative
    machine code that runs nearly as fast as C++. This sophisticated multi-tier pipeline
    balances fast startup with exceptional peak performance.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ˜ç¡®ä¸€ç‚¹ï¼š**V8 æ—¢æ˜¯è§£é‡Šå™¨åˆæ˜¯å¤šçº§ JIT ç¼–è¯‘å™¨**ã€‚å½“ä½ çš„ Node.js åº”ç”¨ç¨‹åºè¿è¡Œæ—¶ï¼Œä½ çš„ JavaScript é¦–å…ˆç”± **Ignition**
    è§£é‡Šï¼Œå°†å…¶ç¼–è¯‘æˆå­—èŠ‚ç å¹¶ç›´æ¥æ‰§è¡Œã€‚éšç€ä½ çš„ä»£ç é€æ¸çƒ­èº«ï¼Œå®ƒå°†é€šè¿‡ä¸€ä¸ªå¤æ‚çš„ 4 çº§ç¼–è¯‘æµç¨‹ï¼š**Sparkplug**ï¼ˆå¿«é€ŸåŸºçº¿ç¼–è¯‘å™¨ï¼‰â†’ **Maglev**ï¼ˆä¸­çº§ä¼˜åŒ–ç¼–è¯‘å™¨ï¼‰â†’
    **TurboFan**ï¼ˆé«˜çº§ä¼˜åŒ–ç¼–è¯‘å™¨ï¼‰ã€‚æ¯ä¸€çº§éƒ½æä¾›äº†è¶Šæ¥è¶Šå¥½çš„æ€§èƒ½ï¼Œä½†ä»£ä»·æ˜¯ç¼–è¯‘æ—¶é—´ã€‚å¯¹äºé‡è¦çš„ä»£ç ï¼ˆä½ çš„â€œçƒ­ç‚¹è·¯å¾„â€ï¼‰ï¼Œæœ€ç»ˆç”± TurboFan ç¼–è¯‘æˆé«˜åº¦ä¼˜åŒ–çš„ã€æ¨æµ‹æ€§çš„æœºå™¨ä»£ç ï¼Œå…¶è¿è¡Œé€Ÿåº¦å‡ ä¹ä¸
    C++ ç›¸å½“ã€‚è¿™ä¸ªå¤æ‚çš„å¤šçº§æµç¨‹åœ¨å¿«é€Ÿå¯åŠ¨å’Œå“è¶Šçš„å³°å€¼æ€§èƒ½ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚
- en: â„¹ï¸Note
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: V8 is both an interpreter and a multi-tier JIT compiler. Understanding this
    sophisticated compilation pipeline is crucial for performance optimization.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: V8 æ—¢æ˜¯è§£é‡Šå™¨åˆæ˜¯å¤šçº§ JIT ç¼–è¯‘å™¨ã€‚ç†è§£è¿™ä¸ªå¤æ‚çš„ç¼–è¯‘æµç¨‹å¯¹äºæ€§èƒ½ä¼˜åŒ–è‡³å…³é‡è¦ã€‚
- en: 'The entire performance model of V8 hinges on a critical assumption: that your
    code is predictable. V8 makes bets on the *shapes* of your objects and the *types*
    of your variables. It achieves this using an internal mechanism called **Hidden
    Classes** (or Shapes). Every time you create an object, V8 assigns it a hidden
    class. When you add a property, it transitions to a new hidden class. V8''s compilers,
    especially Maglev and TurboFan, generate machine code that is specialized for
    these hidden classes. This is incredibly fast - as long as the assumptions hold.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: V8 æ•´ä¸ªæ€§èƒ½æ¨¡å‹ä¾èµ–äºä¸€ä¸ªå…³é”®å‡è®¾ï¼šä½ çš„ä»£ç æ˜¯å¯é¢„æµ‹çš„ã€‚V8 é€šè¿‡å†…éƒ¨æœºåˆ¶ **Hidden Classes**ï¼ˆæˆ–ç§°ä¸ºå½¢çŠ¶ï¼‰å¯¹ä½ çš„å¯¹è±¡å½¢çŠ¶å’Œå˜é‡ç±»å‹è¿›è¡Œä¸‹æ³¨ã€‚å®ƒé€šè¿‡è¿™ç§æœºåˆ¶ä¸ºè¿™äº›éšè—ç±»ç”Ÿæˆä¸“é—¨çš„æœºå™¨ä»£ç ã€‚è¿™éå¸¸å¿«â€”â€”åªè¦å‡è®¾æˆç«‹ã€‚
- en: When your code breaks these assumptions - by creating objects with different
    property orders, mixing types in arrays, or using dynamic patterns - you trigger
    a performance cliff. V8 is forced to throw away the optimized machine code in
    a process called **deoptimization** and fall back to the bytecode interpreter
    or a lower compilation tier. Deoptimizations typically cause slowdowns ranging
    from 2x to 20x, depending on the context. In tight loops or extremely hot paths,
    the penalty can be more severe (potentially 100x or more), but 100x slowdowns
    are rare edge cases. Understanding this concept - that V8 rewards predictable,
    stable object shapes and punishes dynamic, unpredictable ones - is the key to
    unlocking consistent, high-performance Node.js applications. Focus on writing
    "boring," monomorphic JavaScript that keeps the optimizing compilers happy.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ çš„ä»£ç æ‰“ç ´äº†è¿™äº›å‡è®¾â€”â€”é€šè¿‡åˆ›å»ºå…·æœ‰ä¸åŒå±æ€§é¡ºåºçš„å¯¹è±¡ã€åœ¨æ•°ç»„ä¸­æ··åˆç±»å‹æˆ–ä½¿ç”¨åŠ¨æ€æ¨¡å¼â€”â€”ä½ ä¼šè§¦å‘æ€§èƒ½æ‚¬å´–ã€‚V8è¢«è¿«åœ¨ç§°ä¸º**å»ä¼˜åŒ–**çš„è¿‡ç¨‹ä¸­ä¸¢å¼ƒä¼˜åŒ–çš„æœºå™¨ä»£ç ï¼Œå¹¶å›é€€åˆ°å­—èŠ‚ç è§£é‡Šå™¨æˆ–æ›´ä½çš„ç¼–è¯‘å±‚çº§ã€‚å»ä¼˜åŒ–é€šå¸¸ä¼šå¯¼è‡´ä»2å€åˆ°20å€çš„æ€§èƒ½ä¸‹é™ï¼Œå…·ä½“å–å†³äºä¸Šä¸‹æ–‡ã€‚åœ¨ç´§å¯†å¾ªç¯æˆ–æç«¯çƒ­ç‚¹è·¯å¾„ä¸­ï¼Œæƒ©ç½šå¯èƒ½ä¼šæ›´ä¸¥é‡ï¼ˆå¯èƒ½æ˜¯100å€æˆ–æ›´å¤šï¼‰ï¼Œä½†100å€çš„å‡é€Ÿæ˜¯ç½•è§çš„è¾¹ç¼˜æƒ…å†µã€‚ç†è§£è¿™ä¸ªæ¦‚å¿µâ€”â€”V8å¥–åŠ±å¯é¢„æµ‹ã€ç¨³å®šçš„å¯¹è±¡å½¢çŠ¶ï¼Œå¹¶æƒ©ç½šåŠ¨æ€ã€ä¸å¯é¢„æµ‹çš„å½¢çŠ¶â€”â€”æ˜¯è§£é”ä¸€è‡´ã€é«˜æ€§èƒ½Node.jsåº”ç”¨ç¨‹åºçš„å…³é”®ã€‚ä¸“æ³¨äºç¼–å†™â€œæ— èŠâ€çš„å•æ€JavaScriptï¼Œè®©ä¼˜åŒ–ç¼–è¯‘å™¨ä¿æŒé«˜å…´ã€‚
- en: The 100x Slowdown Mystery
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 100å€å‡é€Ÿä¹‹è°œ
- en: It started, as it always does, with a perfectly reasonable piece of code. We
    had an API endpoint responsible for processing configuration objects. It would
    take a base config, layer on some user-specific overrides, and then maybe some
    request-specific settings. Simple stuff. For months, it ran flawlessly, humming
    along at about 2-5ms per request.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå°±åƒå¾€å¸¸ä¸€æ ·ï¼Œä»ä¸€ä¸ªå®Œå…¨åˆç†çš„ä»£ç ç‰‡æ®µå¼€å§‹ã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªAPIç«¯ç‚¹ï¼Œè´Ÿè´£å¤„ç†é…ç½®å¯¹è±¡ã€‚å®ƒä¼šå–ä¸€ä¸ªåŸºæœ¬é…ç½®ï¼Œæ·»åŠ ä¸€äº›ç”¨æˆ·ç‰¹å®šçš„è¦†ç›–ï¼Œç„¶åå¯èƒ½æ˜¯ä¸€äº›è¯·æ±‚ç‰¹å®šçš„è®¾ç½®ã€‚å¾ˆç®€å•çš„äº‹æƒ…ã€‚æ•°æœˆæ¥ï¼Œå®ƒä¸€ç›´è¿è¡Œå¾—æ¯«æ— æ•…éšœï¼Œæ¯ä¸ªè¯·æ±‚å¤§çº¦2-5æ¯«ç§’ã€‚
- en: Then the latency alerts started screaming. P99 latency had shot up to over 200ms.
    Not 20ms. *Two hundred milliseconds*. A 100x slowdown. We thought it was a network
    issue, a database bottleneck, anything but the application code. The code was
    simple, clean, and correct. What could possibly be wrong?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå»¶è¿Ÿè­¦æŠ¥å¼€å§‹å°–å«ã€‚P99å»¶è¿Ÿé£™å‡è‡³200æ¯«ç§’ä»¥ä¸Šã€‚ä¸æ˜¯20æ¯«ç§’ã€‚*ä¸¤ç™¾æ¯«ç§’*ã€‚100å€çš„å‡é€Ÿã€‚æˆ‘ä»¬ä»¥ä¸ºè¿™æ˜¯ç½‘ç»œé—®é¢˜ï¼Œæ•°æ®åº“ç“¶é¢ˆï¼Œä»»ä½•ä¸æ˜¯åº”ç”¨ç¨‹åºä»£ç çš„é—®é¢˜ã€‚ä»£ç ç®€å•ã€å¹²å‡€ã€æ­£ç¡®ã€‚å¯èƒ½å‡ºä»€ä¹ˆé—®é¢˜äº†ï¼Ÿ
- en: We deployed a hotfix to add more logging. Nothing. We dove into the CPU profiler,
    and the flame graphs were a mess. They didn't point to a single culprit function;
    instead, the entire request handler was just... slow. It was as if the CPU had
    decided to run at 1/100th of its normal speed, but only for this specific endpoint.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éƒ¨ç½²äº†ä¸€ä¸ªçƒ­ä¿®å¤æ¥æ·»åŠ æ›´å¤šçš„æ—¥å¿—ã€‚æ²¡æœ‰æ•ˆæœã€‚æˆ‘ä»¬æ·±å…¥CPUåˆ†æå™¨ï¼Œç«ç„°å›¾ä¸€ç‰‡æ··ä¹±ã€‚å®ƒä»¬å¹¶æ²¡æœ‰æŒ‡å‘ä¸€ä¸ªå•ä¸€çš„ç½ªé­ç¥¸é¦–å‡½æ•°ï¼›ç›¸åï¼Œæ•´ä¸ªè¯·æ±‚å¤„ç†å™¨åªæ˜¯â€¦â€¦å¾ˆæ…¢ã€‚å°±å¥½åƒCPUå†³å®šåªä»¥æ­£å¸¸é€Ÿåº¦çš„1/100æ¥è¿è¡Œï¼Œä½†åªé’ˆå¯¹è¿™ä¸ªç‰¹å®šçš„ç«¯ç‚¹ã€‚
- en: The change that caused it was innocuous. A new feature required us to add a
    dynamic, optional property to the config object. A single `if (condition) { config.optionalFeature
    = true; }`. That was it. One line of code. One property addition.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼è‡´è¿™ç§æƒ…å†µçš„å˜åŒ–æ˜¯æ— å®³çš„ã€‚ä¸€ä¸ªæ–°åŠŸèƒ½è¦æ±‚æˆ‘ä»¬å‘é…ç½®å¯¹è±¡æ·»åŠ ä¸€ä¸ªåŠ¨æ€çš„ã€å¯é€‰çš„å±æ€§ã€‚ä¸€è¡Œä»£ç ï¼š`if (condition) { config.optionalFeature
    = true; }`ã€‚å°±æ˜¯è¿™æ ·ã€‚ä¸€è¡Œä»£ç ã€‚ä¸€ä¸ªå±æ€§çš„å¢åŠ ã€‚
- en: We were staring at a ghost. The code was logically identical in its "hot path,"
    yet it was orders of magnitude slower. This was my first real lesson in JavaScript
    performance. It's the moment you realize that the code you write is not the code
    that runs. You're not writing instructions for a simple interpreter; you're writing
    suggestions for a hyper-aggressive optimizing compiler. And we had, completely
    by accident, offended that compiler in the worst way possible.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¢å¯¹çš„æ˜¯ä¸€ä¸ªå¹½çµã€‚ä»£ç åœ¨â€œçƒ­ç‚¹è·¯å¾„â€ä¸Šé€»è¾‘ä¸Šå®Œå…¨ç›¸åŒï¼Œä½†é€Ÿåº¦æ…¢äº†å‡ ä¸ªæ•°é‡çº§ã€‚è¿™æ˜¯æˆ‘å…³äºJavaScriptæ€§èƒ½çš„ç¬¬ä¸€ä¸ªçœŸæ­£æ•™è®­ã€‚è¿™æ˜¯ä½ æ„è¯†åˆ°ä½ å†™çš„ä»£ç å¹¶ä¸æ˜¯è¿è¡Œçš„ä»£ç çš„æ—¶åˆ»ã€‚ä½ å¹¶ä¸æ˜¯åœ¨ä¸ºç®€å•çš„è§£é‡Šå™¨ç¼–å†™æŒ‡ä»¤ï¼›ä½ æ˜¯åœ¨ä¸ºè¶…çº§ç§¯æçš„ä¼˜åŒ–ç¼–è¯‘å™¨æä¾›å»ºè®®ã€‚è€Œæˆ‘ä»¬ï¼Œå®Œå…¨æ„å¤–åœ°ï¼Œä»¥æœ€ç³Ÿç³•çš„æ–¹å¼å†’çŠ¯äº†é‚£ä¸ªç¼–è¯‘å™¨ã€‚
- en: 'We were treating our JavaScript objects like convenient hash maps, adding properties
    whenever we felt like it. We assumed, like most developers, that "JavaScript is
    JavaScript, right?" It''s a dynamic language, and this is how you use it. But
    underneath our code, the V8 engine had made a series of bets about the structure
    of our `config` object. It had generated highly specialized machine code based
    on that structure. And our one innocent property addition invalidated every single
    one of those bets, forcing V8 to throw away all its hard work and fall back to
    a dramatically slower execution path. The function that went from 2ms to 200ms
    taught us a lesson no textbook could: you don''t just write JavaScript for other
    developers. You write it for V8.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»¥å‰æŠŠ JavaScript å¯¹è±¡å½“ä½œæ–¹ä¾¿çš„å“ˆå¸Œè¡¨æ¥å¤„ç†ï¼Œéšæ—¶æ·»åŠ å±æ€§ã€‚æˆ‘ä»¬åƒå¤§å¤šæ•°å¼€å‘è€…ä¸€æ ·å‡è®¾ï¼Œâ€œJavaScript å°±æ˜¯ JavaScriptï¼Œå¯¹å§ï¼Ÿâ€å®ƒæ˜¯ä¸€ç§åŠ¨æ€è¯­è¨€ï¼Œè¿™å°±æ˜¯ä½ ä½¿ç”¨å®ƒçš„æ–¹å¼ã€‚ä½†åœ¨æˆ‘ä»¬çš„ä»£ç ä¸‹é¢ï¼ŒV8
    å¼•æ“å·²ç»å°±æˆ‘ä»¬çš„ `config` å¯¹è±¡çš„ç»“æ„åšå‡ºäº†ä¸€ç³»åˆ—å‡è®¾ã€‚å®ƒåŸºäºè¿™ä¸ªç»“æ„ç”Ÿæˆäº†é«˜åº¦ä¸“ä¸šåŒ–çš„æœºå™¨ä»£ç ã€‚è€Œæˆ‘ä»¬æ·»åŠ çš„ä¸€ä¸ªæ— è¾œçš„å±æ€§å°±ä½¿æ‰€æœ‰è¿™äº›å‡è®¾å¤±æ•ˆï¼Œè¿«ä½¿
    V8 æ‰”æ‰æ‰€æœ‰è¾›å‹¤çš„å·¥ä½œï¼Œå¹¶å›é€€åˆ°ä¸€ä¸ªæ˜¾è‘—æ›´æ…¢çš„æ‰§è¡Œè·¯å¾„ã€‚é‚£ä¸ªä» 2ms æå‡åˆ° 200ms çš„å‡½æ•°æ•™ä¼šäº†æˆ‘ä»¬ä¸€ä¸ªä»»ä½•æ•™ç§‘ä¹¦éƒ½æ— æ³•ä¼ æˆçš„æ•™è®­ï¼šä½ ä¸ä»…ä»…æ˜¯ä¸ºå…¶ä»–å¼€å‘è€…ç¼–å†™
    JavaScriptã€‚ä½ æ˜¯ä¸º V8 ç¼–å†™å®ƒã€‚
- en: '* * *'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: How V8 Actually Executes JavaScript
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V8 å®é™…ä¸Šæ˜¯æ€æ ·æ‰§è¡Œ JavaScript çš„
- en: 'Most of us start with a simple mental model: JavaScript is an interpreted language.
    You write code, an engine reads it line by line, and does what it says. This model
    is not just wrong; it''s dangerously wrong if you care about performance. V8 doesn''t
    interpret your code in the traditional sense. It compiles it through a sophisticated
    multi-tier pipeline.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¤§å¤šæ•°äººéƒ½æœ‰ä¸€ä¸ªç®€å•çš„å¿ƒç†æ¨¡å‹ï¼šJavaScript æ˜¯ä¸€ç§è§£é‡Šå‹è¯­è¨€ã€‚ä½ ç¼–å†™ä»£ç ï¼Œå¼•æ“é€è¡Œè¯»å–å®ƒï¼Œå¹¶æ‰§è¡Œå…¶æŒ‡ç¤ºã€‚è¿™ç§æ¨¡å‹ä¸ä»…é”™è¯¯ï¼Œå¦‚æœä½ å…³å¿ƒæ€§èƒ½ï¼Œå®ƒç”šè‡³æ˜¯éå¸¸å±é™©çš„ã€‚V8
    å¹¶ä¸æ˜¯ä»¥ä¼ ç»Ÿæ–¹å¼è§£é‡Šä½ çš„ä»£ç ã€‚å®ƒé€šè¿‡ä¸€ä¸ªå¤æ‚çš„åˆ†å±‚ç®¡é“ç¼–è¯‘ä½ çš„ä»£ç ã€‚
- en: 'The journey from your `.js` file to executed machine code is a multi-stage
    pipeline designed for one thing: speed. Specifically, it''s designed for a fast
    startup (don''t spend too long compiling upfront) and incredible peak performance
    for code that runs frequently. This is the core idea of a **Just-In-Time (JIT)**
    compiler.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä½ çš„ `.js` æ–‡ä»¶åˆ°æ‰§è¡Œæœºå™¨ä»£ç çš„è¿‡ç¨‹æ˜¯ä¸€ä¸ªå¤šé˜¶æ®µç®¡é“ï¼Œè®¾è®¡ç›®çš„æ˜¯ä¸ºäº†é€Ÿåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒè®¾è®¡ç”¨äºå¿«é€Ÿå¯åŠ¨ï¼ˆä¸è¦èŠ±è´¹å¤ªå¤šæ—¶é—´ç¼–è¯‘ï¼‰ä»¥åŠé¢‘ç¹è¿è¡Œä»£ç çš„æƒŠäººå³°å€¼æ€§èƒ½ã€‚è¿™æ˜¯å³æ—¶ç¼–è¯‘å™¨ï¼ˆ**Just-In-Time
    (JIT)**ï¼‰çš„æ ¸å¿ƒæ€æƒ³ã€‚
- en: 'Here''s the high-level flow:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯é«˜çº§æµç¨‹ï¼š
- en: 'The first thing V8 does is parse your raw JavaScript source code. It doesn''t
    execute anything yet. The goal is to turn your string of characters into a structured
    representation the machine can understand. This process involves two key components:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: V8 é¦–å…ˆè¦åšçš„æ˜¯è§£æä½ çš„åŸå§‹ JavaScript æºä»£ç ã€‚å®ƒè¿˜æ²¡æœ‰å¼€å§‹æ‰§è¡Œä»»ä½•æ“ä½œã€‚ç›®æ ‡æ˜¯æŠŠå­—ç¬¦åºåˆ—è½¬æ¢æˆæœºå™¨å¯ä»¥ç†è§£çš„æœ‰åºè¡¨ç¤ºã€‚è¿™ä¸ªè¿‡ç¨‹æ¶‰åŠä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼š
- en: '**Scanner:** Tokenizes the code, breaking it down into atomic pieces like `const`,
    `myVar`, `=`, `10`, `;`.'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ‰«æå™¨**ï¼šå°†ä»£ç æ ‡è®°åŒ–ï¼Œå°†å…¶åˆ†è§£æˆåŸå­ç‰‡æ®µï¼Œå¦‚ `const`ã€`myVar`ã€`=`ã€`10`ã€`;`ã€‚'
- en: '**Parser:** Takes the stream of tokens and builds an **Abstract Syntax Tree
    (AST)**. The AST is a tree-like data structure that represents the grammatical
    structure of your code. An expression like `const a = 10;` becomes a tree with
    a `VariableDeclaration` node, which has a child for the identifier (`a`) and another
    for the value (`10`).'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è§£æå™¨**ï¼šæ¥æ”¶æ ‡è®°æµå¹¶æ„å»ºä¸€ä¸ª **æŠ½è±¡è¯­æ³•æ ‘ (AST)**ã€‚AST æ˜¯ä¸€ç§æ ‘å½¢æ•°æ®ç»“æ„ï¼Œå®ƒè¡¨ç¤ºäº†ä½ çš„ä»£ç çš„è¯­æ³•ç»“æ„ã€‚ä¸€ä¸ªåƒ `const a
    = 10;` çš„è¡¨è¾¾å¼ä¼šå˜æˆä¸€ä¸ªå…·æœ‰ `VariableDeclaration` èŠ‚ç‚¹çš„æ ‘ï¼Œè¯¥èŠ‚ç‚¹æœ‰ä¸€ä¸ªæ ‡è¯†ç¬¦ï¼ˆ`a`ï¼‰å­èŠ‚ç‚¹å’Œä¸€ä¸ªå€¼ï¼ˆ`10`ï¼‰å­èŠ‚ç‚¹ã€‚'
- en: Once the AST is built, V8's interpreter, named **Ignition**, gets to work. Ignition
    walks the AST and generates **bytecode**. Bytecode is a low-level, platform-independent
    set of instructions. It's not machine code yet, but it's much closer to the metal
    than raw JavaScript. For example, an addition operation `a + b` might become bytecode
    instructions like `Ldar a` (load accumulator with value of `a`), `Add b` (add
    value of `b` to accumulator). Ignition can then execute this bytecode directly.
    For code that only runs once, this is often the beginning and end of the story.
    It's faster than a naive interpreter because it doesn't have to re-parse the source
    code every time.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ„å»ºäº†æŠ½è±¡è¯­æ³•æ ‘ï¼ˆASTï¼‰ï¼ŒV8 çš„è§£é‡Šå™¨ï¼Œåä¸º **Ignition**ï¼Œå°±å¼€å§‹å·¥ä½œã€‚Ignition éå† AST å¹¶ç”Ÿæˆ **å­—èŠ‚ç **ã€‚å­—èŠ‚ç æ˜¯ä¸€ç»„ä½çº§ã€å¹³å°æ— å…³çš„æŒ‡ä»¤ã€‚å®ƒè¿˜ä¸æ˜¯æœºå™¨ä»£ç ï¼Œä½†å®ƒæ¯”åŸå§‹
    JavaScript æ›´æ¥è¿‘åº•å±‚ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªåŠ æ³•æ“ä½œ `a + b` å¯èƒ½ä¼šå˜æˆç±»ä¼¼ `Ldar a`ï¼ˆä½¿ç”¨ `a` çš„å€¼åŠ è½½ç´¯åŠ å™¨ï¼‰ï¼Œ`Add b`ï¼ˆå°†
    `b` çš„å€¼åŠ åˆ°ç´¯åŠ å™¨ï¼‰çš„å­—èŠ‚ç æŒ‡ä»¤ã€‚Ignition ç„¶åå¯ä»¥ç›´æ¥æ‰§è¡Œè¿™äº›å­—èŠ‚ç ã€‚å¯¹äºåªè¿è¡Œä¸€æ¬¡çš„ä»£ç ï¼Œè¿™é€šå¸¸æ˜¯æ•…äº‹çš„å¼€å§‹å’Œç»“æŸã€‚å®ƒæ¯”ç®€å•çš„è§£é‡Šå™¨æ›´å¿«ï¼Œå› ä¸ºå®ƒä¸å¿…æ¯æ¬¡éƒ½é‡æ–°è§£ææºä»£ç ã€‚
- en: While Ignition is executing bytecode, it's also collecting profiling data. It's
    watching your code run. How many times is this function called? What types of
    values are being passed to it? What object shapes are being used? This feedback
    is crucial for the next steps. It's like a scout reporting back from the front
    lines, telling the generals where to focus their efforts.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å½“Ignitionæ­£åœ¨æ‰§è¡Œå­—èŠ‚ç æ—¶ï¼Œå®ƒä¹Ÿåœ¨æ”¶é›†å‰–ææ•°æ®ã€‚å®ƒåœ¨è§‚å¯Ÿä½ çš„ä»£ç è¿è¡Œã€‚è¿™ä¸ªå‡½æ•°è¢«è°ƒç”¨äº†å¤šå°‘æ¬¡ï¼Ÿä¼ é€’ç»™å®ƒçš„å€¼ç±»å‹æ˜¯ä»€ä¹ˆï¼Ÿä½¿ç”¨äº†å“ªäº›å¯¹è±¡å½¢çŠ¶ï¼Ÿè¿™ç§åé¦ˆå¯¹äºä¸‹ä¸€æ­¥è‡³å…³é‡è¦ã€‚å®ƒå°±åƒå‰çº¿ä¾¦å¯Ÿå…µå‘å°†å†›æ±‡æŠ¥ï¼Œå‘Šè¯‰ä»–ä»¬åº”è¯¥åœ¨å“ªé‡Œé›†ä¸­ç²¾åŠ›ã€‚
- en: When Ignition's profiler identifies a piece of code as "warm" (i.e., it's being
    executed somewhat frequently), it gets handed off to **Sparkplug**, the baseline
    compiler. Sparkplug takes the bytecode from Ignition and compiles it directly
    to machine code without any optimizations. This is faster than interpreting bytecode
    but doesn't have the overhead of advanced analysis. Sparkplug smooths out the
    performance cliff between interpreted and optimized code. It was introduced in
    2021 to fill a crucial gap in the compilation pipeline.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å½“Ignitionçš„å‰–æå™¨è¯†åˆ«å‡ºä¸€æ®µä»£ç ä¸ºâ€œçƒ­â€ä»£ç ï¼ˆå³ï¼Œå®ƒè¢«æ‰§è¡Œå¾—ç›¸å¯¹é¢‘ç¹ï¼‰æ—¶ï¼Œå®ƒä¼šè¢«è½¬äº¤ç»™**Sparkplug**ï¼ŒåŸºçº¿ç¼–è¯‘å™¨ã€‚Sparkplugä»Ignitionæ¥æ”¶å­—èŠ‚ç ï¼Œå¹¶ç›´æ¥ç¼–è¯‘æˆæœºå™¨ä»£ç ï¼Œè€Œä¸è¿›è¡Œä»»ä½•ä¼˜åŒ–ã€‚è¿™æ¯”è§£é‡Šå­—èŠ‚ç æ›´å¿«ï¼Œä½†æ²¡æœ‰é«˜çº§åˆ†æçš„å¼€é”€ã€‚Sparkplugå¹³æ»‘äº†è§£é‡Šå’Œä¼˜åŒ–ä»£ç ä¹‹é—´çš„æ€§èƒ½æ‚¬å´–ã€‚å®ƒäº2021å¹´æ¨å‡ºï¼Œä»¥å¡«è¡¥ç¼–è¯‘ç®¡é“ä¸­çš„å…³é”®å·®è·ã€‚
- en: As functions continue to heat up and become "hot" (executed more frequently
    with consistent type feedback), they're promoted to **Maglev**, the mid-tier optimizing
    compiler introduced in Chrome M117 (December 2023). Maglev represents a sweet
    spot in the compilation pipeline. It takes the bytecode and type feedback from
    Ignition and generates optimized machine code using Static Single Assignment (SSA)
    form and a control flow graph. Maglev's philosophy is "good enough code, fast
    enough" - it compiles ~10x slower than Sparkplug but ~10x faster than TurboFan,
    producing code that's significantly better than baseline but without the full
    heavyweight optimization. Maglev performs speculative optimizations based on the
    type feedback but with less aggressive assumptions than TurboFan.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éšç€å‡½æ•°å˜å¾—è¶Šæ¥è¶Šçƒ­é—¨å¹¶æˆä¸ºâ€œçƒ­é—¨â€å‡½æ•°ï¼ˆæ‰§è¡Œé¢‘ç‡æ›´é«˜ï¼Œå¹¶ä¼´éšä¸€è‡´çš„ç±»å‹åé¦ˆï¼‰ï¼Œå®ƒä»¬è¢«æå‡åˆ°**ç£æ‚¬æµ®åˆ—è½¦**ï¼Œè¿™æ˜¯Chrome M117ï¼ˆ2023å¹´12æœˆï¼‰ä¸­å¼•å…¥çš„ä¸­ç«¯ä¼˜åŒ–ç¼–è¯‘å™¨ã€‚ç£æ‚¬æµ®åˆ—è½¦ä»£è¡¨äº†ç¼–è¯‘ç®¡é“ä¸­çš„æœ€ä½³å¹³è¡¡ç‚¹ã€‚å®ƒæ¥æ”¶æ¥è‡ªIgnitionçš„å­—èŠ‚ç å’Œç±»å‹åé¦ˆï¼Œå¹¶ä½¿ç”¨é™æ€å•èµ‹å€¼ï¼ˆSSAï¼‰å½¢å¼å’Œæ§åˆ¶æµå›¾ç”Ÿæˆä¼˜åŒ–çš„æœºå™¨ä»£ç ã€‚ç£æ‚¬æµ®çš„å“²å­¦æ˜¯â€œè¶³å¤Ÿå¥½çš„ä»£ç ï¼Œè¶³å¤Ÿå¿«â€â€”â€”å®ƒçš„ç¼–è¯‘é€Ÿåº¦æ¯”Sparkplugæ…¢çº¦10å€ï¼Œä½†æ¯”TurboFanå¿«çº¦10å€ï¼Œç”Ÿæˆçš„ä»£ç æ¯”åŸºçº¿ä»£ç æ˜¾è‘—æ›´å¥½ï¼Œä½†æ²¡æœ‰å…¨é¢çš„é‡å‹ä¼˜åŒ–ã€‚ç£æ‚¬æµ®åŸºäºç±»å‹åé¦ˆè¿›è¡Œæ¨æµ‹æ€§ä¼˜åŒ–ï¼Œä½†æ¯”TurboFançš„å‡è®¾æ›´ä¸ºä¿å®ˆã€‚
- en: Finally, for the absolute hottest code paths that have been executed thousands
    of times with very stable type feedback, V8 promotes functions to **TurboFan**,
    the advanced optimizing compiler. TurboFan takes the bytecode from Ignition and
    the rich profiling feedback and makes aggressive *speculative optimizations*.
    It says, "Okay, this function has been called 10,000 times, and every single time
    the argument `x` was a number. I'm going to bet it will *always* be a number."
    Based on this bet, it generates highly optimized, low-level machine code specific
    to that assumption. This machine code can bypass many of the checks and overhead
    of the interpreter, leading to massive speedups.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå¯¹äºæ‰§è¡Œäº†æ•°åƒæ¬¡ä¸”ç±»å‹åé¦ˆéå¸¸ç¨³å®šçš„ç»å¯¹çƒ­é—¨ä»£ç è·¯å¾„ï¼ŒV8å°†å‡½æ•°æå‡åˆ°**TurboFan**ï¼Œé«˜çº§ä¼˜åŒ–ç¼–è¯‘å™¨ã€‚TurboFanä»Ignitionæ¥æ”¶å­—èŠ‚ç å’Œä¸°å¯Œçš„å‰–æåé¦ˆï¼Œå¹¶è¿›è¡Œæ¿€è¿›çš„**æ¨æµ‹æ€§ä¼˜åŒ–**ã€‚å®ƒè¯´ï¼šâ€œå¥½å§ï¼Œè¿™ä¸ªå‡½æ•°å·²ç»è¢«è°ƒç”¨äº†10,000æ¬¡ï¼Œè€Œä¸”æ¯æ¬¡ä¼ é€’ç»™å‚æ•°`x`çš„å€¼éƒ½æ˜¯æ•°å­—ã€‚æˆ‘è¦èµŒå®ƒå°†**æ€»æ˜¯**æ˜¯æ•°å­—ã€‚â€åŸºäºè¿™ä¸ªèµŒæ³¨ï¼Œå®ƒç”Ÿæˆé’ˆå¯¹è¿™ä¸ªå‡è®¾çš„é«˜åº¦ä¼˜åŒ–ã€ä½çº§çš„æœºå™¨ä»£ç ã€‚è¿™ç§æœºå™¨ä»£ç å¯ä»¥ç»•è¿‡è§£é‡Šå™¨ä¸­çš„è®¸å¤šæ£€æŸ¥å’Œå¼€é”€ï¼Œä»è€Œå®ç°å·¨å¤§çš„é€Ÿåº¦æå‡ã€‚
- en: What happens if any of the optimizing compilers' bets were wrong? What if, on
    the 10,001st call, you pass a string to that function instead of a number? V8
    detects this assumption violation, immediately discards the optimized machine
    code, and seamlessly transitions execution back to a lower tier - either Maglev,
    Sparkplug, or all the way back to Ignition bytecode. This is called **deoptimization**.
    It ensures correctness, but it comes at a performance cost. If it happens repeatedly,
    your application will be stuck in a deadly loop of optimizing and deoptimizing,
    destroying your performance.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœä¼˜åŒ–ç¼–è¯‘å™¨çš„ä»»ä½•èµŒæ³¨éƒ½å¤±è´¥äº†æ€ä¹ˆåŠï¼Ÿå¦‚æœåœ¨ç¬¬10,001æ¬¡è°ƒç”¨æ—¶ï¼Œä½ ä¼ é€’äº†ä¸€ä¸ªå­—ç¬¦ä¸²è€Œä¸æ˜¯ä¸€ä¸ªæ•°å­—ç»™é‚£ä¸ªå‡½æ•°å‘¢ï¼ŸV8æ£€æµ‹åˆ°è¿™ä¸ªå‡è®¾è¿åï¼Œç«‹å³ä¸¢å¼ƒä¼˜åŒ–çš„æœºå™¨ä»£ç ï¼Œå¹¶æ— ç¼åœ°å°†æ‰§è¡Œåˆ‡æ¢å›è¾ƒä½å±‚çº§â€”â€”æ— è®ºæ˜¯ç£æ‚¬æµ®åˆ—è½¦ã€Sparkplugï¼Œè¿˜æ˜¯ç›´æ¥å›åˆ°Ignitionçš„å­—èŠ‚ç ã€‚è¿™è¢«ç§°ä¸º**å»ä¼˜åŒ–**ã€‚å®ƒç¡®ä¿äº†æ­£ç¡®æ€§ï¼Œä½†è¿™ä¹Ÿå¸¦æ¥äº†æ€§èƒ½æˆæœ¬ã€‚å¦‚æœè¿™ç§æƒ…å†µåå¤å‘ç”Ÿï¼Œä½ çš„åº”ç”¨ç¨‹åºå°†é™·å…¥ä¼˜åŒ–å’Œå»ä¼˜åŒ–çš„è‡´å‘½å¾ªç¯ï¼Œç ´åä½ çš„æ€§èƒ½ã€‚
- en: Let's clear a common myth right here.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åœ¨è¿™é‡Œæ¾„æ¸…ä¸€ä¸ªå¸¸è§çš„è¯¯è§£ã€‚
- en: 'Myth 1: "V8 is just an interpreter"'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¯¯è§£1ï¼šâ€œV8åªæ˜¯ä¸€ä¸ªè§£é‡Šå™¨â€
- en: This is fundamentally untrue. While it *has* an interpreter (Ignition), its
    main goal is to get to optimized machine code through its multi-tier compilation
    pipeline. The bytecode Ignition produces is an implementation detail, a stepping
    stone to the optimizing compilers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åœ¨æœ¬è´¨ä¸Šæ˜¯ä¸çœŸå®çš„ã€‚è™½ç„¶å®ƒç¡®å®æœ‰ä¸€ä¸ªè§£é‡Šå™¨ï¼ˆIgnitionï¼‰ï¼Œä½†å…¶ä¸»è¦ç›®æ ‡æ˜¯é€šè¿‡å¯¹å¤šå±‚çº§ç¼–è¯‘ç®¡é“çš„ä¼˜åŒ–ï¼Œå¾—åˆ°ä¼˜åŒ–çš„æœºå™¨ç ã€‚Ignitionäº§ç”Ÿçš„å­—èŠ‚ç æ˜¯ä¸€ä¸ªå®ç°ç»†èŠ‚ï¼Œæ˜¯é€šå¾€ä¼˜åŒ–ç¼–è¯‘å™¨çš„å«è„šçŸ³ã€‚
- en: 'Here''s a simple diagram of the modern 4-tier process:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯ç°ä»£4å±‚è¿‡ç¨‹çš„ç®€å•å›¾ç¤ºï¼š
- en: This pipeline is the heart of V8\. Your job as a performance-conscious engineer
    is to write code that flows smoothly up the tiers to TurboFan and *stays there*.
    Every time your code causes a deoptimization, you're forcing V8 to climb back
    down to a slower tier, and the performance penalty can be staggering.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç®¡é“æ˜¯V8çš„æ ¸å¿ƒã€‚ä½œä¸ºä¸€ä½æ³¨é‡æ€§èƒ½çš„å·¥ç¨‹å¸ˆï¼Œä½ çš„ä»»åŠ¡æ˜¯ç¼–å†™èƒ½å¤Ÿé¡ºç•…åœ°æµç»å±‚çº§åˆ°TurboFanå¹¶åœç•™åœ¨é‚£é‡Œçš„ä»£ç ã€‚æ¯æ¬¡ä½ çš„ä»£ç å¯¼è‡´å»ä¼˜åŒ–ï¼Œä½ éƒ½åœ¨è¿«ä½¿V8çˆ¬å›ä¸€ä¸ªè¾ƒæ…¢çš„å±‚çº§ï¼Œæ€§èƒ½æƒ©ç½šå¯èƒ½éå¸¸å·¨å¤§ã€‚
- en: '* * *'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The Compilation Pipeline: Ignition to TurboFan'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¼–è¯‘ç®¡é“ï¼šä»Ignitionåˆ°TurboFan
- en: Let's zoom in on that pipeline. Understanding the progression through each tier
    is critical because it's where all the performance magic - and all the performance
    cliffs - happen.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ”¾å¤§æŸ¥çœ‹è¿™ä¸ªç®¡é“ã€‚ç†è§£æ¯ä¸ªå±‚çº§ä¸­çš„è¿›å±•è‡³å…³é‡è¦ï¼Œå› ä¸ºæ‰€æœ‰æ€§èƒ½é­”æ³•â€”â€”ä»¥åŠæ‰€æœ‰æ€§èƒ½æ‚¬å´–â€”â€”éƒ½å‘ç”Ÿåœ¨è¿™é‡Œã€‚
- en: It all starts after parsing. The AST is now in memory.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è¿™ä¸€åˆ‡éƒ½å§‹äºè§£æä¹‹åã€‚ç°åœ¨ASTå·²ç»åœ¨å†…å­˜ä¸­ã€‚
- en: 'Ignition''s Role: Baseline Performance'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç‚¹ç«å™¨çš„ä½œç”¨ï¼šåŸºå‡†æ€§èƒ½
- en: Ignition's primary job is to get your code running *quickly*. Full-blown optimization
    is a heavy process; it consumes CPU and memory. For code that might only run once
    during application startup, it would be wasteful to spin up a massive compiler.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Ignitionçš„ä¸»è¦ä»»åŠ¡æ˜¯è®©ä½ çš„ä»£ç å¿«é€Ÿè¿è¡Œã€‚å®Œæ•´çš„ä¼˜åŒ–æ˜¯ä¸€ä¸ªé‡è¿‡ç¨‹ï¼›å®ƒæ¶ˆè€—CPUå’Œå†…å­˜ã€‚å¯¹äºå¯èƒ½åœ¨åº”ç”¨ç¨‹åºå¯åŠ¨æœŸé—´åªè¿è¡Œä¸€æ¬¡çš„ä»£ç ï¼Œå¯åŠ¨ä¸€ä¸ªåºå¤§çš„ç¼–è¯‘å™¨å°†æ˜¯æµªè´¹çš„ã€‚
- en: So, Ignition walks the AST and emits bytecode. This is a one-to-one process;
    there's no complex optimization happening here. The design of this bytecode is
    fascinating. It's a register-based machine rather than a stack-based one, which
    reduces the number of instructions needed and aligns better with the architecture
    of real CPUs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒIgnitionéå†ASTå¹¶ç”Ÿæˆå­—èŠ‚ç ã€‚è¿™æ˜¯ä¸€ä¸ªä¸€å¯¹ä¸€çš„è¿‡ç¨‹ï¼›è¿™é‡Œæ²¡æœ‰å¤æ‚çš„ä¼˜åŒ–å‘ç”Ÿã€‚è¿™ç§å­—èŠ‚ç çš„è®¾è®¡éå¸¸è¿·äººã€‚å®ƒæ˜¯ä¸€ä¸ªåŸºäºå¯„å­˜å™¨çš„æœºå™¨ï¼Œè€Œä¸æ˜¯åŸºäºå †æ ˆçš„ï¼Œè¿™å‡å°‘äº†æ‰€éœ€çš„æŒ‡ä»¤æ•°é‡ï¼Œå¹¶ä¸”æ›´å¥½åœ°ä¸çœŸå®CPUçš„æ¶æ„ç›¸åŒ¹é…ã€‚
- en: While executing this bytecode, Ignition gathers feedback. The main piece of
    data it collects is called **Type Feedback**. For every operation in your code
    (like property access `obj.x`, or an addition `a + b`), V8 creates a **Feedback
    Vector** slot. As the code runs, Ignition populates this vector with observed
    types.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰§è¡Œè¿™ä¸ªå­—èŠ‚ç çš„è¿‡ç¨‹ä¸­ï¼ŒIgnitionæ”¶é›†åé¦ˆã€‚å®ƒæ”¶é›†çš„ä¸»è¦æ•°æ®ç§°ä¸º**ç±»å‹åé¦ˆ**ã€‚å¯¹äºä½ ä»£ç ä¸­çš„æ¯ä¸ªæ“ä½œï¼ˆå¦‚å±æ€§è®¿é—®`obj.x`æˆ–åŠ æ³•`a +
    b`ï¼‰ï¼ŒV8éƒ½ä¼šåˆ›å»ºä¸€ä¸ª**åé¦ˆå‘é‡**æ§½ã€‚éšç€ä»£ç çš„è¿è¡Œï¼ŒIgnitionä¼šå¡«å……è¿™ä¸ªå‘é‡ä¸­çš„è§‚å¯Ÿåˆ°çš„ç±»å‹ã€‚
- en: 'For example, for the code `function add(a, b) { return a + b; }`:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå¯¹äºä»£ç `function add(a, b) { return a + b; }`ï¼š
- en: 'Ignition sees `add(1, 2)`. It records in the feedback vector: "Saw `a` as Small
    Integer, `b` as Small Integer, operation resulted in Small Integer."'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ignitionçœ‹åˆ°äº†`add(1, 2)`ã€‚å®ƒåœ¨åé¦ˆå‘é‡ä¸­è®°å½•ï¼šâ€œçœ‹åˆ°äº†`a`ä½œä¸ºå°æ•´æ•°ï¼Œ`b`ä½œä¸ºå°æ•´æ•°ï¼Œæ“ä½œç»“æœä¸ºå°æ•´æ•°ã€‚â€
- en: It sees `add(10, 20)`. The feedback is consistent.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒçœ‹åˆ°äº†`add(10, 20)`ã€‚åé¦ˆæ˜¯ä¸€è‡´çš„ã€‚
- en: The function is called 100 times with integers. The feedback vector is now very
    confident about the types involved.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡½æ•°è¢«ä»¥æ•´æ•°è°ƒç”¨100æ¬¡ã€‚ç°åœ¨åé¦ˆå‘é‡å¯¹æ¶‰åŠçš„ç±»å‹éå¸¸æœ‰ä¿¡å¿ƒã€‚
- en: This feedback is the fuel for all the optimizing compilers. Without it, they
    would be flying blind.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ¡åé¦ˆæ˜¯æ‰€æœ‰ä¼˜åŒ–ç¼–è¯‘å™¨çš„ç‡ƒæ–™ã€‚æ²¡æœ‰å®ƒï¼Œå®ƒä»¬å°±ä¼šç›²ç›®é£è¡Œã€‚
- en: 'Sparkplug: The Fast Baseline'
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Sparkplugï¼šå¿«é€ŸåŸºå‡†
- en: '**Sparkplug** is a baseline compiler introduced in 2021 that serves as the
    first optimization tier. It takes Ignition''s bytecode and compiles it directly
    to machine code without any optimizations or type specialization. This is faster
    than interpreting bytecode but doesn''t have the overhead of advanced analysis.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sparkplug**æ˜¯2021å¹´å¼•å…¥çš„åŸºå‡†ç¼–è¯‘å™¨ï¼Œä½œä¸ºç¬¬ä¸€ä¸ªä¼˜åŒ–å±‚çº§ã€‚å®ƒå°†Ignitionçš„å­—èŠ‚ç ç›´æ¥ç¼–è¯‘æˆæœºå™¨ç ï¼Œæ²¡æœ‰ä»»ä½•ä¼˜åŒ–æˆ–ç±»å‹ä¸“é—¨åŒ–ã€‚è¿™æ¯”è§£é‡Šå­—èŠ‚ç å¿«ï¼Œä½†æ²¡æœ‰é«˜çº§åˆ†æçš„å¼€é”€ã€‚'
- en: The key insight behind Sparkplug is that even unoptimized machine code is often
    better than interpreted bytecode. It provides a smooth transition from Ignition
    to the more aggressive optimizing compilers, reducing the performance cliff that
    used to exist.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: SparkplugèƒŒåçš„å…³é”®æ´å¯Ÿæ˜¯ï¼Œå³ä½¿æ˜¯æœªä¼˜åŒ–çš„æœºå™¨ç é€šå¸¸ä¹Ÿæ¯”è§£é‡Šçš„å­—èŠ‚ç è¦å¥½ã€‚å®ƒæä¾›äº†ä»Ignitionåˆ°æ›´æ¿€è¿›çš„ä¼˜åŒ–ç¼–è¯‘å™¨çš„å¹³æ»‘è¿‡æ¸¡ï¼Œå‡å°‘äº†æ›¾ç»å­˜åœ¨çš„æ€§èƒ½æ‚¬å´–ã€‚
- en: 'Maglev: The Mid-Tier Optimizer'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Maglevï¼šä¸­å±‚çš„ä¼˜åŒ–å™¨
- en: '**Maglev** is V8''s newest addition to the compilation pipeline, introduced
    in Chrome M117 (December 2023). It fills a crucial gap between Sparkplug''s fast-but-unoptimized
    code and TurboFan''s slow-to-compile-but-highly-optimized code.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**Maglev**æ˜¯V8ç¼–è¯‘ç®¡é“ä¸­çš„æœ€æ–°æˆå‘˜ï¼ŒäºChrome M117ï¼ˆ2023å¹´12æœˆï¼‰å¼•å…¥ã€‚å®ƒå¡«è¡¥äº†Sparkplugçš„å¿«é€Ÿä½†æœªä¼˜åŒ–çš„ä»£ç å’ŒTurboFançš„æ…¢é€Ÿç¼–è¯‘ä½†é«˜åº¦ä¼˜åŒ–çš„ä»£ç ä¹‹é—´çš„å…³é”®å·®è·ã€‚'
- en: Maglev's design philosophy is "good enough code, fast enough." Here's what makes
    it special -
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Maglevçš„è®¾è®¡ç†å¿µæ˜¯â€œè¶³å¤Ÿå¥½çš„ä»£ç ï¼Œè¶³å¤Ÿå¿«â€ã€‚ä»¥ä¸‹æ˜¯å®ƒç‰¹æ®Šä¹‹å¤„ -
- en: Unlike Sparkplug's direct bytecode-to-machine-code translation, Maglev builds
    a proper Static Single Assignment (SSA) form representation with a control flow
    graph. This allows it to perform meaningful optimizations while keeping compilation
    time reasonable.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸Sparkplugç›´æ¥å°†å­—èŠ‚ç è½¬æ¢ä¸ºæœºå™¨ç çš„ç¿»è¯‘ä¸åŒï¼ŒMaglevé€šè¿‡æ§åˆ¶æµå›¾æ„å»ºäº†é€‚å½“çš„é™æ€å•èµ‹å€¼ï¼ˆSSAï¼‰å½¢å¼è¡¨ç¤ºã€‚è¿™ä½¿å¾—å®ƒèƒ½å¤Ÿåœ¨ä¿æŒç¼–è¯‘æ—¶é—´åˆç†çš„åŒæ—¶æ‰§è¡Œæœ‰æ„ä¹‰çš„ä¼˜åŒ–ã€‚
- en: It uses the type feedback from Ignition to generate specialized code. If a function
    always receives integers, Maglev will generate integer-specific machine code.
    But it's less aggressive than TurboFan - it makes safer bets that are less likely
    to require deoptimization.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ƒä½¿ç”¨Ignitionçš„ç±»å‹åé¦ˆæ¥ç”Ÿæˆä¸“ç”¨ä»£ç ã€‚å¦‚æœä¸€ä¸ªå‡½æ•°æ€»æ˜¯æ¥æ”¶æ•´æ•°ï¼ŒMaglevå°†ç”Ÿæˆç‰¹å®šäºæ•´æ•°çš„æœºå™¨ç ã€‚ä½†å®ƒçš„ä¾µç•¥æ€§ä¸å¦‚TurboFan - å®ƒåšå‡ºæ›´å®‰å…¨çš„èµŒæ³¨ï¼Œä¸å¤ªå¯èƒ½éœ€è¦å»ä¼˜åŒ–ã€‚
- en: It compiles approximately 10x slower than Sparkplug but 10x faster than TurboFan.
    This makes it perfect for code that's hot enough to benefit from optimization
    but not so critical that it needs TurboFan's heavyweight treatment.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ƒçš„ç¼–è¯‘é€Ÿåº¦å¤§çº¦æ¯”Sparkplugæ…¢10å€ï¼Œä½†æ¯”TurboFanå¿«10å€ã€‚è¿™ä½¿å¾—å®ƒéå¸¸é€‚åˆé‚£äº›è¶³å¤Ÿçƒ­ä»¥ä»ä¼˜åŒ–ä¸­å—ç›Šä½†åˆä¸é‚£ä¹ˆå…³é”®ä»¥è‡³äºéœ€è¦TurboFançš„é‡å‹å¤„ç†çš„ä»£ç ã€‚
- en: One of it's surprising benefits is reduced energy consumption. By providing
    good-enough optimization quickly, it prevents the CPU from spinning in less efficient
    code while waiting for TurboFan to finish its compilation.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸€ä¸ªä»¤äººæƒŠè®¶çš„å¥½å¤„æ˜¯å‡å°‘äº†èƒ½è€—ã€‚é€šè¿‡å¿«é€Ÿæä¾›è¶³å¤Ÿçš„ä¼˜åŒ–ï¼Œå®ƒé˜²æ­¢CPUåœ¨ç­‰å¾…TurboFanå®Œæˆç¼–è¯‘æ—¶åœ¨æ•ˆç‡è¾ƒä½çš„ä»£ç ä¸­ç©ºè½¬ã€‚
- en: Maglev serves as a proving ground. Code that performs well in Maglev with stable
    type feedback becomes a strong candidate for TurboFan optimization.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Maglevä½œä¸ºä¸€ä¸ªè¯•éªŒåœºã€‚åœ¨Maglevä¸­è¡¨ç°è‰¯å¥½çš„ä»£ç ï¼Œå…·æœ‰ç¨³å®šçš„ç±»å‹åé¦ˆï¼Œæˆä¸ºTurboFanä¼˜åŒ–çš„å¼ºæœ‰åŠ›å€™é€‰è€…ã€‚
- en: Here's the modern four-tier compilation pipeline -
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯ç°ä»£çš„å››å±‚ç¼–è¯‘ç®¡é“ -
- en: 'TurboFan''s Trigger: The Hotness Counter'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TurboFançš„è§¦å‘å™¨ï¼šçƒ­åº¦è®¡æ•°å™¨
- en: How does V8 decide when to optimize? It uses a combination of counters and heuristics.
    Every time a function is executed, V8 might increment its hotness counter. When
    this counter reaches certain thresholds, V8 promotes the function to the next
    tier.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: V8å¦‚ä½•å†³å®šä½•æ—¶è¿›è¡Œä¼˜åŒ–ï¼Ÿå®ƒä½¿ç”¨è®¡æ•°å™¨å’Œå¯å‘å¼ç®—æ³•çš„ç»„åˆã€‚æ¯æ¬¡å‡½æ•°æ‰§è¡Œæ—¶ï¼ŒV8å¯èƒ½ä¼šå¢åŠ å…¶çƒ­åº¦è®¡æ•°å™¨ã€‚å½“è¿™ä¸ªè®¡æ•°å™¨è¾¾åˆ°æŸäº›é˜ˆå€¼æ—¶ï¼ŒV8å°†å‡½æ•°æå‡åˆ°ä¸‹ä¸€çº§ã€‚
- en: 'The thresholds aren''t fixed - V8 adjusts them based on various factors:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: é˜ˆå€¼ä¸æ˜¯å›ºå®šçš„ - V8æ ¹æ®å„ç§å› ç´ è¿›è¡Œè°ƒæ•´ï¼š
- en: Loop iterations count more than function calls
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¾ªç¯è¿­ä»£æ¬¡æ•°æ¯”å‡½æ•°è°ƒç”¨å¤š
- en: Functions with stable type feedback are promoted more aggressively
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…·æœ‰ç¨³å®šç±»å‹åé¦ˆçš„å‡½æ•°è¢«æ›´ç§¯æåœ°æå‡
- en: Available CPU resources influence promotion decisions
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ç”¨çš„CPUèµ„æºå½±å“æå‡å†³ç­–
- en: 'Once flagged for TurboFan optimization, the **compilation job** is sent to
    a background thread. This is important: V8 doesn''t block your main application
    thread to compile your code. It does the heavy lifting in parallel, ensuring your
    app remains responsive.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ ‡è®°ä¸ºTurboFanä¼˜åŒ–ï¼Œ**ç¼–è¯‘ä»»åŠ¡**å°†è¢«å‘é€åˆ°åå°çº¿ç¨‹ã€‚è¿™å¾ˆé‡è¦ï¼šV8ä¸ä¼šé˜»å¡ä½ çš„ä¸»åº”ç”¨ç¨‹åºçº¿ç¨‹æ¥ç¼–è¯‘ä½ çš„ä»£ç ã€‚å®ƒå¹¶è¡Œå¤„ç†ç¹é‡çš„å·¥ä½œï¼Œç¡®ä¿ä½ çš„åº”ç”¨ç¨‹åºä¿æŒå“åº”ã€‚
- en: TurboFan's Speculative Optimization
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TurboFançš„æ¨æµ‹æ€§ä¼˜åŒ–
- en: 'TurboFan now has three things: the **bytecode from Ignition**, the **rich Type
    Feedback**, and potentially **optimized code from Maglev** to analyze. It begins
    its work, which is a masterclass in speculation.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: TurboFanç°åœ¨æœ‰ä¸‰ä¸ªä¸œè¥¿ï¼šæ¥è‡ªIgnitionçš„**å­—èŠ‚ç **ã€ä¸°å¯Œçš„**ç±»å‹åé¦ˆ**ï¼Œä»¥åŠå¯èƒ½æ¥è‡ªMaglevçš„**ä¼˜åŒ–ä»£ç **è¿›è¡Œåˆ†æã€‚å®ƒå¼€å§‹å·¥ä½œï¼Œè¿™æ˜¯ä¸€é—¨å…³äºæ¨æµ‹çš„ç²¾æ¹›è¯¾ç¨‹ã€‚
- en: TurboFan doesn't work with bytecode directly. It converts it into an internal
    graph representation called a "**sea of nodes.**" This graph makes it easier to
    apply advanced compiler optimizations like redundant/dead code elimination, [constant
    folding](https://en.wikipedia.org/wiki/Constant_folding), and [loop unrolling](https://en.wikipedia.org/wiki/Loop_unrolling).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: TurboFan ä¸ç›´æ¥ä¸å­—èŠ‚ç å·¥ä½œã€‚å®ƒå°†å…¶è½¬æ¢ä¸ºç§°ä¸ºâ€œ**èŠ‚ç‚¹æµ·æ´‹**â€çš„å†…éƒ¨å›¾è¡¨ç¤ºã€‚è¿™ä¸ªå›¾ä½¿å¾—åº”ç”¨é«˜çº§ç¼–è¯‘å™¨ä¼˜åŒ–ï¼ˆå¦‚å†—ä½™/æ­»ä»£ç æ¶ˆé™¤ã€[å¸¸é‡æŠ˜å ](https://en.wikipedia.org/wiki/Constant_folding)ã€[å¾ªç¯å±•å¼€](https://en.wikipedia.org/wiki/Loop_unrolling)ï¼‰å˜å¾—æ›´å®¹æ˜“ã€‚
- en: 'TurboFan looks at the feedback vector and makes its most aggressive bets. "The
    feedback for `obj.x` says it has always seen the same object shape. I will generate
    machine code that assumes this shape." This means instead of a generic "look up
    property `x` on this object" operation (which involves a hash map lookup), it
    can generate a direct memory access: `mov rax, [rbx + 0x18]`. This is the difference
    between a slow, multi-step process and a single, blazing-fast CPU instruction.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: TurboFan ä¼šæŸ¥çœ‹åé¦ˆå‘é‡å¹¶åšå‡ºæœ€æ¿€è¿›çš„çŒœæµ‹ã€‚â€œå¯¹äº `obj.x` çš„åé¦ˆè¡¨æ˜å®ƒæ€»æ˜¯çœ‹åˆ°ç›¸åŒçš„å¯¹è±¡å½¢çŠ¶ã€‚æˆ‘å°†ç”Ÿæˆå‡è®¾è¿™ä¸ªå½¢çŠ¶çš„æœºå™¨ä»£ç ã€‚â€è¿™æ„å‘³ç€å®ƒå¯ä»¥ç›´æ¥ç”Ÿæˆå†…å­˜è®¿é—®ï¼š`mov
    rax, [rbx + 0x18]`ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªé€šç”¨çš„â€œåœ¨è¿™ä¸ªå¯¹è±¡ä¸ŠæŸ¥æ‰¾å±æ€§ `x`â€æ“ä½œï¼ˆè¿™æ¶‰åŠåˆ°å“ˆå¸Œè¡¨æŸ¥æ‰¾ï¼‰ã€‚è¿™æ˜¯ç¼“æ…¢çš„å¤šæ­¥éª¤è¿‡ç¨‹å’Œå•ä¸ªå¿«é€Ÿ CPU æŒ‡ä»¤ä¹‹é—´çš„åŒºåˆ«ã€‚
- en: â„¹ï¸Note
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: Don't worry if you haven't seen assembly code before. This instruction is a
    direct command to fetch data from a precise memory location. It calculates the
    address using the object's location (rbx) plus a fixed offset (+ 0x18), completely
    skipping a slow property lookup.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¹‹å‰æ²¡æœ‰è§è¿‡æ±‡ç¼–ä»£ç ï¼Œä¸è¦æ‹…å¿ƒã€‚è¿™æ¡æŒ‡ä»¤æ˜¯ç›´æ¥ä»ç²¾ç¡®å†…å­˜ä½ç½®è·å–æ•°æ®çš„å‘½ä»¤ã€‚å®ƒä½¿ç”¨å¯¹è±¡çš„ä½ç½®ï¼ˆrbxï¼‰åŠ ä¸Šä¸€ä¸ªå›ºå®šåç§»é‡ï¼ˆ+ 0x18ï¼‰æ¥è®¡ç®—åœ°å€ï¼Œå®Œå…¨è·³è¿‡äº†ç¼“æ…¢çš„å±æ€§æŸ¥æ‰¾ã€‚
- en: If a hot function `foo()` calls another function `bar()`, TurboFan might decide
    to **inline** `bar()`. It essentially copies the machine code for `bar()` directly
    into the code for `foo()`, eliminating the overhead of a function call. This is
    one of the most powerful optimizations V8 performs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸€ä¸ªçƒ­é—¨å‡½æ•° `foo()` è°ƒç”¨äº†å¦ä¸€ä¸ªå‡½æ•° `bar()`ï¼ŒTurboFan å¯èƒ½ä¼šå†³å®š **å†…è”** `bar()`ã€‚å®ƒæœ¬è´¨ä¸Šæ˜¯å°† `bar()`
    çš„æœºå™¨ä»£ç ç›´æ¥å¤åˆ¶åˆ° `foo()` çš„ä»£ç ä¸­ï¼Œæ¶ˆé™¤äº†å‡½æ•°è°ƒç”¨çš„å¼€é”€ã€‚è¿™æ˜¯ V8 æ‰§è¡Œçš„æœ€å¼ºå¤§çš„ä¼˜åŒ–ä¹‹ä¸€ã€‚
- en: What if a function is already running when it becomes hot? Imagine a long-running
    `for` loop. The function was called once, but the loop has been spinning for millions
    of iterations. V8 can't wait for the function to return to swap in the optimized
    code. This is where **On-Stack Replacement** (OSR) comes in. While the loop is
    running in slow Ignition bytecode, TurboFan compiles an optimized version in the
    background. Once it's ready, V8 can pause execution *in the middle of the loop*,
    replace the execution frame on the stack with the new optimized frame, and resume
    execution in the fast machine code.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸€ä¸ªå‡½æ•°åœ¨å˜å¾—çƒ­é—¨æ—¶å·²ç»å¼€å§‹è¿è¡Œå‘¢ï¼Ÿæƒ³è±¡ä¸€ä¸‹ä¸€ä¸ªé•¿æ—¶é—´è¿è¡Œçš„ `for` å¾ªç¯ã€‚å‡½æ•°è¢«è°ƒç”¨äº†ä¸€æ¬¡ï¼Œä½†å¾ªç¯å·²ç»è¿›è¡Œäº†æ•°ç™¾ä¸‡æ¬¡è¿­ä»£ã€‚V8 ä¸èƒ½ç­‰å¾…å‡½æ•°è¿”å›æ¥äº¤æ¢ä¼˜åŒ–åçš„ä»£ç ã€‚è¿™å°±æ˜¯
    **æ ˆä¸Šæ›¿æ¢**ï¼ˆOSRï¼‰å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚å½“å¾ªç¯åœ¨æ…¢é€Ÿçš„ Ignition å­—èŠ‚ç ä¸­è¿è¡Œæ—¶ï¼ŒTurboFan åœ¨åå°ç¼–è¯‘ä¸€ä¸ªä¼˜åŒ–ç‰ˆæœ¬ã€‚ä¸€æ—¦å‡†å¤‡å¥½ï¼ŒV8 å¯ä»¥åœ¨å¾ªç¯çš„ä¸­é—´æš‚åœæ‰§è¡Œï¼Œç”¨æ–°çš„ä¼˜åŒ–å¸§æ›¿æ¢æ ˆä¸Šçš„æ‰§è¡Œå¸§ï¼Œç„¶ååœ¨å¿«é€Ÿæœºå™¨ç ä¸­ç»§ç»­æ‰§è¡Œã€‚
- en: 'What you get from TurboFan is a block of machine code that''s been highly optimized
    based on the behavior Ignition observed. This code is extremely fast, but there''s
    a catch: it''s totally dependent on those early observations holding true.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä» TurboFan è·å¾—çš„æ˜¯ä¸€ä¸ªåŸºäº Ignition è§‚å¯Ÿåˆ°çš„è¡Œä¸ºé«˜åº¦ä¼˜åŒ–çš„æœºå™¨ä»£ç å—ã€‚è¿™æ®µä»£ç éå¸¸å¿«ï¼Œä½†æœ‰ä¸€ä¸ªé—®é¢˜ï¼šå®ƒå®Œå…¨ä¾èµ–äºé‚£äº›æ—©æœŸè§‚å¯Ÿç»“æœçš„çœŸå®æ€§ã€‚
- en: Hidden Classes
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: éšè—ç±»
- en: '**This is it**. If you only learn one thing about V8 internals, make it this.
    **Hidden Classes** (also called "Shapes" or "Maps" in V8''s source code) are the
    mechanism V8 uses to implement fast property access on JavaScript objects. They
    are the foundation upon which all the optimizing compilers build their optimizations.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¿™å°±æ˜¯å…³é”®**ã€‚å¦‚æœä½ åªæƒ³äº†è§£å…³äº V8 å†…éƒ¨çš„ä¸€ä¸ªçŸ¥è¯†ç‚¹ï¼Œé‚£å°±è®©å®ƒæˆä¸ºè¿™ä¸ªã€‚**éšè—ç±»**ï¼ˆåœ¨ V8 çš„æºä»£ç ä¸­ä¹Ÿç§°ä¸ºâ€œå½¢çŠ¶â€æˆ–â€œæ˜ å°„â€ï¼‰æ˜¯ V8
    ç”¨äºåœ¨ JavaScript å¯¹è±¡ä¸Šå®ç°å¿«é€Ÿå±æ€§è®¿é—®çš„æœºåˆ¶ã€‚å®ƒä»¬æ˜¯æ‰€æœ‰ä¼˜åŒ–ç¼–è¯‘å™¨æ„å»ºä¼˜åŒ–åŸºç¡€çš„éƒ¨åˆ†ã€‚'
- en: Let's bust another myth.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ‰“ç ´å¦ä¸€ä¸ªè¯¯åŒºã€‚
- en: 'Myth 2: "JavaScript objects are like hash maps"'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'è¯¯åŒº 2: â€œJavaScript å¯¹è±¡å°±åƒå“ˆå¸Œè¡¨â€'
- en: In your mind, you probably picture a JavaScript object as a dictionary or a
    hash map, where property names map to values. While this is the *logical* model,
    it's not the physical reality for V8\. Hash map lookups are relatively slow. To
    make property access fast, V8 pretends that JavaScript has classes.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½ çš„è„‘æµ·ä¸­ï¼Œä½ å¯èƒ½å°† JavaScript å¯¹è±¡æƒ³è±¡æˆä¸€ä¸ªå­—å…¸æˆ–å“ˆå¸Œè¡¨ï¼Œå…¶ä¸­å±æ€§åæ˜ å°„åˆ°å€¼ã€‚è™½ç„¶è¿™æ˜¯ *é€»è¾‘* æ¨¡å‹ï¼Œä½†ä¸æ˜¯ V8 çš„ç‰©ç†ç°å®ã€‚å“ˆå¸Œè¡¨æŸ¥æ‰¾ç›¸å¯¹è¾ƒæ…¢ã€‚ä¸ºäº†ä½¿å±æ€§è®¿é—®å¿«é€Ÿï¼ŒV8
    å‡è®¾ JavaScript æœ‰ç±»ã€‚
- en: When you create an object, V8 creates a **hidden class** for it behind the scenes.
    This hidden class stores meta-information about the object's shape, specifically
    the layout of its properties.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ åˆ›å»ºä¸€ä¸ªå¯¹è±¡æ—¶ï¼ŒV8 åœ¨å¹•åä¸ºå®ƒåˆ›å»ºä¸€ä¸ª **éšè—ç±»**ã€‚è¿™ä¸ªéšè—ç±»å­˜å‚¨æœ‰å…³å¯¹è±¡å½¢çŠ¶çš„å…ƒä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯å…¶å±æ€§å¸ƒå±€ã€‚
- en: Let's watch it happen.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å‘ç”Ÿçš„ã€‚
- en: '[PRE0]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ğŸš¨Caution
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸš¨ è­¦å‘Š
- en: V8 intrinsics (like `%HaveSameMap`) are internal, unsupported APIs that change
    between V8 versions. Use them only for experiments with `--allow-natives-syntax`.
    Never use in production code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: V8 å†…ç½®å‡½æ•°ï¼ˆå¦‚ `%HaveSameMap`ï¼‰æ˜¯å†…éƒ¨ã€ä¸å—æ”¯æŒçš„ APIï¼Œå®ƒä»¬åœ¨ V8 ç‰ˆæœ¬ä¹‹é—´ä¼šå‘ç”Ÿå˜åŒ–ã€‚ä»…åœ¨ä½¿ç”¨ `--allow-natives-syntax`
    è¿›è¡Œå®éªŒæ—¶ä½¿ç”¨å®ƒä»¬ã€‚åˆ‡å‹¿åœ¨ç”Ÿäº§ä»£ç ä¸­ä½¿ç”¨ã€‚
- en: Transition Trees
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è½¬æ¢æ ‘
- en: V8 doesn't just create a new hidden class for every possible object shape. It
    creates **transition chains**.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: V8 å¹¶ä¸ä»…ä»…ä¸ºæ¯ä¸ªå¯èƒ½çš„å¯¹è±¡å½¢çŠ¶åˆ›å»ºä¸€ä¸ªæ–°çš„éšè—ç±»ã€‚å®ƒåˆ›å»º **è½¬æ¢é“¾**ã€‚
- en: When you create `const p1 = {}`, `p1` gets a base hidden class, let's call it
    `C0`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ åˆ›å»º `const p1 = {}` æ—¶ï¼Œ`p1` è·å¾—ä¸€ä¸ªåŸºæœ¬éšè—ç±»ï¼Œè®©æˆ‘ä»¬ç§°å®ƒä¸º `C0`ã€‚
- en: 'When you add `p1.x = 5`, V8 checks if a transition for property `x` already
    exists from `C0`. If not, it creates a new hidden class `C1` and records a transition:
    `C0 + ''x'' => C1`. The hidden class `C1` now knows that objects with its shape
    have a property `x` at a specific offset in memory. `p1`''s hidden class is updated
    to `C1`.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ æ·»åŠ  `p1.x = 5` æ—¶ï¼ŒV8 ä¼šæ£€æŸ¥æ˜¯å¦å­˜åœ¨ä» `C0` åˆ°å±æ€§ `x` çš„è½¬æ¢ã€‚å¦‚æœæ²¡æœ‰ï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„éšè—ç±» `C1` å¹¶è®°å½•ä¸€ä¸ªè½¬æ¢ï¼š`C0
    + 'x' => C1`ã€‚éšè—ç±» `C1` ç°åœ¨çŸ¥é“å…·æœ‰å…¶å½¢çŠ¶çš„å¯¹è±¡åœ¨å†…å­˜ä¸­å…·æœ‰ä¸€ä¸ªç‰¹å®šåç§»é‡çš„å±æ€§ `x`ã€‚`p1` çš„éšè—ç±»è¢«æ›´æ–°ä¸º `C1`ã€‚
- en: 'When you add `p1.y = 10`, it does the same thing: it creates `C2` and a transition:
    `C1 + ''y'' => C2`.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ æ·»åŠ  `p1.y = 10` æ—¶ï¼Œå®ƒåšçš„æ˜¯åŒæ ·çš„äº‹æƒ…ï¼šå®ƒåˆ›å»º `C2` å’Œä¸€ä¸ªè½¬æ¢ï¼š`C1 + 'y' => C2`ã€‚
- en: Now, if you create another object, `const p2 = {}`, it starts at `C0`. If you
    then add `p2.x = 15`, V8 sees the existing transition and simply moves `p2` to
    hidden class `C1`. If you then add `p2.y = 20`, it moves to `C2`. Now, `p1` and
    `p2` have the *exact same hidden class*. V8 can optimize any code that operates
    on these objects because it knows they have the same memory layout.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¦‚æœä½ åˆ›å»ºå¦ä¸€ä¸ªå¯¹è±¡ï¼Œ`const p2 = {}`ï¼Œå®ƒä» `C0` å¼€å§‹ã€‚å¦‚æœä½ ç„¶åæ·»åŠ  `p2.x = 15`ï¼ŒV8 ä¼šçœ‹åˆ°ç°æœ‰çš„è½¬æ¢ï¼Œå¹¶ç®€å•åœ°å°†
    `p2` ç§»åŠ¨åˆ°éšè—ç±» `C1`ã€‚å¦‚æœä½ ç„¶åæ·»åŠ  `p2.y = 20`ï¼Œå®ƒå°†ç§»åŠ¨åˆ° `C2`ã€‚ç°åœ¨ï¼Œ`p1` å’Œ `p2` æ‹¥æœ‰ **å®Œå…¨ç›¸åŒçš„éšè—ç±»**ã€‚V8
    å¯ä»¥ä¼˜åŒ–ä»»ä½•æ“ä½œè¿™äº›å¯¹è±¡çš„ä»£ç ï¼Œå› ä¸ºå®ƒçŸ¥é“å®ƒä»¬å…·æœ‰ç›¸åŒçš„å†…å­˜å¸ƒå±€ã€‚
- en: Here's the killer. What if you create `const p3 = {}` and add the properties
    in a different order? `p3.y = 1;` `p3.x = 2;`
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å…³é”®ã€‚å¦‚æœä½ åˆ›å»º `const p3 = {}` å¹¶ä»¥ä¸åŒçš„é¡ºåºæ·»åŠ å±æ€§ï¼Ÿ`p3.y = 1;` `p3.x = 2;`
- en: This creates a completely different transition path! `C0 + 'y' => C3` `C3 +
    'x' => C4`
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åˆ›å»ºäº†ä¸€ä¸ªå®Œå…¨ä¸åŒçš„è½¬æ¢è·¯å¾„ï¼`C0 + 'y' => C3` `C3 + 'x' => C4`
- en: Even though `p2` and `p3` have the same properties, they have **different hidden
    classes**. To V8, they are fundamentally different shapes.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿ `p2` å’Œ `p3` å…·æœ‰ç›¸åŒçš„å±æ€§ï¼Œå®ƒä»¬å´æ‹¥æœ‰ **ä¸åŒçš„éšè—ç±»**ã€‚å¯¹ V8 æ¥è¯´ï¼Œå®ƒä»¬æ˜¯æ ¹æœ¬ä¸åŒçš„å½¢çŠ¶ã€‚
- en: The "Config Object" disaster we had
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é‡åˆ°çš„â€œé…ç½®å¯¹è±¡â€ç¾éš¾
- en: 'This is exactly what killed us in the 100x slowdown mystery. Our code looked
    something like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ­£æ˜¯æˆ‘ä»¬åœ¨ 100 å€å‡é€Ÿä¹‹è°œä¸­é‡åˆ°çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„ä»£ç çœ‹èµ·æ¥åƒè¿™æ ·ï¼š
- en: '[PRE1]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Because `userOverrides` added keys in an unpredictable order and `optionalFeature`
    was only sometimes present, we were creating dozens, sometimes hundreds, of different
    hidden classes for objects that were logically the same. When the optimizing compiler
    (TurboFan) tried to optimize functions that used these `config` objects, they
    saw chaos. They couldn't make any reliable bets, so they just gave up. Or worse,
    they would optimize for one shape, then immediately deoptimize when they saw another.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº `userOverrides` æ·»åŠ é”®çš„é¡ºåºä¸å¯é¢„æµ‹ï¼Œè€Œ `optionalFeature` åªæœ‰æ—¶å­˜åœ¨ï¼Œæˆ‘ä»¬ä¸ºé€»è¾‘ä¸Šç›¸åŒçš„å¯¹è±¡åˆ›å»ºäº†æ•°åä¸ªï¼Œæœ‰æ—¶ç”šè‡³æ•°ç™¾ä¸ªä¸åŒçš„éšè—ç±»ã€‚å½“ä¼˜åŒ–ç¼–è¯‘å™¨ï¼ˆTurboFanï¼‰å°è¯•ä¼˜åŒ–ä½¿ç”¨è¿™äº›
    `config` å¯¹è±¡çš„å‡½æ•°æ—¶ï¼Œå®ƒä»¬çœ‹åˆ°äº†æ··ä¹±ã€‚å®ƒä»¬æ— æ³•åšå‡ºä»»ä½•å¯é çš„çŒœæµ‹ï¼Œå› æ­¤åªèƒ½æ”¾å¼ƒã€‚æˆ–è€…æ›´ç³Ÿï¼Œå®ƒä»¬ä¼šé’ˆå¯¹ä¸€ä¸ªå½¢çŠ¶è¿›è¡Œä¼˜åŒ–ï¼Œç„¶ååœ¨çœ‹åˆ°å¦ä¸€ä¸ªå½¢çŠ¶æ—¶ç«‹å³é™çº§ã€‚
- en: 'Here''s how the hidden class fork happened in our config object:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å¦‚ä½•åœ¨æˆ‘ä»¬çš„é…ç½®å¯¹è±¡ä¸­å‘ç”Ÿéšè—ç±»åˆ†æ”¯çš„ï¼š
- en: 'The fix was deceptively simple for our hot-path config objects: **pre-initialize
    properties that are frequently accessed**, even with `null` or `undefined`.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘ä»¬çš„çƒ­ç‚¹è·¯å¾„é…ç½®å¯¹è±¡ï¼Œä¿®å¤æ–¹æ³•æ˜¯æ¬ºéª—æ€§åœ°ç®€å•ï¼š**é¢„å…ˆåˆå§‹åŒ–é¢‘ç¹è®¿é—®çš„å±æ€§**ï¼Œå³ä½¿ä½¿ç”¨ `null` æˆ– `undefined`ã€‚
- en: '[PRE2]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'By creating a stable initial shape, we ensured that almost all our config objects
    shared the same hidden class. This allowed the optimizing compilers to generate
    highly optimized code for handling them, and our latency dropped from 200ms back
    down to 2ms. We learned a brutal lesson: **property addition order is not just
    a stylistic choice, it''s a critical performance determinant**.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åˆ›å»ºä¸€ä¸ªç¨³å®šçš„åˆå§‹å½¢çŠ¶ï¼Œæˆ‘ä»¬ç¡®ä¿äº†å‡ ä¹æ‰€æœ‰æˆ‘ä»¬çš„é…ç½®å¯¹è±¡éƒ½å…±äº«ç›¸åŒçš„éšè—ç±»ã€‚è¿™ä½¿å¾—ä¼˜åŒ–ç¼–è¯‘å™¨èƒ½å¤Ÿä¸ºå®ƒä»¬ç”Ÿæˆé«˜åº¦ä¼˜åŒ–çš„ä»£ç ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„å»¶è¿Ÿä» 200ms
    é™è‡³ 2msã€‚æˆ‘ä»¬å­¦åˆ°äº†ä¸€ä¸ªæ®‹é…·çš„æ•™è®­ï¼š**å±æ€§æ·»åŠ é¡ºåºä¸ä»…ä»…æ˜¯ä¸€ä¸ªé£æ ¼é€‰æ‹©ï¼Œå®ƒæ˜¯ä¸€ä¸ªå…³é”®çš„æ€§èƒ½å†³å®šå› ç´ **ã€‚
- en: ğŸš¨Caution
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸš¨æ³¨æ„
- en: Pre-initializing all properties stabilizes shapes but can waste memory with
    large objects. Only do this for performance-critical objects on hot paths. For
    general-purpose objects, favor readability and maintainability.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„å…ˆåˆå§‹åŒ–æ‰€æœ‰å±æ€§å¯ä»¥ç¨³å®šå½¢çŠ¶ï¼Œä½†å¯èƒ½ä¼šæµªè´¹å¤§å¯¹è±¡çš„å†…å­˜ã€‚ä»…å¯¹æ€§èƒ½å…³é”®çš„å¯¹è±¡åœ¨çƒ­ç‚¹è·¯å¾„ä¸Šè¿™æ ·åšã€‚å¯¹äºé€šç”¨å¯¹è±¡ï¼Œä¼˜å…ˆè€ƒè™‘å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
- en: Inline Caching and Monomorphism
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å†…è”ç¼“å­˜å’Œå¤šæ€æ€§
- en: 'So, V8 uses **Hidden Classes** to create a secret blueprint for your objects.
    That''s the "what." Now for the "how": how does V8 actually *use* that blueprint
    to make your code scream? The answer is a brilliant piece of runtime optimization
    called an **Inline Cache (IC)**. This is the mechanism that connects the theory
    of Hidden Classes to real-world speed.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒV8 ä½¿ç”¨ **éšè—ç±»** ä¸ºä½ çš„å¯¹è±¡åˆ›å»ºä¸€ä¸ªç§˜å¯†è“å›¾ã€‚è¿™å°±æ˜¯â€œæ˜¯ä»€ä¹ˆâ€ã€‚ç°åœ¨æ¥è¯´â€œå¦‚ä½•â€ï¼šV8 å¦‚ä½•å®é™… *ä½¿ç”¨* è¿™ä¸ªè“å›¾è®©ä½ çš„ä»£ç é£å¿«è¿è¡Œï¼Ÿç­”æ¡ˆæ˜¯è¿è¡Œæ—¶ä¼˜åŒ–çš„ä¸€ä»¶æ°ä½œï¼Œç§°ä¸º
    **å†…è”ç¼“å­˜ (IC)**ã€‚è¿™æ˜¯å°†éšè—ç±»çš„ç†è®ºè¿æ¥åˆ°å®é™…é€Ÿåº¦çš„æœºåˆ¶ã€‚
- en: 'First, let''s nail down a key piece of jargon: the **call site**. A call site
    isn''t some abstract idea; it''s a literal, physical place in your code where
    a dynamic operation happens.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬ç¡®å®šä¸€ä¸ªå…³é”®æœ¯è¯­ï¼š**è°ƒç”¨ç‚¹**ã€‚è°ƒç”¨ç‚¹ä¸æ˜¯ä¸€ä¸ªæŠ½è±¡çš„æ¦‚å¿µï¼›å®ƒæ˜¯åœ¨ä½ çš„ä»£ç ä¸­å‘ç”ŸåŠ¨æ€æ“ä½œçš„ä¸€ä¸ªå®é™…çš„ã€ç‰©ç†çš„ä½ç½®ã€‚
- en: '[PRE3]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The line `return point.x;` is a single, unique call site. No matter what object
    you pass to `getX`, V8 is always executing that *same line* to access the `x`
    property. This specific location is what V8 optimizes.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¡Œä»£ç  `return point.x;` æ˜¯ä¸€ä¸ªå•ä¸€ã€ç‹¬ç‰¹çš„è°ƒç”¨ç‚¹ã€‚æ— è®ºä½ ä¼ é€’ä»€ä¹ˆå¯¹è±¡ç»™ `getX`ï¼ŒV8 æ€»æ˜¯æ‰§è¡Œç›¸åŒçš„è¿™ä¸€è¡Œæ¥è®¿é—® `x` å±æ€§ã€‚è¿™ä¸ªç‰¹å®šçš„ä½ç½®å°±æ˜¯
    V8 ä¼˜åŒ–çš„åœ°æ–¹ã€‚
- en: 'Think of an IC as targeted muscle memory. The first time you access `obj.x`
    at a particular call site, V8 has to do the slow, painful lookup:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å°† IC æƒ³è±¡æˆæœ‰é’ˆå¯¹æ€§çš„è‚Œè‚‰è®°å¿†ã€‚ç¬¬ä¸€æ¬¡ä½ åœ¨ç‰¹å®šçš„è°ƒç”¨ç‚¹ä¸Šè®¿é—® `obj.x`ï¼ŒV8 å¿…é¡»è¿›è¡Œæ…¢é€Ÿã€ç—›è‹¦çš„æŸ¥æ‰¾ï¼š
- en: Get the hidden class of `obj`.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è·å– `obj` çš„éšè—ç±»ã€‚
- en: Scan that hidden class's metadata for the memory offset of property `x`.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥é‚£ä¸ªéšè—ç±»çš„å…ƒæ•°æ®ä»¥è·å–å±æ€§ `x` çš„å†…å­˜åç§»é‡ã€‚
- en: Jump to that offset in the object's memory and get the value.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è·³è½¬åˆ°å¯¹è±¡å†…å­˜ä¸­çš„é‚£ä¸ªåç§»é‡å¹¶è·å–å€¼ã€‚
- en: 'After doing all that work, V8 doesn''t just forget. It rewrites a tiny stub
    of machine code at that exact call site. This stub is the Inline Cache. The next
    time that line of code is executed, the IC does a single, super-fast check: **"Is
    the hidden class of this new object the same as the one I saw last time?"** If
    the answer is yes, it completely skips the slow lookup and uses the cached offset
    to access the property directly. A dynamic lookup just became as fast as a direct
    memory access in C++. This is a massive win.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®Œæˆæ‰€æœ‰è¿™äº›å·¥ä½œåï¼ŒV8 å¹¶ä¸ä¼šå¿˜è®°ã€‚å®ƒä¼šåœ¨é‚£ä¸ªç¡®åˆ‡çš„è°ƒç”¨ç‚¹ä¸Šé‡å†™ä¸€å°æ®µæœºå™¨ä»£ç çš„å­˜æ ¹ã€‚è¿™ä¸ªå­˜æ ¹å°±æ˜¯å†…è”ç¼“å­˜ã€‚ä¸‹æ¬¡æ‰§è¡Œé‚£è¡Œä»£ç æ—¶ï¼ŒIC ä¼šè¿›è¡Œä¸€æ¬¡å•ä¸€ã€è¶…çº§å¿«é€Ÿçš„æ£€æŸ¥ï¼š**â€œè¿™ä¸ªæ–°å¯¹è±¡çš„éšè—ç±»å’Œæˆ‘ä¸Šæ¬¡çœ‹åˆ°çš„æ˜¯å¦ç›¸åŒï¼Ÿâ€**
    å¦‚æœç­”æ¡ˆæ˜¯è‚¯å®šçš„ï¼Œå®ƒå°†å®Œå…¨è·³è¿‡æ…¢é€ŸæŸ¥æ‰¾ï¼Œå¹¶ä½¿ç”¨ç¼“å­˜çš„åç§»é‡ç›´æ¥è®¿é—®å±æ€§ã€‚åŠ¨æ€æŸ¥æ‰¾ç°åœ¨å˜å¾—å’Œ C++ ä¸­çš„ç›´æ¥å†…å­˜è®¿é—®ä¸€æ ·å¿«ã€‚è¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„èƒœåˆ©ã€‚
- en: 'This brings us to the different "modes" or states an IC can be in. This is
    where the terminology gets important:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æˆ‘ä»¬å¼•å‘ IC å¯ä»¥å¤„äºçš„ä¸åŒâ€œæ¨¡å¼â€æˆ–çŠ¶æ€ã€‚è¿™æ˜¯æœ¯è¯­å˜å¾—é‡è¦çš„åœ°æ–¹ï¼š
- en: '**Uninitialized -** The IC is a clean slate before the first execution of that
    line of code.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æœªåˆå§‹åŒ– -** åœ¨æ‰§è¡Œé‚£è¡Œä»£ç ä¹‹å‰ï¼ŒIC æ˜¯ä¸€å¼ ç™½çº¸ã€‚'
- en: '**Monomorphic -** This is the golden state. The IC has only ever seen **one**
    hidden class at this call site. `Mono` means one. This is the fastest possible
    state because V8 can generate machine code that is hyper-specialized for this
    single shape.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å•æ€å‹ -** è¿™æ˜¯é»„é‡‘çŠ¶æ€ã€‚åœ¨è¿™ä¸ªè°ƒç”¨ç‚¹ä¸Šï¼ŒIC åªçœ‹åˆ°äº† **ä¸€ä¸ª** éšè—ç±»ã€‚`Mono` æ„å‘³ç€ä¸€ä¸ªã€‚è¿™æ˜¯å¯èƒ½çš„æœ€å¿«çŠ¶æ€ï¼Œå› ä¸º V8 å¯ä»¥ç”Ÿæˆé’ˆå¯¹è¿™ä¸ªå•ä¸€å½¢çŠ¶çš„è¶…ä¸“ç”¨æœºå™¨ä»£ç ã€‚'
- en: '**Polymorphic -** The IC has seen a small number of different hidden classes
    (typically 2 to 4). `Poly` means many. V8 can still handle this, but it''s slower.
    It has to add checks: "Is it shape A? If so, use offset X. Is it shape B? If so,
    use offset Y?" This is still faster than a full dynamic lookup.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¤šæ€å‹ -** IC çœ‹åˆ°äº†å°‘æ•°ä¸åŒçš„éšè—ç±»ï¼ˆé€šå¸¸æ˜¯ 2 åˆ° 4 ä¸ªï¼‰ã€‚`Poly` æ„å‘³ç€å¤šä¸ªã€‚V8 ä»ç„¶å¯ä»¥å¤„ç†è¿™ç§æƒ…å†µï¼Œä½†é€Ÿåº¦è¾ƒæ…¢ã€‚å®ƒå¿…é¡»æ·»åŠ æ£€æŸ¥ï¼šâ€œè¿™æ˜¯å½¢çŠ¶
    A å—ï¼Ÿå¦‚æœæ˜¯ï¼Œä½¿ç”¨åç§»é‡ Xã€‚è¿™æ˜¯å½¢çŠ¶ B å—ï¼Ÿå¦‚æœæ˜¯ï¼Œä½¿ç”¨åç§»é‡ Yï¼Ÿâ€è¿™ä»ç„¶æ¯”å®Œæ•´çš„åŠ¨æ€æŸ¥æ‰¾è¦å¿«ã€‚'
- en: '**Megamorphic -** The IC has seen too many different hidden classes. `Mega`
    means huge. At this point, V8 gives up. The IC is considered "polluted," and V8
    falls back to the slow, generic lookup. Performance goes off a cliff.'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å·¨å½¢æ€ -** ICå·²ç»çœ‹åˆ°äº†å¤ªå¤šä¸åŒçš„éšè—ç±»ã€‚`Mega`æ„å‘³ç€å·¨å¤§ã€‚åœ¨è¿™ä¸ªæ—¶å€™ï¼ŒV8æ”¾å¼ƒäº†ã€‚ICè¢«è®¤ä¸ºæ˜¯â€œæ±¡æŸ“çš„â€ï¼ŒV8é€€å›åˆ°æ…¢é€Ÿçš„é€šç”¨æŸ¥æ‰¾ã€‚æ€§èƒ½ç›´çº¿ä¸‹é™ã€‚'
- en: Here's how an IC transitions through these states -
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ICå¦‚ä½•é€šè¿‡è¿™äº›çŠ¶æ€è½¬æ¢çš„ -
- en: When the IC is polymorphic, it's essentially running a series of checks like
    this internally -
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ICæ˜¯å¤šæ€çš„ï¼Œå®ƒå®é™…ä¸Šæ˜¯åœ¨å†…éƒ¨è¿è¡Œä¸€ç³»åˆ—è¿™æ ·çš„æ£€æŸ¥ -
- en: A small example
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå°ä¾‹å­
- en: Talk is cheap. Let's see what this performance difference actually looks like
    with a real benchmark. This pattern is incredibly common in data processing.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: è°ˆè¯æ˜¯å»‰ä»·çš„ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªæ€§èƒ½å·®å¼‚åœ¨çœŸå®åŸºå‡†æµ‹è¯•ä¸­å®é™…ä¸Šçœ‹èµ·æ¥æ˜¯ä»€ä¹ˆæ ·å­ã€‚è¿™ç§æ¨¡å¼åœ¨æ•°æ®å¤„ç†ä¸­éå¸¸å¸¸è§ã€‚
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'On my machine running Node.js v23, the results are obvious (your results may
    vary): `Monomorphic: 16.05ms` `Polymorphic: 47.23ms`'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘çš„æœºå™¨ä¸Šè¿è¡ŒNode.js v23æ—¶ï¼Œç»“æœå¾ˆæ˜æ˜¾ï¼ˆä½ çš„ç»“æœå¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼‰ï¼š`å•æ€ï¼š16.05ms` `å¤šæ€ï¼š47.23ms`
- en: The polymorphic version is nearly **3x slower**. And that's with only *two*
    shapes. Imagine a function that receives objects from five different sources,
    each with a slightly different structure. That call site will become megamorphic,
    and the performance penalty could easily be 10-50x.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šæ€ç‰ˆæœ¬å‡ ä¹**æ…¢3å€**ã€‚è€Œä¸”è¿™ä»…ä»…æ˜¯**ä¸¤ç§**å½¢çŠ¶ã€‚æƒ³è±¡ä¸€ä¸ªæ¥æ”¶æ¥è‡ªäº”ä¸ªä¸åŒæ¥æºçš„å¯¹è±¡çš„å‡½æ•°ï¼Œæ¯ä¸ªå¯¹è±¡çš„ç»“æ„ç•¥æœ‰ä¸åŒã€‚é‚£ä¸ªè°ƒç”¨ç‚¹å°†å˜æˆå·¨å½¢æ€ï¼Œæ€§èƒ½æƒ©ç½šå¯èƒ½ä¼šé«˜è¾¾10-50å€ã€‚
- en: 'The goal is to write functions that operate on predictable data structures.
    When you see a function that can receive "either a User object or a Company object,"
    your performance senses should be tingling. It might be better to have two separate,
    monomorphic functions: `processUser(user)` and `processCompany(company)`. Boring,
    repetitive code is often the fastest code.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡æ˜¯ç¼–å†™æ“ä½œå¯é¢„æµ‹æ•°æ®ç»“æ„çš„å‡½æ•°ã€‚å½“ä½ çœ‹åˆ°ä¸€ä¸ªå¯ä»¥æ¥æ”¶â€œç”¨æˆ·å¯¹è±¡æˆ–å…¬å¸å¯¹è±¡â€çš„å‡½æ•°æ—¶ï¼Œä½ çš„æ€§èƒ½æ„Ÿè§‰åº”è¯¥ä¼šå‘ç—’ã€‚å¯èƒ½æ›´å¥½çš„åšæ³•æ˜¯æ‹¥æœ‰ä¸¤ä¸ªç‹¬ç«‹çš„ã€å•æ€çš„å‡½æ•°ï¼š`processUser(user)`å’Œ`processCompany(company)`ã€‚æ— èŠã€é‡å¤çš„ä»£ç é€šå¸¸æ˜¯æœ€å¿«çš„ä»£ç ã€‚
- en: Deoptimization - When V8 Gives Up
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å»ä¼˜åŒ– - å½“V8æ”¾å¼ƒ
- en: Deoptimization is V8's emergency eject button. It's the process of throwing
    away fast, optimized machine code and falling back to a lower compilation tier.
    It is, without a doubt, the single biggest cause of mysterious performance problems
    in Node.js applications.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: å»ä¼˜åŒ–æ˜¯V8çš„ç´§æ€¥å¼¹å‡ºæŒ‰é’®ã€‚å®ƒæ˜¯ä¸¢å¼ƒå¿«é€Ÿä¼˜åŒ–çš„æœºå™¨ä»£ç å¹¶é€€å›åˆ°è¾ƒä½ç¼–è¯‘å±‚çš„è¿‡ç¨‹ã€‚æ¯«æ— ç–‘é—®ï¼Œå®ƒæ˜¯Node.jsåº”ç”¨ç¨‹åºä¸­ç¥ç§˜æ€§èƒ½é—®é¢˜çš„æœ€å¤§åŸå› ã€‚
- en: Remember, the optimized machine code from Maglev and TurboFan is *speculative*.
    It's built on a pile of assumptions (type feedback) gathered by Ignition. Deoptimization
    occurs whenever one of those assumptions is proven false at runtime.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œæ¥è‡ªç£æ‚¬æµ®å’ŒTurboFançš„ä¼˜åŒ–æœºå™¨ä»£ç æ˜¯**æ¨æµ‹æ€§çš„**ã€‚å®ƒå»ºç«‹åœ¨Ignitionæ”¶é›†çš„ä¸€å †å‡è®¾ï¼ˆç±»å‹åé¦ˆï¼‰ä¹‹ä¸Šã€‚æ¯å½“è¿™äº›å‡è®¾ä¹‹ä¸€åœ¨è¿è¡Œæ—¶è¢«è¯æ˜æ˜¯é”™è¯¯çš„ï¼Œå°±ä¼šå‘ç”Ÿå»ä¼˜åŒ–ã€‚
- en: Common Deoptimization Triggers
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¸¸è§å»ä¼˜åŒ–è§¦å‘å™¨
- en: V8 will deoptimize for many reasons, but some culprits are far more common than
    others.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: V8ä¼šå› è®¸å¤šåŸå› å»ä¼˜åŒ–ï¼Œä½†æŸäº›åŸå› æ¯”å…¶ä»–åŸå› æ›´å¸¸è§ã€‚
- en: '**Hidden Class Mismatch -** This is the big one. TurboFan compiled a function
    assuming it would always see objects with hidden class `C2`. Suddenly, an object
    with `C4` arrives. The specialized machine code is now invalid. **Bailout!**'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**éšè—ç±»ä¸åŒ¹é… -** è¿™æ˜¯æœ€å¤§çš„é—®é¢˜ã€‚TurboFanç¼–è¯‘äº†ä¸€ä¸ªå‡½æ•°ï¼Œå‡è®¾å®ƒå°†å§‹ç»ˆçœ‹åˆ°å…·æœ‰éšè—ç±»`C2`çš„å¯¹è±¡ã€‚çªç„¶ï¼Œä¸€ä¸ªå…·æœ‰`C4`çš„å¯¹è±¡åˆ°è¾¾äº†ã€‚ä¸“é—¨çš„æœºå™¨ä»£ç ç°åœ¨æ— æ•ˆã€‚**é€€å‡ºï¼**'
- en: '**Changing Array Element Kinds -** V8 tracks the "kind" of elements in an array.
    Is it all small integers? All doubles? All objects? It optimizes based on this.
    If you have an array `[1, 2, 3]` (packed small integers, the fastest kind) and
    you suddenly push a string `arr.push(''a'')`, you''ve forced a storage transition.
    V8 dynamically upgrades the array to handle the new element type, and any optimized
    code that assumed an integer array may need to deoptimize. Not all transitions
    cause persistent slowdowns - V8 handles many efficiently - but in hot loops with
    large arrays, these transitions can impact performance.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ”¹å˜æ•°ç»„å…ƒç´ ç±»å‹ -** V8è·Ÿè¸ªæ•°ç»„ä¸­å…ƒç´ çš„â€œç±»å‹â€ã€‚å®ƒæ˜¯æ‰€æœ‰å°æ•´æ•°ï¼Ÿæ‰€æœ‰åŒç²¾åº¦æµ®ç‚¹æ•°ï¼Ÿæ‰€æœ‰å¯¹è±¡ï¼Ÿå®ƒæ ¹æ®è¿™ä¸ªæ¥ä¼˜åŒ–ã€‚å¦‚æœä½ æœ‰ä¸€ä¸ªæ‰€æœ‰å…ƒç´ éƒ½æ˜¯å°æ•´æ•°çš„æ•°ç»„
    `[1, 2, 3]`ï¼ˆæ‰“åŒ…çš„å°æ•´æ•°ï¼Œæœ€å¿«çš„ç±»å‹ï¼‰ï¼Œä½ çªç„¶æ¨å…¥ä¸€ä¸ªå­—ç¬¦ä¸² `arr.push(''a'')`ï¼Œä½ å°±å¼ºåˆ¶äº†ä¸€ä¸ªå­˜å‚¨è½¬æ¢ã€‚V8åŠ¨æ€å‡çº§æ•°ç»„ä»¥å¤„ç†æ–°çš„å…ƒç´ ç±»å‹ï¼Œä»»ä½•å‡è®¾æ•´æ•°æ•°ç»„çš„ä¼˜åŒ–ä»£ç å¯èƒ½éœ€è¦å»ä¼˜åŒ–ã€‚å¹¶éæ‰€æœ‰è½¬æ¢éƒ½ä¼šå¯¼è‡´æŒç»­çš„å‡é€Ÿ
    - V8é«˜æ•ˆåœ°å¤„ç†äº†è®¸å¤šè½¬æ¢ - ä½†åœ¨å¤§å‹æ•°ç»„çš„çƒ­ç‚¹å¾ªç¯ä¸­ï¼Œè¿™äº›è½¬æ¢å¯èƒ½ä¼šå½±å“æ€§èƒ½ã€‚'
- en: '**`try...catch` Blocks (Historical Issue) -** This was problematic in older
    V8 versions, where the machinery needed to handle exceptions could interfere with
    TurboFan''s optimizations. Modern V8 (Node v16+) has largely resolved this issue.
    In current Node versions (v22-24), `try...catch` has minimal performance impact
    in most cases. Use error handling freely for correctness â€“ the old advice to avoid
    `try...catch` is outdated.'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**`try...catch` å—ï¼ˆå†å²é—®é¢˜ï¼‰ -** åœ¨è¾ƒè€çš„V8ç‰ˆæœ¬ä¸­ï¼Œè¿™ä¸ªé—®é¢˜å¾ˆæˆé—®é¢˜ï¼Œå› ä¸ºå¤„ç†å¼‚å¸¸æ‰€éœ€çš„æœºåˆ¶å¯èƒ½ä¼šå¹²æ‰°TurboFançš„ä¼˜åŒ–ã€‚ç°ä»£V8ï¼ˆNode
    v16+ï¼‰åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚åœ¨å½“å‰çš„Nodeç‰ˆæœ¬ï¼ˆv22-24ï¼‰ä¸­ï¼Œ`try...catch`åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹å¯¹æ€§èƒ½çš„å½±å“æœ€å°ã€‚ä¸ºäº†æ­£ç¡®æ€§ï¼Œå¯ä»¥è‡ªç”±åœ°ä½¿ç”¨é”™è¯¯å¤„ç†â€”â€”é¿å…`try...catch`çš„æ—§å»ºè®®å·²ç»è¿‡æ—¶ã€‚'
- en: ğŸ’¡Tip
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡æç¤º
- en: Modern V8 (Node 16+) optimizes `try...catch` blocks reasonably well. Use them
    freely for correctness; only profile before considering refactoring out of extreme
    hot paths.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ç°ä»£V8ï¼ˆNode 16+ï¼‰å¯¹`try...catch`å—è¿›è¡Œäº†åˆç†çš„ä¼˜åŒ–ã€‚ä¸ºäº†æ­£ç¡®æ€§ï¼Œå¯ä»¥è‡ªç”±åœ°ä½¿ç”¨å®ƒä»¬ï¼›åªæœ‰åœ¨è€ƒè™‘é‡æ„å‡ºæç«¯çƒ­è·¯å¾„ä¹‹å‰ï¼Œæ‰éœ€è¦è¿›è¡Œåˆ†æã€‚
- en: '**Using `arguments` Object -** The `arguments` object is a classic deoptimizer.
    It''s an "array-like" object, but it''s not a true array and has some magic properties
    that make it difficult for compilers to reason about. Using it, especially in
    older versions of Node, was a guaranteed way to kill performance. Modern V8 is
    better, but a function that leaks `arguments` can still be problematic. Rest parameters
    (`...args`) are almost always a better, optimization-friendly choice.'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨ `arguments` å¯¹è±¡ -** `arguments` å¯¹è±¡æ˜¯ä¸€ä¸ªç»å…¸çš„å»ä¼˜åŒ–å™¨ã€‚å®ƒæ˜¯ä¸€ä¸ªâ€œç±»ä¼¼æ•°ç»„â€çš„å¯¹è±¡ï¼Œä½†å®ƒä¸æ˜¯ä¸€ä¸ªçœŸæ­£çš„æ•°ç»„ï¼Œå¹¶ä¸”æœ‰ä¸€äº›é­”æ³•å±æ€§ï¼Œè¿™ä½¿å¾—ç¼–è¯‘å™¨éš¾ä»¥æ¨ç†ã€‚ç‰¹åˆ«æ˜¯åœ¨Nodeçš„è¾ƒè€ç‰ˆæœ¬ä¸­ä½¿ç”¨å®ƒï¼Œæ˜¯ä¿è¯é™ä½æ€§èƒ½çš„ä¸€ç§æ–¹å¼ã€‚ç°ä»£V8æ›´å¥½ï¼Œä½†ä¸€ä¸ªæ³„æ¼`arguments`çš„å‡½æ•°ä»ç„¶å¯èƒ½å­˜åœ¨é—®é¢˜ã€‚å‰©ä½™å‚æ•°ï¼ˆ`...args`ï¼‰å‡ ä¹æ€»æ˜¯æ›´å¥½çš„ã€ä¼˜åŒ–å‹å¥½çš„é€‰æ‹©ã€‚'
- en: '**The `delete` Keyword -** While V8 has improved its handling of `delete` over
    the years, it still degrades performance on hot objects. Using `delete obj.x`
    can force V8 to switch the object into "dictionary mode," where properties are
    stored in a slower hash map-like structure. If you only need to clear a value
    on a hot path, use `obj.x = undefined`. However, if you need the property truly
    gone for correctness (e.g., for key enumeration or the `in` operator), `delete`
    remains the right choice â€“ just avoid it in performance-critical paths.'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**`delete` å…³é”®å­— -** è™½ç„¶V8å¤šå¹´æ¥å¯¹å…¶`delete`çš„å¤„ç†æœ‰äº†æ”¹è¿›ï¼Œä½†å®ƒä»ç„¶ä¼šé™ä½çƒ­å¯¹è±¡çš„æ€§èƒ½ã€‚ä½¿ç”¨`delete obj.x`å¯ä»¥å¼ºåˆ¶V8å°†å¯¹è±¡åˆ‡æ¢åˆ°â€œå­—å…¸æ¨¡å¼â€ï¼Œå…¶ä¸­å±æ€§å­˜å‚¨åœ¨è¾ƒæ…¢çš„ç±»ä¼¼å“ˆå¸Œè¡¨çš„ç»“æ„ä¸­ã€‚å¦‚æœä½ åªéœ€è¦åœ¨çƒ­è·¯å¾„ä¸Šæ¸…é™¤ä¸€ä¸ªå€¼ï¼Œè¯·ä½¿ç”¨`obj.x
    = undefined`ã€‚ç„¶è€Œï¼Œå¦‚æœä½ éœ€è¦å±æ€§çœŸæ­£æ¶ˆå¤±ä»¥ç¡®ä¿æ­£ç¡®æ€§ï¼ˆä¾‹å¦‚ï¼Œç”¨äºé”®æšä¸¾æˆ–`in`è¿ç®—ç¬¦ï¼‰ï¼Œåˆ™`delete`ä»ç„¶æ˜¯æ­£ç¡®çš„é€‰æ‹©â€”â€”åªæ˜¯é¿å…åœ¨æ€§èƒ½å…³é”®è·¯å¾„ä¸Šä½¿ç”¨å®ƒã€‚'
- en: ğŸ“ŒImportant
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“Œé‡è¦
- en: Avoid `delete` on hot objects, but remember that setting to `undefined` is not
    semantically equivalent. Properties set to `undefined` still exist for `Object.keys()`,
    `in` operator, and iteration.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: é¿å…åœ¨çƒ­å¯¹è±¡ä¸Šä½¿ç”¨`delete`ï¼Œä½†è¯·è®°ä½ï¼Œè®¾ç½®ä¸º`undefined`åœ¨è¯­ä¹‰ä¸Šå¹¶ä¸ç­‰ä»·ã€‚è®¾ç½®ä¸º`undefined`çš„å±æ€§ä»ç„¶å­˜åœ¨äº`Object.keys()`ã€`in`è¿ç®—ç¬¦å’Œè¿­ä»£ä¸­ã€‚
- en: Caught Off Guard by BigInt Deoptimization
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¢«BigIntå»ä¼˜åŒ–æ‰€æƒŠå“
- en: We were running a high-performance transaction simulation service for our trading
    platform. It monitored the mempool, simulating thousands of transactions per second
    to front-run profitable opportunities. The service would fire up, blazing fast,
    but over the course of an hour, its simulated TPS would drop off a cliff until
    it was missing every arbitrage window. A restart was the only cure, but the relief
    was temporary.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨ä¸ºæˆ‘ä»¬çš„äº¤æ˜“å¹³å°è¿è¡Œä¸€ä¸ªé«˜æ€§èƒ½çš„äº¤æ˜“æ¨¡æ‹ŸæœåŠ¡ã€‚å®ƒç›‘æ§ç€äº¤æ˜“æ± ï¼Œæ¯ç§’æ¨¡æ‹Ÿæ•°åƒç¬”äº¤æ˜“ä»¥æŠ¢å æœ‰åˆ©å¯å›¾çš„æœºä¼šã€‚è¯¥æœåŠ¡ä¼šè¿…é€Ÿå¯åŠ¨ï¼Œé€Ÿåº¦æå¿«ï¼Œä½†åœ¨ä¸€ä¸ªå°æ—¶å†…ï¼Œå…¶æ¨¡æ‹Ÿçš„TPSä¼šæ€¥å‰§ä¸‹é™ï¼Œç›´åˆ°é”™è¿‡äº†æ¯ä¸€ä¸ªå¥—åˆ©çª—å£ã€‚é‡å¯æ˜¯å”¯ä¸€çš„è§£å†³åŠæ³•ï¼Œä½†ç¼“è§£åªæ˜¯æš‚æ—¶çš„ã€‚
- en: 'We were burning our heads against the wall. Finally, we attached the V8 inspector
    with some flags: `node --trace-opt --trace-deopt simulator.js`. The logs were
    a torrential downpour of data, but one line screamed at us, repeated thousands
    of times:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸€ç›´åœ¨å¤´ç ´è¡€æµã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€äº›æ ‡å¿—é™„åŠ äº†V8æ£€æŸ¥å™¨ï¼š`node --trace-opt --trace-deopt simulator.js`ã€‚æ—¥å¿—å¦‚æš´é›¨èˆ¬å€¾æ³»è€Œä¸‹ï¼Œä½†æœ‰ä¸€è¡Œä¿¡æ¯å¯¹æˆ‘ä»¬å¤§å£°ç–¾å‘¼ï¼Œé‡å¤äº†æ•°åƒæ¬¡ï¼š
- en: '`[deoptimizing: begin 0x... <validateTransaction> (opt #3) at bytecode offset
    68, reason=unexpected BigInt]`'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '`[å»ä¼˜åŒ–ï¼šå¼€å§‹ 0x... <validateTransaction> (opt #3) åœ¨å­—èŠ‚ç åç§»é‡ 68ï¼ŒåŸå› =æ„å¤–çš„BigInt]`'
- en: The `validateTransaction` function - our hottest code path - was being beautifully
    optimized by TurboFan, only to be immediately thrown out. Over and over. A quick
    look at the code corresponding to that bytecode offset pointed to a line where
    we were calculating potential [slippage](https://en.wikipedia.org/wiki/Slippage_(finance))
    on a token swap amount.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`validateTransaction`å‡½æ•°â€”â€”æˆ‘ä»¬æœ€çƒ­çš„ä»£ç è·¯å¾„â€”â€”è¢«TurboFanä¼˜åŒ–å¾—éå¸¸æ¼‚äº®ï¼Œä½†éšå³è¢«ç«‹å³ä¸¢å¼ƒã€‚ä¸€æ¬¡åˆä¸€æ¬¡ã€‚å¿«é€ŸæŸ¥çœ‹å¯¹åº”äºè¯¥å­—èŠ‚ç åç§»é‡çš„ä»£ç ï¼ŒæŒ‡å‘äº†æˆ‘ä»¬è®¡ç®—ä»£å¸å…‘æ¢æ½œåœ¨[æ»‘ç‚¹](https://en.wikipedia.org/wiki/Slippage_(finance))çš„é‚£ä¸€è¡Œã€‚'
- en: The problem? The vast majority of transactions we processed - standard ETH transfers,
    small DEX swaps - had values that fit neatly into a standard JavaScript `Number`.
    But every so often, a whale would move a massive amount of a high-decimal token
    (think SHIB). Those values are so large they can **only** be represented as a
    `BigInt`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘ä»¬å¤„ç†çš„å¤§å¤šæ•°äº¤æ˜“â€”â€”æ ‡å‡†çš„ETHè½¬è´¦ã€å°å‹çš„DEXå…‘æ¢â€”â€”å…¶ä»·å€¼éƒ½èƒ½å®Œç¾åœ°é€‚åº”æ ‡å‡†çš„JavaScript `Number`ã€‚ä½†æ—¶ä¸æ—¶åœ°ï¼ŒæŸä¸ªâ€œé²¸é±¼â€ä¼šè½¬ç§»å¤§é‡é«˜ç²¾åº¦ä»£å¸ï¼ˆæ¯”å¦‚SHIBï¼‰ã€‚è¿™äº›æ•°å€¼å¦‚æ­¤ä¹‹å¤§ï¼Œåªèƒ½ç”¨`BigInt`æ¥è¡¨ç¤ºã€‚
- en: TurboFan had seen millions of `Number` types and bet the farm on it. It generated
    hyper-optimized machine code for fast, floating-point arithmetic. When the `BigInt`
    showed up, the JIT's worldview shattered. **Bailout!** The function deoptimized.
    A few thousand transactions later, V8 would try again, re-optimizing for `Number`.
    Then another whale transfer would hit. Lather, rinse, repeat.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: TurboFanå·²ç»çœ‹åˆ°äº†æ•°ç™¾ä¸‡ä¸ª`Number`ç±»å‹ï¼Œå¹¶å¯¹å…¶ä¸‹äº†é‡æ³¨ã€‚å®ƒä¸ºå¿«é€Ÿæµ®ç‚¹è¿ç®—ç”Ÿæˆäº†è¶…ä¼˜åŒ–çš„æœºå™¨ä»£ç ã€‚å½“`BigInt`å‡ºç°æ—¶ï¼ŒJITçš„ä¸–ç•Œè§‚å´©æºƒã€‚**é€€å‡ºï¼**å‡½æ•°å»ä¼˜åŒ–ã€‚å‡ åƒç¬”äº¤æ˜“åï¼ŒV8ä¼šå†æ¬¡å°è¯•ï¼Œé‡æ–°ä¼˜åŒ–ä¸º`Number`ã€‚ç„¶åå¦ä¸€ä¸ªé²¸é±¼è½¬è´¦ä¼šåˆ°æ¥ã€‚é‡å¤ä¸Šè¿°è¿‡ç¨‹ã€‚
- en: 'This is the "Deoptimization Loop of Death" in the wild:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯é‡å¤–çš„â€œå»ä¼˜åŒ–å¾ªç¯æ­»äº¡â€ï¼š
- en: '* * *'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The Fix: Enforcing Type Consistency'
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: è§£å†³æ–¹æ¡ˆï¼šå¼ºåˆ¶æ‰§è¡Œç±»å‹ä¸€è‡´æ€§
- en: Our first instinct was to normalize the data. We knew we couldn't just convert
    everything to `BigInt` and keep our floating-point math, as that would immediately
    throw a `TypeError`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç¬¬ä¸€ç›´è§‰æ˜¯æ ‡å‡†åŒ–æ•°æ®ã€‚æˆ‘ä»¬çŸ¥é“æˆ‘ä»¬ä¸èƒ½ç®€å•åœ°å°†æ‰€æœ‰å†…å®¹è½¬æ¢ä¸º`BigInt`å¹¶ä¿ç•™æµ®ç‚¹æ•°æ•°å­¦ï¼Œå› ä¸ºè¿™ä¼šç«‹å³æŠ›å‡ºä¸€ä¸ª`TypeError`ã€‚
- en: '[PRE5]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The solution had to be holistic. We chose to enforce absolute type consistency
    by treating all monetary values as scaled integers from the moment they entered
    our system. This is a common pattern in finance to avoid floating-point inaccuracies
    anyway.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å†³æ–¹æ¡ˆå¿…é¡»æ˜¯å…¨é¢çš„ã€‚æˆ‘ä»¬é€‰æ‹©é€šè¿‡å°†æ‰€æœ‰è´§å¸ä»·å€¼è§†ä¸ºä»è¿›å…¥æˆ‘ä»¬ç³»ç»Ÿçš„é‚£ä¸€åˆ»èµ·å°±ç¼©æ”¾ä¸ºæ•´æ•°çš„ç»å¯¹ç±»å‹ä¸€è‡´æ€§æ¥å¼ºåˆ¶æ‰§è¡Œã€‚è¿™æœ¬èº«å°±æ˜¯é‡‘èä¸­é¿å…æµ®ç‚¹æ•°ä¸ç²¾ç¡®çš„å¸¸è§æ¨¡å¼ã€‚
- en: '**Our Fix: Normalize to BigInt and Use Scaled Integer Math**'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆï¼šå°†æ•°æ®æ ‡å‡†åŒ–ä¸ºBigIntå¹¶ä½¿ç”¨ç¼©æ”¾æ•´æ•°æ•°å­¦**'
- en: We represented our slippage constant in basis points (1 basis point = 0.01%)
    as a `BigInt` and performed all calculations using `BigInt` arithmetic.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ»‘ç‚¹å¸¸æ•°è¡¨ç¤ºä¸ºåŸºç¡€ç‚¹ï¼ˆ1ä¸ªåŸºç‚¹=0.01%ï¼‰ä½œä¸º`BigInt`ï¼Œå¹¶ä½¿ç”¨`BigInt`ç®—æœ¯è¿›è¡Œæ‰€æœ‰è®¡ç®—ã€‚
- en: '[PRE6]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This solved the deoptimization loop completely. TurboFan now only ever saw `BigInt`s
    in this function and generated stable, optimized code for that specific type.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®Œå…¨è§£å†³äº†å»ä¼˜åŒ–å¾ªç¯ã€‚ç°åœ¨ï¼ŒTurboFanåœ¨è¿™ä¸ªå‡½æ•°ä¸­åªçœ‹åˆ°`BigInt`ï¼Œå¹¶ä¸ºè¯¥ç‰¹å®šç±»å‹ç”Ÿæˆäº†ç¨³å®šã€ä¼˜åŒ–çš„ä»£ç ã€‚
- en: Trade-offs and Alternative Fixes
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æƒè¡¡å’Œæ›¿ä»£è§£å†³æ–¹æ¡ˆ
- en: 'While our scaled-integer approach worked, it''s not the only solution, and
    it comes with a trade-off: **`BigInt`** arithmetic is generally slower than `Number`
    arithmetic for values that fit within a standard **number**. We were potentially
    slowing down 99.9% of our transactions to safely handle the 0.1% of whale transfers.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æˆ‘ä»¬çš„ç¼©æ”¾æ•´æ•°æ–¹æ³•æœ‰æ•ˆï¼Œä½†è¿™ä¸æ˜¯å”¯ä¸€çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶ä¸”å®ƒæœ‰ä¸€ä¸ªæƒè¡¡ï¼šå¯¹äºé€‚åˆæ ‡å‡†**æ•°å­—**çš„å€¼ï¼Œ`BigInt`ç®—æœ¯é€šå¸¸æ¯”`Number`ç®—æœ¯æ…¢ã€‚æˆ‘ä»¬å¯èƒ½æ­£åœ¨å‡æ…¢99.9%çš„äº¤æ˜“é€Ÿåº¦ï¼Œä»¥å®‰å…¨åœ°å¤„ç†0.1%çš„é²¸é±¼è½¬è´¦ã€‚
- en: For our specific use case, stability was worth the trade-off. However, here
    are two other powerful, practical patterns for solving this problem.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘ä»¬çš„ç‰¹å®šç”¨ä¾‹ï¼Œç¨³å®šæ€§å€¼å¾—è¿™ä¸ªæƒè¡¡ã€‚ç„¶è€Œï¼Œè¿™é‡Œè¿˜æœ‰ä¸¤ç§å…¶ä»–å¼ºå¤§ã€å®ç”¨çš„æ¨¡å¼æ¥è§£å†³æ­¤é—®é¢˜ã€‚
- en: The Dispatcher - What we decided to use
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: è°ƒåº¦å™¨â€”â€”æˆ‘ä»¬å†³å®šä½¿ç”¨
- en: This is what was - according to our team - the highest-performance solution,
    we could think of. The idea is to have two separate, specialized hot functions
    and a single "dispatcher" that routes transactions to the correct one. This keeps
    each hot path **monomorphic** (only ever seeing one type), which is exactly what
    the JIT loves.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ®æˆ‘ä»¬å›¢é˜Ÿæ‰€è¯´ï¼Œæ˜¯æˆ‘ä»¬èƒ½æƒ³åˆ°çš„æœ€é«˜æ€§èƒ½è§£å†³æ–¹æ¡ˆã€‚æƒ³æ³•æ˜¯æ‹¥æœ‰ä¸¤ä¸ªç‹¬ç«‹çš„ã€ä¸“é—¨çš„â€œçƒ­ç‚¹â€å‡½æ•°å’Œä¸€ä¸ªå•ä¸€çš„â€œè°ƒåº¦å™¨â€ï¼Œè¯¥è°ƒåº¦å™¨å°†äº¤æ˜“è·¯ç”±åˆ°æ­£ç¡®çš„å‡½æ•°ã€‚è¿™ä¿æŒäº†æ¯ä¸ªçƒ­ç‚¹è·¯å¾„**å•æ€æ€§**ï¼ˆåªçœ‹åˆ°ä¸€ç§ç±»å‹ï¼‰ï¼Œè¿™æ­£æ˜¯JITæ‰€çˆ±çš„ã€‚
- en: '[PRE7]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Alternative B: The Guarded Branch (Pragmatic Middle Ground)'
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æ›¿ä»£æ–¹æ¡ˆBï¼šå—ä¿æŠ¤çš„åˆ†æ”¯ï¼ˆå®ç”¨æŠ˜ä¸­æ–¹æ¡ˆï¼‰
- en: If you want to keep your logic in a single function, you can use an explicit
    `typeof` check. This creates two different paths within the same function. While
    this makes the function **polymorphic** (seeing multiple types), it's a clear
    signal to V8 and is often optimized well - certainly better than incurring repeated
    deopts.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³å°†ä½ çš„é€»è¾‘ä¿æŒåœ¨å•ä¸ªå‡½æ•°ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨æ˜¾å¼çš„ `typeof` æ£€æŸ¥ã€‚è¿™ä¼šåœ¨åŒä¸€ä¸ªå‡½æ•°å†…åˆ›å»ºä¸¤ä¸ªä¸åŒçš„è·¯å¾„ã€‚è™½ç„¶è¿™ä½¿å¾—å‡½æ•° **å¤šæ€**ï¼ˆçœ‹åˆ°å¤šç§ç±»å‹ï¼‰ï¼Œä½†å®ƒæ˜¯å¯¹
    V8 çš„ä¸€ä¸ªæ˜ç¡®ä¿¡å·ï¼Œå¹¶ä¸”é€šå¸¸è¢«å¾ˆå¥½åœ°ä¼˜åŒ–â€”â€”è‚¯å®šæ¯”é‡å¤ deopts ä¼˜åŒ–å¾—æ›´å¥½ã€‚
- en: '[PRE8]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: âš ï¸Warning
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸è­¦å‘Š
- en: A single function that contains both a bigint path and a number path (via typeof
    checks) is polymorphic. That's often fine - but in very hot loops it can make
    V8 generate slower, less-stable machine code than splitting those paths into two
    monomorphic functions and dispatching once up-front. Pick the dispatcher for raw
    performance in the hot path; pick the guarded-branch for simplicity when the branch
    is predictable or the path isn't super hot.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: åŒ…å« bigint è·¯å¾„å’Œæ•°å­—è·¯å¾„ï¼ˆé€šè¿‡ typeof æ£€æŸ¥ï¼‰çš„å•ä¸ªå‡½æ•°æ˜¯å¤šæ€çš„ã€‚è¿™é€šå¸¸æ²¡é—®é¢˜â€”â€”ä½†åœ¨éå¸¸çƒ­çš„å¾ªç¯ä¸­ï¼Œå®ƒå¯èƒ½ä¼šä½¿ V8 ç”Ÿæˆæ¯”å°†é‚£äº›è·¯å¾„æ‹†åˆ†ä¸ºä¸¤ä¸ªå•æ€å‡½æ•°å¹¶æå‰åˆ†å‘ä¸€æ¬¡æ›´æ…¢ã€æ›´ä¸ç¨³å®šçš„æœºå™¨ä»£ç ã€‚åœ¨çƒ­è·¯å¾„ä¸Šé€‰æ‹©æ€§èƒ½è°ƒåº¦å™¨ï¼›å½“åˆ†æ”¯å¯é¢„æµ‹æˆ–è·¯å¾„ä¸æ˜¯è¶…çº§çƒ­æ—¶ï¼Œé€‰æ‹©å—ä¿æŠ¤çš„åˆ†æ”¯ä»¥ä¿æŒç®€å•ã€‚
- en: Memory Layout and Object Representation
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å†…å­˜å¸ƒå±€å’Œå¯¹è±¡è¡¨ç¤º
- en: To truly understand V8 performance, you have to go one level deeper and think
    about how your JavaScript values are actually laid out in your computer's memory.
    This isn't just academic; it has direct performance implications.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: è¦çœŸæ­£ç†è§£ V8 çš„æ€§èƒ½ï¼Œä½ å¿…é¡»å†æ·±å…¥ä¸€å±‚ï¼Œæ€è€ƒä½ çš„ JavaScript å€¼å®é™…ä¸Šæ˜¯å¦‚ä½•åœ¨ä½ çš„è®¡ç®—æœºå†…å­˜ä¸­å¸ƒå±€çš„ã€‚è¿™ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå­¦æœ¯é—®é¢˜ï¼›å®ƒæœ‰ç›´æ¥çš„æ€§èƒ½å½±å“ã€‚
- en: V8 uses a clever trick called pointer tagging to distinguish between immediate
    values (like small integers) and pointers to objects on the heap. While a 64-bit
    system uses 64-bit machine words, V8's default pointer compression optimization
    means that these tagged values are often stored in compact 32-bit slots on the
    heap to save memory.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: V8 ä½¿ç”¨ä¸€ä¸ªç§°ä¸ºæŒ‡é’ˆæ ‡è®°çš„å·§å¦™æŠ€å·§æ¥åŒºåˆ†ç«‹å³å€¼ï¼ˆå¦‚å°æ•´æ•°ï¼‰å’Œå †ä¸Šå¯¹è±¡çš„æŒ‡é’ˆã€‚è™½ç„¶ 64 ä½ç³»ç»Ÿä½¿ç”¨ 64 ä½æœºå™¨å­—ï¼Œä½† V8 çš„é»˜è®¤æŒ‡é’ˆå‹ç¼©ä¼˜åŒ–æ„å‘³ç€è¿™äº›æ ‡è®°å€¼é€šå¸¸å­˜å‚¨åœ¨å †ä¸Šçš„ç´§å‡‘
    32 ä½æ§½ä¸­ï¼Œä»¥èŠ‚çœå†…å­˜ã€‚
- en: Small Integers (SMI)
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å°æ•´æ•°ï¼ˆSMIï¼‰
- en: If the last bit of a 64-bit word is a `0`, V8 knows the remaining bits represent
    a **Small Integer**, or **Smi**. This is an incredibly important optimization.
    On 64-bit builds with pointer compression (the default), Smis are 31-bit signed
    integers, giving a range of approximately -1 billion to +1 billion. V8 doesn't
    need to allocate any extra memory on the heap for these values. The number *is*
    the pointer.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ 64 ä½å­—çš„æœ€æœ«ä½æ˜¯ `0`ï¼ŒV8 å°±çŸ¥é“å‰©ä½™çš„ä½è¡¨ç¤ºä¸€ä¸ª **Small Integer**ï¼Œæˆ– **Smi**ã€‚è¿™æ˜¯ä¸€ä¸ªæå…¶é‡è¦çš„ä¼˜åŒ–ã€‚åœ¨å…·æœ‰æŒ‡é’ˆå‹ç¼©ï¼ˆé»˜è®¤ï¼‰çš„
    64 ä½æ„å»ºä¸­ï¼ŒSmi æ˜¯ 31 ä½æœ‰ç¬¦å·æ•´æ•°ï¼ŒèŒƒå›´å¤§çº¦ä¸º -1 äº¿åˆ° +1 äº¿ã€‚V8 ä¸éœ€è¦åœ¨å †ä¸Šä¸ºè¿™äº›å€¼åˆ†é…ä»»ä½•é¢å¤–çš„å†…å­˜ã€‚è¿™ä¸ªæ•°å­— *å°±æ˜¯* æŒ‡é’ˆã€‚
- en: â„¹ï¸Note
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: On 64-bit builds with pointer compression, Smis are 31-bit signed integers.
    On 32-bit builds, the range is slightly different. Always assume ~Â±1 billion as
    the safe range, not full 32-bit.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å…·æœ‰æŒ‡é’ˆå‹ç¼©çš„ 64 ä½æ„å»ºä¸­ï¼ŒSmi æ˜¯ 31 ä½æœ‰ç¬¦å·æ•´æ•°ã€‚åœ¨ 32 ä½æ„å»ºä¸­ï¼ŒèŒƒå›´ç•¥æœ‰ä¸åŒã€‚å§‹ç»ˆå‡è®¾ ~Â±1 äº¿ä¸ºå®‰å…¨èŒƒå›´ï¼Œè€Œä¸æ˜¯å®Œæ•´çš„ 32
    ä½ã€‚
- en: Arithmetic on Smis is lightning fast. The CPU's integer arithmetic logic unit
    (ALU) can operate on them directly. This is why `for` loops with integer counters
    are so much faster than loops dealing with floating-point numbers or objects.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Smi çš„ç®—æœ¯è¿ç®—éå¸¸å¿«ã€‚CPU çš„æ•´æ•°ç®—æœ¯é€»è¾‘å•å…ƒï¼ˆALUï¼‰å¯ä»¥ç›´æ¥æ“ä½œå®ƒä»¬ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½¿ç”¨æ•´æ•°è®¡æ•°å™¨çš„ `for` å¾ªç¯æ¯”å¤„ç†æµ®ç‚¹æ•°æˆ–å¯¹è±¡çš„å¾ªç¯è¦å¿«å¾—å¤šã€‚
- en: 'A 64-bit word representing a Smi (e.g., the number 5):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ç¤º Smiï¼ˆä¾‹å¦‚ï¼Œæ•°å­— 5ï¼‰çš„ 64 ä½å­—ï¼š
- en: Heap Objects
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å †å¯¹è±¡
- en: So, what happens when that special tag bit is a `1`? This signals that the word
    isn't the value itself, but a **pointer** - a memory address that references the
    actual data's location on the V8 heap.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œå½“é‚£ä¸ªç‰¹æ®Šçš„æ ‡ç­¾ä½æ˜¯ `1` æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿè¿™è¡¨ç¤ºè¯¥å­—ä¸æ˜¯å€¼æœ¬èº«ï¼Œè€Œæ˜¯ä¸€ä¸ª **æŒ‡é’ˆ**â€”â€”ä¸€ä¸ªå¼•ç”¨ V8 å †ä¸Šå®é™…æ•°æ®ä½ç½®çš„å†…å­˜åœ°å€ã€‚
- en: 'This is how V8 handles all the complex data that can''t be represented as a
    Smi: from strings and arrays to objects, and even numbers with decimal points.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ V8 å¤„ç†æ‰€æœ‰æ— æ³•è¡¨ç¤ºä¸º Smi çš„å¤æ‚æ•°æ®çš„æ–¹å¼ï¼šä»å­—ç¬¦ä¸²å’Œæ•°ç»„åˆ°å¯¹è±¡ï¼Œç”šè‡³å¸¦æœ‰å°æ•°ç‚¹çš„æ•°å­—ã€‚
- en: To keep its memory usage low, V8 uses a fantastic optimization by default called
    **pointer compression**. This means that even on a 64-bit system, these pointers
    are often stored in compact **32-bit** slots.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä¿æŒå…¶å†…å­˜ä½¿ç”¨é‡ä½ï¼ŒV8 é»˜è®¤ä½¿ç”¨ä¸€ä¸ªç§°ä¸º **æŒ‡é’ˆå‹ç¼©** çš„å‡ºè‰²ä¼˜åŒ–ã€‚è¿™æ„å‘³ç€å³ä½¿åœ¨ 64 ä½ç³»ç»Ÿä¸Šï¼Œè¿™äº›æŒ‡é’ˆé€šå¸¸ä¹Ÿå­˜å‚¨åœ¨ç´§å‡‘çš„ **32 ä½**æ§½ä¸­ã€‚
- en: 'Here''s a simplified look at a tagged pointer in V8''s memory-saving mode:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ V8 å†…å­˜èŠ‚çœæ¨¡å¼ä¸‹æ ‡ç­¾æŒ‡é’ˆçš„ç®€åŒ–è§†å›¾ï¼š
- en: Let's take a number like `const a = 3.14;`. In the classic sense, V8 would handle
    this by creating a `HeapNumber` object, which involves a few steps -
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»¥ä¸€ä¸ªæ•°å­—`const a = 3.14;`ä¸ºä¾‹ã€‚åœ¨ç»å…¸æ„ä¹‰ä¸Šï¼ŒV8ä¼šé€šè¿‡åˆ›å»ºä¸€ä¸ª`HeapNumber`å¯¹è±¡æ¥å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œè¿™æ¶‰åŠå‡ ä¸ªæ­¥éª¤ -
- en: First, it allocates a small chunk of memory on the heap.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œå®ƒåœ¨å †ä¸Šåˆ†é…ä¸€å°å—å†…å­˜ã€‚
- en: Then, it writes the floating-point representation of `3.14` into that memory.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå®ƒå°†`3.14`çš„æµ®ç‚¹è¡¨ç¤ºå†™å…¥é‚£ä¸ªå†…å­˜ã€‚
- en: Finally, it stores a tagged pointer to that new location in the variable `a`.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå®ƒå°†æŒ‡å‘é‚£ä¸ªæ–°ä½ç½®çš„æ ‡è®°æŒ‡é’ˆå­˜å‚¨åœ¨å˜é‡`a`ä¸­ã€‚
- en: But this is where the story gets exciting. The V8 team has spent years optimizing
    this process, and modern V8 has some amazing tricks up its sleeve to avoid that
    heap trip for frequently executed code -
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™æ­£æ˜¯æ•…äº‹å˜å¾—ç²¾å½©çš„åœ°æ–¹ã€‚V8å›¢é˜Ÿå·²ç»èŠ±è´¹å¤šå¹´ä¼˜åŒ–è¿™ä¸ªè¿‡ç¨‹ï¼Œç°ä»£V8æœ‰ä¸€äº›æƒŠäººçš„æŠ€å·§æ¥é¿å…é¢‘ç¹æ‰§è¡Œä»£ç çš„å †ä¹‹æ—… -
- en: '**Unboxing -** V8 can store a number''s raw value directly inside another object''s
    memory, avoiding the need to allocate a separate `HeapNumber` object.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è§£åŒ…** - V8å¯ä»¥ç›´æ¥åœ¨å¦ä¸€ä¸ªå¯¹è±¡çš„å†…å­˜ä¸­å­˜å‚¨æ•°å­—çš„åŸå§‹å€¼ï¼Œä»è€Œé¿å…åˆ†é…å•ç‹¬çš„`HeapNumber`å¯¹è±¡çš„éœ€è¦ã€‚'
- en: '**Escape Analysis -** If a number is created and used only within a single
    function and never "escapes" to an outer scope, V8 is smart enough to avoid heap
    allocation altogether.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é€ƒé€¸åˆ†æ** - å¦‚æœä¸€ä¸ªæ•°å­—ä»…åœ¨ä¸€ä¸ªå‡½æ•°å†…éƒ¨åˆ›å»ºå’Œä½¿ç”¨ï¼Œå¹¶ä¸”ä»æœªâ€œé€ƒé€¸â€åˆ°å¤–éƒ¨ä½œç”¨åŸŸï¼ŒV8è¶³å¤Ÿæ™ºèƒ½ï¼Œå¯ä»¥å®Œå…¨é¿å…å †åˆ†é…ã€‚'
- en: So, while there's a performance cost when heap allocation *does* occur (it requires
    managing memory and following pointers), all thanks to V8's incredible engineering
    that this happens far less often than you might think.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè™½ç„¶å †åˆ†é…ç¡®å®ä¼šäº§ç”Ÿæ€§èƒ½æˆæœ¬ï¼ˆéœ€è¦ç®¡ç†å†…å­˜å’Œè·Ÿè¸ªæŒ‡é’ˆï¼‰ï¼Œä½†å¤šäºäº†V8çš„æƒŠäººå·¥ç¨‹ï¼Œè¿™ç§æƒ…å†µå‘ç”Ÿçš„é¢‘ç‡æ¯”ä½ æƒ³è±¡çš„è¦ä½å¾—å¤šã€‚
- en: Object Layout in Memory
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å†…å­˜ä¸­çš„å¯¹è±¡å¸ƒå±€
- en: When an object is created, V8 allocates memory for it on the heap. This memory
    block contains 1) a pointer to its **hidden class**. This is the first and most
    important field and 2) space for its properties.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: å½“åˆ›å»ºå¯¹è±¡æ—¶ï¼ŒV8åœ¨å †ä¸Šä¸ºå…¶åˆ†é…å†…å­˜ã€‚è¿™ä¸ªå†…å­˜å—åŒ…å«1)æŒ‡å‘å…¶**éšè—ç±»**çš„æŒ‡é’ˆã€‚è¿™æ˜¯ç¬¬ä¸€ä¸ªä¹Ÿæ˜¯æœ€é‡è¦çš„å­—æ®µï¼Œ2)å…¶å±æ€§çš„ç©ºé—´ã€‚
- en: For objects with "fast properties" (i.e., not in dictionary mode), the properties
    are stored directly inside the object's memory block at fixed offsets determined
    by the hidden class.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå…·æœ‰â€œå¿«é€Ÿå±æ€§â€çš„å¯¹è±¡ï¼ˆå³ä¸åœ¨å­—å…¸æ¨¡å¼ä¸­ï¼‰ï¼Œå±æ€§ç›´æ¥å­˜å‚¨åœ¨å¯¹è±¡çš„å†…å­˜å—ä¸­ï¼Œåç§»é‡ç”±éšè—ç±»ç¡®å®šã€‚
- en: 'Let''s imagine our `Point` object: `const p = { x: 1, y: 2 }`. Its memory might
    look like this -'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®©æˆ‘ä»¬æƒ³è±¡æˆ‘ä»¬çš„`Point`å¯¹è±¡ï¼š`const p = { x: 1, y: 2 }`ã€‚å®ƒçš„å†…å­˜å¯èƒ½çœ‹èµ·æ¥åƒè¿™æ · -'
- en: When TurboFan optimizes `p.y`, it gets the hidden class from `p`, sees it's
    `C2`, knows from `C2` that `y` is at offset +8 bytes (for example), and generates
    machine code to just read the memory at `[address of p + 8]`. No hash map lookups.
    No string comparisons. Just raw, fast memory access.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: å½“TurboFanä¼˜åŒ–`p.y`æ—¶ï¼Œå®ƒä¼šä»`p`ä¸­è·å–éšè—ç±»ï¼Œçœ‹åˆ°å®ƒæ˜¯`C2`ï¼Œå¹¶ä»`C2`çŸ¥é“`y`ä½äºåç§»é‡+8å­—èŠ‚ï¼ˆä¾‹å¦‚ï¼‰çš„ä½ç½®ï¼Œç„¶åç”Ÿæˆæœºå™¨ä»£ç æ¥ç›´æ¥è¯»å–`[påœ°å€
    + 8]`å¤„çš„å†…å­˜ã€‚æ²¡æœ‰å“ˆå¸Œè¡¨æŸ¥æ‰¾ã€‚æ²¡æœ‰å­—ç¬¦ä¸²æ¯”è¾ƒã€‚åªæ˜¯ç›´æ¥çš„ã€å¿«é€Ÿçš„å†…å­˜è®¿é—®ã€‚
- en: String Internalization
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å­—ç¬¦ä¸²å†…åŒ–
- en: 'Strings are another area with a clever optimization. When you have the same
    string literal multiple times in your code, like `''success''`, V8 only stores
    it in memory once. This is called **string internalization** or "interning." All
    variables pointing to that string literal will point to the same memory address.
    This saves memory and makes string comparisons much faster: V8 can just compare
    the pointers (a single CPU instruction) instead of comparing the strings character
    by character.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: å­—ç¬¦ä¸²æ˜¯å¦ä¸€ä¸ªæœ‰å·§å¦™ä¼˜åŒ–çš„é¢†åŸŸã€‚å½“ä½ çš„ä»£ç ä¸­å¤šæ¬¡å‡ºç°ç›¸åŒçš„å­—ç¬¦ä¸²å­—é¢é‡ï¼Œæ¯”å¦‚`'success'`ï¼ŒV8åªä¼šå°†å…¶å­˜å‚¨åœ¨å†…å­˜ä¸­ä¸€æ¬¡ã€‚è¿™è¢«ç§°ä¸º**å­—ç¬¦ä¸²å†…åŒ–**æˆ–â€œå†…éƒ¨åŒ–â€ã€‚æ‰€æœ‰æŒ‡å‘è¯¥å­—ç¬¦ä¸²å­—é¢é‡çš„å˜é‡éƒ½å°†æŒ‡å‘ç›¸åŒçš„å†…å­˜åœ°å€ã€‚è¿™èŠ‚çœäº†å†…å­˜ï¼Œå¹¶ä½¿å­—ç¬¦ä¸²æ¯”è¾ƒå˜å¾—æ›´å¿«ï¼šV8åªéœ€æ¯”è¾ƒæŒ‡é’ˆï¼ˆä¸€ä¸ªCPUæŒ‡ä»¤ï¼‰è€Œä¸æ˜¯é€å­—ç¬¦æ¯”è¾ƒå­—ç¬¦ä¸²ã€‚
- en: 'Here''s how string internalization works in memory:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å­—ç¬¦ä¸²å†…åŒ–åœ¨å†…å­˜ä¸­çš„å·¥ä½œæ–¹å¼ï¼š
- en: Understanding this memory model helps explain many V8 performance characteristics
    -
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£è¿™ä¸ªå†…å­˜æ¨¡å‹æœ‰åŠ©äºè§£é‡Šè®¸å¤šV8çš„æ€§èƒ½ç‰¹æ€§ -
- en: '**Why integer math is fast?** Smis avoid heap allocation and indirection.'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¸ºä»€ä¹ˆæ•´æ•°è¿ç®—å¿«ï¼Ÿ** Smisé¿å…å †åˆ†é…å’Œé—´æ¥å¼•ç”¨ã€‚'
- en: '**Why hidden classes are key?** They enable fixed-offset property access.'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¸ºä»€ä¹ˆéšè—ç±»å¾ˆé‡è¦ï¼Ÿ** å®ƒä»¬ä½¿å¾—å›ºå®šåç§»é‡å±æ€§è®¿é—®æˆä¸ºå¯èƒ½ã€‚'
- en: '**Why `delete` is slow?** It forces a change from this clean, array-like property
    storage to a complex, slow dictionary-based one.'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¸ºä»€ä¹ˆ`delete`æ“ä½œæ…¢ï¼Ÿ** å®ƒè¿«ä½¿ä»è¿™ç§å¹²å‡€ã€ç±»ä¼¼æ•°ç»„çš„å±æ€§å­˜å‚¨æ–¹å¼è½¬å˜ä¸ºå¤æ‚ã€ç¼“æ…¢çš„åŸºäºå­—å…¸çš„æ–¹å¼ã€‚'
- en: Common Performance Cliffs
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¸¸è§æ€§èƒ½æ‚¬å´–
- en: After seeing hundreds of production performance issues, you start to see the
    same patterns over and over. These are the common cliffs that developers, even
    senior ones, fall off when they don't understand the engine.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çœ‹åˆ°æ•°ç™¾ä¸ªç”Ÿäº§æ€§èƒ½é—®é¢˜ä¹‹åï¼Œä½ å¼€å§‹ä¸€æ¬¡åˆä¸€æ¬¡åœ°çœ‹åˆ°ç›¸åŒçš„æ¨¡å¼ã€‚è¿™äº›æ˜¯å¼€å‘è€…ï¼Œå³ä½¿æ˜¯é«˜çº§å¼€å‘è€…ï¼Œåœ¨ä¸äº†è§£å¼•æ“çš„æƒ…å†µä¸‹å®¹æ˜“æ‰å…¥çš„å¸¸è§é™·é˜±ã€‚
- en: 'Cliff #1: Unstable Object Shapes (Hidden Class Explosions)'
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Cliff #1: ä¸ç¨³å®šçš„å¯¹è±¡å½¢çŠ¶ï¼ˆéšè—ç±»çˆ†ç‚¸ï¼‰'
- en: This is the big one we saw in our recent discussion. Any code that creates objects
    with different property orders, different total properties, or conditional properties
    is a minefield.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬æœ€è¿‘è®¨è®ºä¸­çœ‹åˆ°çš„å¤§é—®é¢˜ã€‚ä»»ä½•åˆ›å»ºå…·æœ‰ä¸åŒå±æ€§é¡ºåºã€ä¸åŒæ€»å±æ€§æˆ–æ¡ä»¶å±æ€§çš„å¯¹è±¡çš„ä»£ç éƒ½æ˜¯ä¸€ä¸ªé›·åŒºã€‚
- en: '**Symptom -** Code that processes objects is mysteriously slow. Flame graphs
    are wide and flat, with no single hot function.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç—‡çŠ¶ -** å¤„ç†å¯¹è±¡çš„ä»£ç ç¥ç§˜åœ°å˜æ…¢ã€‚ç«ç„°å›¾å®½è€Œå¹³ï¼Œæ²¡æœ‰å•ä¸ªçƒ­ç‚¹å‡½æ•°ã€‚'
- en: '**Cause?** Megamorphic inline caches due to an explosion of hidden classes.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åŸå› ï¼Ÿ** ç”±äºéšè—ç±»çš„çˆ†ç‚¸ï¼Œå·¨å½¢æ€å†…è”ç¼“å­˜ã€‚'
- en: '[PRE9]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Cliff #2: Polymorphic and Megamorphic Functions'
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Cliff #2: å¤šæ€å’Œå·¨å½¢æ€å‡½æ•°'
- en: Functions that are designed to handle many different types of inputs are an
    enemy of the JIT compiler.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: è®¾è®¡ç”¨äºå¤„ç†å¤šç§ä¸åŒç±»å‹è¾“å…¥çš„å‡½æ•°æ˜¯ JIT ç¼–è¯‘å™¨çš„æ•Œäººã€‚
- en: '**Symptom -** A specific utility function or event handler is a bottleneck.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç—‡çŠ¶ -** ç‰¹å®šçš„å®ç”¨å‡½æ•°æˆ–äº‹ä»¶å¤„ç†å™¨æ˜¯ç“¶é¢ˆã€‚'
- en: '**Cause?** An IC at a property access or function call site has become polymorphic
    or megamorphic.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åŸå› ï¼Ÿ** åœ¨å±æ€§è®¿é—®æˆ–å‡½æ•°è°ƒç”¨ä½ç½®ä¸Šçš„ IC å˜æˆäº†å¤šæ€æˆ–å·¨å½¢æ€ã€‚'
- en: '[PRE11]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Cliff #3: Using `delete` on Objects'
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Cliff #3: åœ¨å¯¹è±¡ä¸Šä½¿ç”¨ `delete`'
- en: We built a simple in-memory caching layer for our Node.js service. It was just
    a big JavaScript object. When an item expired, we'd remove it from the cache using
    `delete cache[key]`. Simple, right? I've also posted about this on [Reddit](https://www.reddit.com/r/webdev/comments/1n23rbi/i_stopped_deleting_and_my_hot_paths_calmed_down/)
    in case you're interested.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ºæˆ‘ä»¬çš„ Node.js æœåŠ¡æ„å»ºäº†ä¸€ä¸ªç®€å•çš„å†…å­˜ç¼“å­˜å±‚ã€‚å®ƒåªæ˜¯ä¸€ä¸ªå¤§å‹çš„ JavaScript å¯¹è±¡ã€‚å½“ä¸€ä¸ªé¡¹ç›®è¿‡æœŸæ—¶ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ `delete
    cache[key]` ä»ç¼“å­˜ä¸­åˆ é™¤å®ƒã€‚å¾ˆç®€å•ï¼Œå¯¹å§ï¼Ÿæˆ‘è¿˜åœ¨ [Reddit](https://www.reddit.com/r/webdev/comments/1n23rbi/i_stopped_deleting_and_my_hot_paths_calmed_down/)
    ä¸Šå‘äº†ä¸€ç¯‡å…³äºè¿™ä¸ªè¯é¢˜çš„æ–‡ç« ï¼Œä»¥é˜²ä½ æ„Ÿå…´è¶£ã€‚
- en: The service throughput was disappointing, about 35-40% of what we expected.
    Profiling showed a huge amount of time being spent inside property access functions
    for the cache object. The flame graph was dominated by dictionary lookups and
    megamorphic inline cache misses.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: æœåŠ¡çš„ååé‡ä»¤äººå¤±æœ›ï¼Œå¤§çº¦åªæœ‰æˆ‘ä»¬é¢„æœŸçš„ 35-40%ã€‚åˆ†ææ˜¾ç¤ºï¼Œå¤§é‡æ—¶é—´è¢«èŠ±è´¹åœ¨ç¼“å­˜å¯¹è±¡çš„å±æ€§è®¿é—®å‡½æ•°ä¸­ã€‚ç«ç„°å›¾ä¸»è¦ç”±å­—å…¸æŸ¥æ‰¾å’Œå·¨å½¢æ€å†…è”ç¼“å­˜ç¼ºå¤±ä¸»å¯¼ã€‚
- en: The problem was `delete`. When you use `delete`, you are not just removing a
    property. You are fundamentally changing the object's structure in a way that
    V8 cannot optimize with a simple hidden class transition. Using `delete` forces
    V8 to switch the object's properties into **Dictionary Mode**. In this mode, the
    properties are stored in a slower, hash map-like data structure. Every single
    property access on that object, *even for keys you didn't delete*, now becomes
    a slow dictionary lookup. Our entire cache object was kneecapped.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜åœ¨äº `delete`ã€‚å½“ä½ ä½¿ç”¨ `delete` æ—¶ï¼Œä½ ä¸ä»…ä»…æ˜¯åˆ é™¤ä¸€ä¸ªå±æ€§ã€‚ä½ ä»æ ¹æœ¬ä¸Šæ”¹å˜äº†å¯¹è±¡çš„ç»“æ„ï¼ŒV8 æ— æ³•é€šè¿‡ç®€å•çš„éšè—ç±»è½¬æ¢æ¥ä¼˜åŒ–ã€‚ä½¿ç”¨
    `delete` å¼ºåˆ¶ V8 å°†å¯¹è±¡çš„å±æ€§åˆ‡æ¢åˆ° **å­—å…¸æ¨¡å¼**ã€‚åœ¨è¿™ç§æ¨¡å¼ä¸‹ï¼Œå±æ€§å­˜å‚¨åœ¨ä¸€ä¸ªè¾ƒæ…¢çš„ã€ç±»ä¼¼å“ˆå¸Œè¡¨çš„æ•°æ®ç»“æ„ä¸­ã€‚è¯¥å¯¹è±¡ä¸Šæ¯ä¸ªå±æ€§è®¿é—®ï¼Œ*å³ä½¿æ˜¯æœªåˆ é™¤çš„é”®*ï¼Œç°åœ¨éƒ½å˜æˆäº†æ…¢é€Ÿçš„å­—å…¸æŸ¥æ‰¾ã€‚æˆ‘ä»¬çš„æ•´ä¸ªç¼“å­˜å¯¹è±¡å—åˆ°äº†å‰Šå¼±ã€‚
- en: The fix? **Never use `delete` on hot objects.** Instead, set the property to
    `undefined`.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å†³æ–¹æ¡ˆï¼Ÿ**æ°¸è¿œä¸è¦åœ¨çƒ­ç‚¹å¯¹è±¡ä¸Šä½¿ç”¨ `delete`ã€‚ç›¸åï¼Œå°†å±æ€§è®¾ç½®ä¸º `undefined`**ã€‚
- en: '[PRE13]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Assigning `undefined` preserves the hidden class and keeps the object in "fast
    mode." Our throughput instantly jumped by 3-4x after we replaced all `delete`
    calls with assignments to `undefined`.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: å°† `undefined` åˆ†é…ç»™å˜é‡å¯ä»¥ä¿ç•™éšè—ç±»å¹¶ä¿æŒå¯¹è±¡å¤„äºâ€œå¿«é€Ÿæ¨¡å¼â€ã€‚åœ¨æˆ‘ä»¬å°†æ‰€æœ‰ `delete` è°ƒç”¨æ›¿æ¢ä¸ºå¯¹ `undefined` çš„èµ‹å€¼åï¼Œæˆ‘ä»¬çš„ååé‡ç«‹å³æé«˜äº†
    3-4 å€ã€‚
- en: 'Cliff #4: Mixing Element Kinds in Arrays'
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Cliff #4: åœ¨æ•°ç»„ä¸­æ··åˆå…ƒç´ ç§ç±»'
- en: 'V8 optimizes arrays heavily based on their contents and dynamically upgrades
    between element kinds:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: V8 æ ¹æ®å…¶å†…å®¹å¯¹æ•°ç»„è¿›è¡Œå¤§é‡ä¼˜åŒ–ï¼Œå¹¶åœ¨å…ƒç´ ç§ç±»ä¹‹é—´åŠ¨æ€å‡çº§ï¼š
- en: '`PACKED_SMI_ELEMENTS` - The fastest. A contiguous block of memory holding only
    small integers.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PACKED_SMI_ELEMENTS` - æœ€å¿«çš„ã€‚åªåŒ…å«å°æ•´æ•°çš„å†…å­˜è¿ç»­å—ã€‚'
- en: '`PACKED_DOUBLE_ELEMENTS` - Still fast. A contiguous block of doubles.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PACKED_DOUBLE_ELEMENTS` - ä»ç„¶å¾ˆå¿«ã€‚è¿ç»­çš„åŒç²¾åº¦æµ®ç‚¹æ•°å—ã€‚'
- en: '`PACKED_ELEMENTS` - A contiguous block of pointers to heap objects.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PACKED_ELEMENTS` - æŒ‡å‘å †å¯¹è±¡çš„æŒ‡é’ˆçš„è¿ç»­å—ã€‚'
- en: '`HOLEY_ELEMENTS` - An array with empty slots (e.g., `const a = [1, , 3]`).
    Slower, because V8 has to check for holes.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HOLEY_ELEMENTS` - å…·æœ‰ç©ºæ§½çš„æ•°ç»„ï¼ˆä¾‹å¦‚ï¼Œ`const a = [1, , 3]`ï¼‰ã€‚è¾ƒæ…¢ï¼Œå› ä¸º V8 å¿…é¡»æ£€æŸ¥ç©ºæ§½ã€‚'
- en: '`DICTIONARY_ELEMENTS` - The slowest. The array is basically a hash map.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DICTIONARY_ELEMENTS` - æœ€æ…¢çš„ã€‚æ•°ç»„åŸºæœ¬ä¸Šæ˜¯ä¸€ä¸ªå“ˆå¸Œè¡¨ã€‚'
- en: If you start with `[1, 2, 3]` and then `push('hello')`, V8 has to convert the
    entire underlying storage from `PACKED_SMI_ELEMENTS` to `PACKED_ELEMENTS`. This
    transition is one-way and affects performance primarily in hot loops where the
    array is accessed repeatedly. For most everyday array usage, V8 handles these
    transitions efficiently, but in performance-critical numeric computations or when
    processing large datasets, maintaining stable element kinds can provide significant
    benefits.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä» `[1, 2, 3]` å¼€å§‹ï¼Œç„¶å `push('hello')`ï¼ŒV8 å¿…é¡»å°†æ•´ä¸ªåº•å±‚å­˜å‚¨ä» `PACKED_SMI_ELEMENTS` è½¬æ¢ä¸º
    `PACKED_ELEMENTS`ã€‚è¿™ç§è½¬æ¢æ˜¯å•å‘çš„ï¼Œä¸»è¦å½±å“åœ¨æ•°ç»„è¢«é‡å¤è®¿é—®çš„çƒ­ç‚¹å¾ªç¯ä¸­çš„æ€§èƒ½ã€‚å¯¹äºå¤§å¤šæ•°æ—¥å¸¸æ•°ç»„ä½¿ç”¨ï¼ŒV8 é«˜æ•ˆåœ°å¤„ç†è¿™äº›è½¬æ¢ï¼Œä½†åœ¨æ€§èƒ½å…³é”®çš„æ•°å€¼è®¡ç®—æˆ–å¤„ç†å¤§æ•°æ®é›†æ—¶ï¼Œä¿æŒç¨³å®šçš„å…ƒç´ ç±»å‹å¯ä»¥æä¾›æ˜¾è‘—çš„å¥½å¤„ã€‚
- en: ğŸ“ŒImportant
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“Œé‡è¦
- en: Mixing element kinds forces storage transitions, which can hurt performance
    in hot loops. For most everyday use, the impact is negligible, but in tight numeric
    loops or large datasets, stable element kinds matter.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: æ··åˆå…ƒç´ ç±»å‹ä¼šå¼ºåˆ¶è¿›è¡Œå­˜å‚¨è½¬æ¢ï¼Œè¿™å¯èƒ½ä¼šåœ¨çƒ­ç‚¹å¾ªç¯ä¸­æŸå®³æ€§èƒ½ã€‚å¯¹äºå¤§å¤šæ•°æ—¥å¸¸ä½¿ç”¨ï¼Œè¿™ç§å½±å“å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œä½†åœ¨ç´§å¯†çš„æ•°å€¼å¾ªç¯æˆ–å¤§æ•°æ®é›†ä¸­ï¼Œç¨³å®šçš„å…ƒç´ ç±»å‹å¾ˆé‡è¦ã€‚
- en: Patterns that work
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„æ¨¡å¼
- en: So how do we stay in V8's good graces? By writing boring, predictable, monomorphic
    code. It might feel less "clever," but it will be orders of magnitude faster.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•ä¿æŒ V8 çš„å¥½æ„Ÿï¼Ÿé€šè¿‡ç¼–å†™æ— èŠã€å¯é¢„æµ‹ã€å•æ€çš„ä»£ç ã€‚è¿™å¯èƒ½æ„Ÿè§‰ä¸é‚£ä¹ˆâ€œèªæ˜â€ï¼Œä½†å®ƒå°†å¿«å¾—å¤šã€‚
- en: The V8-Friendly Code Pattern
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V8 å‹å¥½çš„ä»£ç æ¨¡å¼
- en: Here's a blueprint for a performance-critical data structure and the function
    that processes it.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæ€§èƒ½å…³é”®æ•°æ®ç»“æ„å’Œå¤„ç†å®ƒçš„å‡½æ•°çš„è“å›¾ã€‚
- en: '[PRE14]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Optimization Strategy: A Checklist'
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¼˜åŒ–ç­–ç•¥ï¼šæ£€æŸ¥æ¸…å•
- en: 'Before you even think about changing code, follow this process:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä½ è€ƒè™‘æ›´æ”¹ä»£ç ä¹‹å‰ï¼Œéµå¾ªä»¥ä¸‹æµç¨‹ï¼š
- en: Don't guess. Use `--prof` or the Chrome DevTools inspector to find your actual
    hot paths. Optimizing code that only runs 0.1% of the time is a waste of effort.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸è¦çŒœæµ‹ã€‚ä½¿ç”¨ `--prof` æˆ– Chrome DevTools æ£€æŸ¥å™¨æ¥æ‰¾åˆ°ä½ çš„å®é™…çƒ­ç‚¹è·¯å¾„ã€‚ä¼˜åŒ–åªè¿è¡Œ 0.1% æ—¶é—´çš„ä»£ç æ˜¯å¾’åŠ³çš„ã€‚
- en: Zoom in on the 1-3 functions that consume the most CPU. This is where your focus
    should be - "identifying the hot paths".
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸“æ³¨äºæ¶ˆè€—æœ€å¤š CPU çš„ 1-3 ä¸ªå‡½æ•°ã€‚è¿™å°±æ˜¯ä½ åº”è¯¥å…³æ³¨çš„ç„¦ç‚¹â€”â€”â€œè¯†åˆ«çƒ­ç‚¹è·¯å¾„â€ã€‚
- en: For each hot function, analyze the data it receives. Are the object shapes consistent?
    Are array element kinds stable? Use `console.log(%HaveSameMap(a, b))` to verify.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªçƒ­ç‚¹å‡½æ•°ï¼Œåˆ†æå®ƒæ¥æ”¶åˆ°çš„æ•°æ®ã€‚å¯¹è±¡å½¢çŠ¶æ˜¯å¦ä¸€è‡´ï¼Ÿæ•°ç»„å…ƒç´ ç±»å‹æ˜¯å¦ç¨³å®šï¼Ÿä½¿ç”¨ `console.log(%HaveSameMap(a, b))`
    æ¥éªŒè¯ã€‚
- en: Run your hot path in a tight loop with `--trace-deopt` and `grep` for your function's
    name. Look at the reasons V8 gives for bailing out.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `--trace-deopt` å’Œ `grep` æŸ¥æ‰¾ä½ çš„å‡½æ•°åç§°ï¼Œåœ¨ç´§å¯†å¾ªç¯ä¸­è¿è¡Œä½ çš„çƒ­ç‚¹è·¯å¾„ã€‚æŸ¥çœ‹ V8 æä¾›çš„é€€å‡ºåŸå› ã€‚
- en: Refactor your code for predictability -
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡æ–°æ„å»ºä½ çš„ä»£ç ä»¥å®ç°å¯é¢„æµ‹æ€§ -
- en: Initialize objects with all properties (`null` or `undefined` is fine).
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ‰€æœ‰å±æ€§ï¼ˆ`null` æˆ– `undefined` æ˜¯å¯ä»¥çš„ï¼‰åˆå§‹åŒ–å¯¹è±¡ã€‚
- en: Use constructors or factory functions to enforce a single creation path.
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ„é€ å‡½æ•°æˆ–å·¥å‚å‡½æ•°æ¥å¼ºåˆ¶æ‰§è¡Œå•ä¸ªåˆ›å»ºè·¯å¾„ã€‚
- en: If a function needs to handle different shapes, split it into multiple, monomorphic
    functions.
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä¸€ä¸ªå‡½æ•°éœ€è¦å¤„ç†ä¸åŒçš„å½¢çŠ¶ï¼Œå°†å…¶æ‹†åˆ†ä¸ºå¤šä¸ªå•æ€å‡½æ•°ã€‚
- en: Replace `delete` with `obj.prop = undefined`.
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°† `delete` æ›¿æ¢ä¸º `obj.prop = undefined`ã€‚
- en: Avoid mixing element kinds in performance-critical arrays.
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…åœ¨æ€§èƒ½å…³é”®æ•°ç»„ä¸­æ··åˆå…ƒç´ ç±»å‹ã€‚
- en: After refactoring, run the profiler again. Did the change work? Is the time
    spent in that function lower?
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‡æ„åï¼Œå†æ¬¡è¿è¡Œåˆ†æå™¨ã€‚å˜åŒ–æ˜¯å¦æœ‰æ•ˆï¼Ÿåœ¨è¯¥å‡½æ•°ä¸­èŠ±è´¹çš„æ—¶é—´æ˜¯å¦é™ä½ï¼Ÿ
- en: V8 Flags and Runtime Options
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V8 æ ‡å¿—å’Œè¿è¡Œæ—¶é€‰é¡¹
- en: The Node.js runtime provides a powerful set of V8 flags that let you tune, debug,
    and examine the engine's behavior. You can list all available flags for your version
    of Node with `node --v8-options`. Here are some of the most critical ones for
    performance engineering.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js è¿è¡Œæ—¶æä¾›äº†ä¸€ç»„å¼ºå¤§çš„ V8 æ ‡å¿—ï¼Œå…è®¸ä½ è°ƒæ•´ã€è°ƒè¯•å’Œæ£€æŸ¥å¼•æ“çš„è¡Œä¸ºã€‚ä½ å¯ä»¥ä½¿ç”¨ `node --v8-options` åˆ—å‡ºä½  Node.js
    ç‰ˆæœ¬çš„æ‰€æœ‰å¯ç”¨æ ‡å¿—ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¯¹æ€§èƒ½å·¥ç¨‹æœ€å…³é”®çš„æ ‡å¿—ã€‚
- en: Informational Flags
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¿¡æ¯æ€§æ ‡å¿—
- en: These flags don't change behavior but provide a stream of diagnostic information.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ ‡å¿—ä¸ä¼šæ”¹å˜è¡Œä¸ºï¼Œä½†æä¾›äº†ä¸€ä¸²è¯Šæ–­ä¿¡æ¯ã€‚
- en: '`--trace-opt`: As mentioned, this logs every function that the optimizing compilers
    (Sparkplug, Maglev, TurboFan) successfully optimize. It''s great for confirming
    that your hot paths are actually being compiled.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--trace-opt`ï¼šå¦‚å‰æ‰€è¿°ï¼Œå®ƒä¼šè®°å½•ä¼˜åŒ–ç¼–è¯‘å™¨ï¼ˆSparkplugã€Maglevã€TurboFanï¼‰æˆåŠŸä¼˜åŒ–çš„æ¯ä¸ªå‡½æ•°ã€‚è¿™å¯¹äºç¡®è®¤ä½ çš„çƒ­ç‚¹è·¯å¾„å®é™…ä¸Šæ­£åœ¨è¢«ç¼–è¯‘éå¸¸æœ‰ç”¨ã€‚'
- en: '`--trace-deopt`: Logs every deoptimization, including the function name, bytecode
    offset, and the reason. This is arguably the most important performance debugging
    flag.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--trace-deopt`: è®°å½•æ¯æ¬¡å»ä¼˜åŒ–ï¼ŒåŒ…æ‹¬å‡½æ•°åã€å­—èŠ‚ç åç§»å’ŒåŸå› ã€‚è¿™å¯èƒ½æ˜¯æœ€é‡è¦çš„æ€§èƒ½è°ƒè¯•æ ‡å¿—ã€‚'
- en: '`--trace-ic`: Shows the state transitions of Inline Caches. Useful for diagnosing
    polymorphic and megamorphic call sites. You can see a property access go from
    `1` (monomorphic) to `P` (polymorphic) to `N` (megamorphic).'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--trace-ic`: æ˜¾ç¤ºå†…è”ç¼“å­˜çš„å·è½¬æ¢ã€‚å¯¹äºè¯Šæ–­å¤šæ€å’Œå·¨å½¢æ€è°ƒç”¨ç‚¹éå¸¸æœ‰ç”¨ã€‚ä½ å¯ä»¥çœ‹åˆ°å±æ€§è®¿é—®ä»`1`ï¼ˆå•æ€ï¼‰å˜ä¸º`P`ï¼ˆå¤šæ€ï¼‰åˆ°`N`ï¼ˆå·¨å½¢æ€ï¼‰ã€‚'
- en: '`--trace-gc`: Prints a log line for every garbage collection event, showing
    how much memory was collected and how long it took. Useful for diagnosing memory
    pressure and GC pauses.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--trace-gc`: ä¸ºæ¯æ¬¡åƒåœ¾å›æ”¶äº‹ä»¶æ‰“å°ä¸€æ¡æ—¥å¿—è¡Œï¼Œæ˜¾ç¤ºæ”¶é›†äº†å¤šå°‘å†…å­˜ä»¥åŠèŠ±è´¹äº†å¤šé•¿æ—¶é—´ã€‚å¯¹äºè¯Šæ–­å†…å­˜å‹åŠ›å’ŒGCæš‚åœéå¸¸æœ‰ç”¨ã€‚'
- en: Behavioral Flags
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¡Œä¸ºæ ‡å¿—
- en: These flags can alter how V8 optimizes and executes code. Use with caution.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ ‡å¿—å¯ä»¥æ”¹å˜V8ä¼˜åŒ–å’Œæ‰§è¡Œä»£ç çš„æ–¹å¼ã€‚ä½¿ç”¨æ—¶è¯·è°¨æ…ã€‚
- en: '`--allow-natives-syntax`: Exposes the `%` functions for scripting V8''s internals.
    Helpful for detailed analysis and benchmarking, but never for production.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--allow-natives-syntax`: æä¾›äº†`%`å‡½æ•°æ¥è„šæœ¬åŒ–V8çš„å†…éƒ¨ç»“æ„ã€‚å¯¹äºè¯¦ç»†åˆ†æå’ŒåŸºå‡†æµ‹è¯•å¾ˆæœ‰å¸®åŠ©ï¼Œä½†ç»ä¸åº”è¯¥ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚'
- en: '`--optimize-for-size`: Asks V8 to be more conservative with optimizations to
    reduce the memory footprint of compiled code. This can be useful in low-memory
    environments.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--optimize-for-size`: è¯·æ±‚V8åœ¨ä¼˜åŒ–æ—¶æ›´åŠ ä¿å®ˆï¼Œä»¥å‡å°‘ç¼–è¯‘ä»£ç çš„å†…å­˜å ç”¨ã€‚è¿™åœ¨å†…å­˜å—é™çš„ç¯å¢ƒä¸­éå¸¸æœ‰ç”¨ã€‚'
- en: '`--max-old-space-size=<megabytes>`: Sets the maximum size of the old generation
    heap. Increasing this can reduce GC frequency for memory-intensive applications,
    but also lead to longer GC pauses when they do occur.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--max-old-space-size=<megabytes>`: è®¾ç½®æ—§ç”Ÿä»£å †çš„æœ€å¤§å¤§å°ã€‚å¢åŠ è¿™ä¸ªå€¼å¯ä»¥å‡å°‘å†…å­˜å¯†é›†å‹åº”ç”¨ç¨‹åºçš„GCé¢‘ç‡ï¼Œä½†ä¹Ÿä¼šå¯¼è‡´GCå‘ç”Ÿæ—¶çš„æš‚åœæ—¶é—´æ›´é•¿ã€‚'
- en: '`--jitless`: This is an interesting one. It completely disables the JIT (Sparkplug,
    Maglev, TurboFan). Your code will only ever be run by the Ignition interpreter.
    This provides better security (by preventing runtime code generation) at a significant
    performance cost. It''s useful for establishing a "baseline" performance to see
    how much the optimizing compilers are actually helping.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--jitless`: è¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„é€‰æ‹©ã€‚å®ƒå®Œå…¨ç¦ç”¨äº†JITï¼ˆSparkplugã€Maglevã€TurboFanï¼‰ã€‚ä½ çš„ä»£ç å°†åªç”±Ignitionè§£é‡Šå™¨è¿è¡Œã€‚è¿™æä¾›äº†æ›´å¥½çš„å®‰å…¨æ€§ï¼ˆé€šè¿‡é˜²æ­¢è¿è¡Œæ—¶ä»£ç ç”Ÿæˆï¼‰ï¼Œä½†ä¼šä»¥æ˜¾è‘—çš„æ€§èƒ½æˆæœ¬ä¸ºä»£ä»·ã€‚è¿™å¯¹äºå»ºç«‹â€œåŸºçº¿â€æ€§èƒ½ä»¥æŸ¥çœ‹ä¼˜åŒ–ç¼–è¯‘å™¨å®é™…å¸®åŠ©äº†å¤šå°‘éå¸¸æœ‰ç”¨ã€‚'
- en: How to Use Flags
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä½¿ç”¨æ ‡å¿—
- en: 'You pass these flags to the `node` executable before your script name: `node
    --trace-deopt --max-old-space-size=4096 my_app.js`'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åœ¨è„šæœ¬åç§°ä¹‹å‰ä¼ é€’è¿™äº›æ ‡å¿—ç»™`node`å¯æ‰§è¡Œæ–‡ä»¶ï¼š`node --trace-deopt --max-old-space-size=4096 my_app.js`
- en: 'You can also set them via the `NODE_OPTIONS` environment variable, which is
    often more convenient for development environments or CI/CD pipelines: `export
    NODE_OPTIONS="--trace-deopt --max-old-space-size=4096"` `node my_app.js`'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥é€šè¿‡`NODE_OPTIONS`ç¯å¢ƒå˜é‡æ¥è®¾ç½®å®ƒä»¬ï¼Œè¿™å¯¹äºå¼€å‘ç¯å¢ƒæˆ–CI/CDç®¡é“é€šå¸¸æ›´æ–¹ä¾¿ï¼š`export NODE_OPTIONS="--trace-deopt
    --max-old-space-size=4096"` `node my_app.js`
- en: Knowing how to use these flags is like having a diagnostic toolkit for the engine.
    When performance goes wrong, you're no longer guessing; you can ask V8 directly
    what's happening.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: äº†è§£å¦‚ä½•ä½¿ç”¨è¿™äº›æ ‡å¿—å°±åƒæ‹¥æœ‰äº†ä¸€ä¸ªé’ˆå¯¹å¼•æ“çš„è¯Šæ–­å·¥å…·åŒ…ã€‚å½“æ€§èƒ½å‡ºç°é—®é¢˜æ—¶ï¼Œä½ ä¸å†éœ€è¦çŒœæµ‹ï¼›ä½ å¯ä»¥ç›´æ¥è¯¢é—®V8å‘ç”Ÿäº†ä»€ä¹ˆã€‚
- en: From Full-Codegen to TurboFan
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»å…¨ä»£ç ç”Ÿæˆåˆ°TurboFan
- en: The V8 architecture we've discussed - the 4-tier pipeline with Ignition, Sparkplug,
    Maglev, and TurboFan - is the result of years of evolution. To appreciate its
    design, it's helpful to understand what came before it.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¨è®ºè¿‡çš„V8æ¶æ„â€”â€”åŒ…å«Ignitionã€Sparkplugã€Maglevå’ŒTurboFançš„4å±‚ç®¡é“â€”â€”æ˜¯å¤šå¹´æ¼”åŒ–çš„ç»“æœã€‚è¦æ¬£èµå…¶è®¾è®¡ï¼Œäº†è§£å…¶å‰èº«æ˜¯æœ‰å¸®åŠ©çš„ã€‚
- en: For many years, V8's pipeline consisted of two main components -
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šå¹´æ¥ï¼ŒV8çš„ç®¡é“ç”±ä¸¤ä¸ªä¸»è¦ç»„ä»¶ç»„æˆ -
- en: '**Full-Codegen -** A simple, non-optimizing compiler. Its job was to take JavaScript
    and produce machine code as quickly as possible. It was fast to compile but produced
    slow machine code. It was the "good enough for now" compiler.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '**Full-Codegen -** ä¸€ä¸ªç®€å•ã€éä¼˜åŒ–çš„ç¼–è¯‘å™¨ã€‚å…¶ä»»åŠ¡æ˜¯å°½å¯èƒ½å¿«åœ°å°†JavaScriptè½¬æ¢ä¸ºæœºå™¨ä»£ç ã€‚å®ƒç¼–è¯‘é€Ÿåº¦å¿«ï¼Œä½†ç”Ÿæˆçš„æœºå™¨ä»£ç è¾ƒæ…¢ã€‚å®ƒæ˜¯â€œç°åœ¨è¶³å¤Ÿå¥½â€çš„ç¼–è¯‘å™¨ã€‚'
- en: '**Crankshaft -** The optimizing compiler. Like TurboFan, Crankshaft would take
    hot functions and re-compile them into highly optimized machine code. It used
    a technique called **Static Single Assignment (SSA)** form and had a sophisticated
    optimization pipeline.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**Crankshaft -** ä¼˜åŒ–ç¼–è¯‘å™¨ã€‚ä¸TurboFanç±»ä¼¼ï¼ŒCrankshaftä¼šå°†çƒ­å‡½æ•°é‡æ–°ç¼–è¯‘æˆé«˜åº¦ä¼˜åŒ–çš„æœºå™¨ä»£ç ã€‚å®ƒä½¿ç”¨äº†ä¸€ç§ç§°ä¸º**é™æ€å•èµ‹å€¼ï¼ˆSSAï¼‰**çš„å½¢å¼ï¼Œå¹¶å…·æœ‰å¤æ‚çš„ä¼˜åŒ–æµç¨‹ã€‚'
- en: 'However, this architecture had several problems:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ä¸ªæ¶æ„æœ‰å‡ ä¸ªé—®é¢˜ï¼š
- en: There was a huge performance gap between the code produced by Full-Codegen and
    Crankshaft. Your code was either slow or very fast, with little in between.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Full-Codegenå’ŒCrankshaftç”Ÿæˆçš„ä»£ç ä¹‹é—´æœ‰å¾ˆå¤§çš„æ€§èƒ½å·®è·ã€‚ä½ çš„ä»£ç è¦ä¹ˆå¾ˆæ…¢ï¼Œè¦ä¹ˆéå¸¸å¿«ï¼Œä¸­é—´å¾ˆå°‘æœ‰ã€‚
- en: Deoptimization (or "bailout" as it was(is) often called) from Crankshaft was
    a complex and slow process.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»Crankshaftï¼ˆæˆ–å¸¸è¢«ç§°ä¸ºâ€œé€€å‡ºâ€çš„è¿‡ç¨‹ï¼‰ä¸­é€€åŒ–çš„è¿‡ç¨‹æ˜¯å¤æ‚ä¸”ç¼“æ…¢çš„ã€‚
- en: Full-Codegen generated a lot of machine code, and the Crankshaft pipeline itself
    was memory-intensive.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Full-Codegenç”Ÿæˆäº†å¤§é‡çš„æœºå™¨ä»£ç ï¼Œè€ŒCrankshaftæµæ°´çº¿æœ¬èº«ä¹Ÿç›¸å½“æ¶ˆè€—å†…å­˜ã€‚
- en: The two compilers didn't share much code. Adding new language features often
    meant implementing them twice, in two different ways.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªç¼–è¯‘å™¨å…±äº«çš„ä»£ç ä¸å¤šã€‚æ·»åŠ æ–°çš„è¯­è¨€ç‰¹æ€§é€šå¸¸æ„å‘³ç€ä»¥ä¸¤ç§ä¸åŒçš„æ–¹å¼å®ç°å®ƒä»¬ä¸¤æ¬¡ã€‚
- en: 'The New Pipeline: Ignition and TurboFan (and later Sparkplug and Maglev)'
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ–°çš„æµæ°´çº¿ï¼šIgnitionå’ŒTurboFanï¼ˆä»¥åŠåæ¥çš„Sparkplugå’ŒMaglevï¼‰
- en: The V8 team undertook a massive project to re-architect the engine from the
    ground up. This resulted in the modern pipeline -
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: V8å›¢é˜Ÿæ‰¿æ‹…äº†ä¸€ä¸ªåºå¤§çš„é¡¹ç›®ï¼Œä»åº•å±‚é‡æ–°æ¶æ„å¼•æ“ã€‚è¿™å¯¼è‡´äº†ç°ä»£çš„æµæ°´çº¿ -
- en: '**Ignition (Interpreter) -** The team realized that for much of the web and
    Node.js applications, compiling to machine code upfront (even with Full-Codegen)
    was overkill. An interpreter that generates and runs bytecode would have a much
    lower memory footprint and faster startup time. This was a key insight: **bytecode
    is often better than unoptimized machine code**. The memory savings were substantial,
    especially on mobile devices.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ignitionï¼ˆè§£é‡Šå™¨ï¼‰-** å›¢é˜Ÿæ„è¯†åˆ°ï¼Œå¯¹äºè®¸å¤šWebå’ŒNode.jsåº”ç”¨ç¨‹åºï¼Œé¢„å…ˆç¼–è¯‘æˆæœºå™¨ä»£ç ï¼ˆå³ä½¿æ˜¯Full-Codegenï¼‰éƒ½æ˜¯è¿‡åº¦è¡Œä¸ºã€‚ä¸€ä¸ªç”Ÿæˆå’Œè¿è¡Œå­—èŠ‚ç çš„è§£é‡Šå™¨å°†å…·æœ‰æ›´ä½çš„å†…å­˜å ç”¨å’Œæ›´å¿«çš„å¯åŠ¨æ—¶é—´ã€‚è¿™æ˜¯ä¸€ä¸ªå…³é”®çš„æ´å¯Ÿï¼š**å­—èŠ‚ç é€šå¸¸æ¯”æœªä¼˜åŒ–çš„æœºå™¨ä»£ç æ›´å¥½**ã€‚å†…å­˜èŠ‚çœæ˜¯æ˜¾è‘—çš„ï¼Œå°¤å…¶æ˜¯åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šã€‚'
- en: '**TurboFan (Compiler) -** TurboFan was designed from the start to be a more
    advanced and flexible optimizing compiler.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '**TurboFanï¼ˆç¼–è¯‘å™¨ï¼‰-** TurboFanä»ä¸€å¼€å§‹å°±è¢«è®¾è®¡æˆä¸€ä¸ªæ›´å…ˆè¿›å’Œçµæ´»çš„ä¼˜åŒ–ç¼–è¯‘å™¨ã€‚'
- en: It has a cleaner architecture based on the "sea of nodes" graph representation.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæœ‰ä¸€ä¸ªåŸºäºâ€œèŠ‚ç‚¹æµ·æ´‹â€å›¾è¡¨ç¤ºçš„æ›´æ¸…æ™°çš„æ¶æ„ã€‚
- en: It was designed to optimize not just JavaScript, but also WebAssembly and other
    languages.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ—¨åœ¨ä¼˜åŒ–ä¸ä»…ä»…æ˜¯JavaScriptï¼Œè¿˜åŒ…æ‹¬WebAssemblyå’Œå…¶ä»–è¯­è¨€ã€‚
- en: It has a much better-defined "tiering" model. The path from Ignition to TurboFan
    is smoother, and deoptimization is less catastrophic.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæœ‰ä¸€ä¸ªå®šä¹‰å¾—æ›´å¥½çš„â€œåˆ†å±‚â€æ¨¡å‹ã€‚ä»Ignitionåˆ°TurboFançš„è·¯å¾„æ›´å¹³æ»‘ï¼Œé€€åŒ–è¿‡ç¨‹ä¸é‚£ä¹ˆç¾éš¾æ€§ã€‚
- en: It can handle constructs like `try...catch` and `with` much more gracefully
    than Crankshaft ever could.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒå¯ä»¥æ¯”Crankshaftæ›´ä¼˜é›…åœ°å¤„ç†åƒ`try...catch`å’Œ`with`è¿™æ ·çš„ç»“æ„ã€‚
- en: '**Sparkplug (2021) -** Added as a baseline compiler to smooth the transition
    between interpreter and optimizer.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sparkplugï¼ˆ2021ï¼‰-** ä½œä¸ºåŸºå‡†ç¼–è¯‘å™¨æ·»åŠ ï¼Œä»¥å¹³æ»‘è§£é‡Šå™¨å’Œä¼˜åŒ–å™¨ä¹‹é—´çš„è¿‡æ¸¡ã€‚'
- en: '**Maglev (2023) -** The latest addition, providing a mid-tier optimization
    level that balances compilation speed with code quality. This new pipeline, which
    evolved from V8 v5.9 (2017) through to the current 4-tier system, provided significant
    real-world benefits that we talked about in this chapter.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '**Maglevï¼ˆ2023ï¼‰-** æœ€æ–°åŠ å…¥çš„ï¼Œæä¾›äº†ä¸€ç§å¹³è¡¡ç¼–è¯‘é€Ÿåº¦å’Œä»£ç è´¨é‡çš„ä¸­é—´å±‚ä¼˜åŒ–çº§åˆ«ã€‚è¿™ä¸ªä»V8 v5.9ï¼ˆ2017ï¼‰åˆ°å½“å‰4å±‚ç³»ç»Ÿçš„æ¼”å˜ï¼Œæä¾›äº†æˆ‘ä»¬åœ¨æœ¬ç« ä¸­è®¨è®ºçš„æ˜¾è‘—çš„å®é™…å¥½å¤„ã€‚'
- en: Here's how the architecture evolved -
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ¶æ„æ¼”å˜çš„è¿‡ç¨‹ -
- en: This history clears up another myth.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ®µå†å²æ¾„æ¸…äº†å¦ä¸€ä¸ªç¥è¯ã€‚
- en: 'Myth 3: "Modern V8 optimizes everything"'
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¥è¯3ï¼šâ€œç°ä»£V8ä¼˜åŒ–ä¸€åˆ‡â€
- en: Not even close. V8 doesn't *want* to optimize everything. Optimization is expensive.
    The entire design of the modern Ignition/Sparkplug/Maglev/TurboFan pipeline is
    based on the idea of **tiered compilation**. It does the absolute minimum work
    required to get your code running (Ignition) and only spends CPU cycles on optimizing
    the small percentage of your code that is actually performance-critical. Your
    job is to make that small percentage of code easy for the optimizing compilers
    to understand and optimize.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: å·®å¾—è¿œã€‚V8å¹¶ä¸æƒ³ä¼˜åŒ–ä¸€åˆ‡ã€‚ä¼˜åŒ–æ˜¯æ˜‚è´µçš„ã€‚ç°ä»£Ignition/Sparkplug/Maglev/TurboFanæµæ°´çº¿çš„æ•´ä¸ªè®¾è®¡åŸºäº**åˆ†å±‚ç¼–è¯‘**çš„ç†å¿µã€‚å®ƒåªåšå¿…è¦çš„æœ€å°å·¥ä½œæ¥è¿è¡Œä½ çš„ä»£ç ï¼ˆIgnitionï¼‰ï¼Œå¹¶ä¸”åªå°†CPUå‘¨æœŸç”¨äºä¼˜åŒ–é‚£äº›çœŸæ­£æ€§èƒ½å…³é”®çš„å°éƒ¨åˆ†ä»£ç ã€‚ä½ çš„ä»»åŠ¡æ˜¯è®©è¿™éƒ¨åˆ†ä»£ç æ˜“äºä¼˜åŒ–ç¼–è¯‘å™¨ç†è§£å’Œä¼˜åŒ–ã€‚
- en: Best practices for V8 performance
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V8æ€§èƒ½çš„æœ€ä½³å®è·µ
- en: This is the actionable summary. If you're in a performance review and need a
    checklist, this is it.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¯æ“ä½œçš„æ€»ç»“ã€‚å¦‚æœä½ æ­£åœ¨è¿›è¡Œæ€§èƒ½å®¡æŸ¥å¹¶éœ€è¦ä¸€ä¸ªæ¸…å•ï¼Œè¿™å°±æ˜¯å®ƒã€‚
- en: '**DO''s -**'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**DO''s -**'
- en: Use constructors, classes, or factory functions to ensure objects have the same
    hidden class. Initialize all members, even with `null` or `undefined`.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ„é€ å‡½æ•°ã€ç±»æˆ–å·¥å‚å‡½æ•°ç¡®ä¿å¯¹è±¡å…·æœ‰ç›¸åŒçš„éšè—ç±»ã€‚åˆå§‹åŒ–æ‰€æœ‰æˆå‘˜ï¼Œå³ä½¿æ˜¯ `null` æˆ– `undefined`ã€‚
- en: Write functions that operate on a single, predictable object shape (monomorphic).
    If you must handle multiple shapes, consider breaking the function into smaller,
    monomorphic ones.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼–å†™æ“ä½œå•ä¸€ã€å¯é¢„æµ‹å¯¹è±¡å½¢çŠ¶ï¼ˆå•å½¢ï¼‰çš„å‡½æ•°ã€‚å¦‚æœæ‚¨å¿…é¡»å¤„ç†å¤šä¸ªå½¢çŠ¶ï¼Œè€ƒè™‘å°†å‡½æ•°åˆ†è§£æˆæ›´å°çš„ã€å•å½¢çš„å‡½æ•°ã€‚
- en: Leverage the fast path for Small Integers (Smis) whenever possible.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°½å¯èƒ½åˆ©ç”¨å°æ•´æ•°ï¼ˆSmisï¼‰çš„å¿«é€Ÿè·¯å¾„ã€‚
- en: Don't guess where your bottlenecks are. Use `node --prof` or the Chrome Inspector
    to find them.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸è¦çŒœæµ‹ç“¶é¢ˆåœ¨å“ªé‡Œã€‚ä½¿ç”¨ `node --prof` æˆ– Chrome æ£€æŸ¥å™¨æ¥æŸ¥æ‰¾å®ƒä»¬ã€‚
- en: Use `--trace-deopt` to find and fix deoptimization loops.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `--trace-deopt` æ¥æŸ¥æ‰¾å’Œä¿®å¤å»ä¼˜åŒ–å¾ªç¯ã€‚
- en: Clever, dynamic code is often the enemy of the JIT compiler. Simple, straightforward
    code is easier for V8 to optimize.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: èªæ˜ã€åŠ¨æ€çš„ä»£ç é€šå¸¸æ˜¯ JIT ç¼–è¯‘å™¨çš„æ•Œäººã€‚ç®€å•ã€ç›´æ¥çš„ä»£ç æ›´å®¹æ˜“è¢« V8 ä¼˜åŒ–ã€‚
- en: '**DON''Ts -**'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¸è¦åšçš„äº‹æƒ… -**'
- en: Never use `delete` on objects in a hot path. Set properties to `undefined` instead.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ°¸è¿œä¸è¦åœ¨çƒ­ç‚¹è·¯å¾„ä¸Šçš„å¯¹è±¡ä¸Šä½¿ç”¨ `delete`ã€‚å°†å±æ€§è®¾ç½®ä¸º `undefined`ã€‚
- en: Avoid writing functions where arguments can be one of many different shapes
    or types.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…ç¼–å†™å‚æ•°å¯ä»¥æ˜¯å¤šç§ä¸åŒå½¢çŠ¶æˆ–ç±»å‹çš„å‡½æ•°ã€‚
- en: Avoid adding properties to objects after they've been created.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¿å…åœ¨å¯¹è±¡åˆ›å»ºåæ·»åŠ å±æ€§ã€‚
- en: '**Don''t use the `arguments` object.** Use rest parameters (`...args`) instead.
    They are fully optimizable.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸è¦ä½¿ç”¨ `arguments` å¯¹è±¡ã€‚** ä½¿ç”¨å‰©ä½™å‚æ•°ï¼ˆ`...args`ï¼‰ä»£æ›¿ã€‚å®ƒä»¬æ˜¯å®Œå…¨å¯ä¼˜åŒ–çš„ã€‚'
- en: '**Don''t `eval` or use `with` statements.** These are black boxes for the compiler
    and kill performance.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸è¦ä½¿ç”¨ `eval` æˆ– `with` è¯­å¥ã€‚** è¿™äº›å¯¹ç¼–è¯‘å™¨æ¥è¯´æ˜¯é»‘ç›’ï¼Œä¼šé™ä½æ€§èƒ½ã€‚'
- en: '**Don''t ignore deoptimizations.** A deopt in a hot function is a critical
    performance bug.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸è¦å¿½ç•¥å»ä¼˜åŒ–ã€‚** çƒ­å‡½æ•°ä¸­çš„å»ä¼˜åŒ–æ˜¯ä¸€ä¸ªå…³é”®çš„æ€§èƒ½é”™è¯¯ã€‚'
- en: A checklist you can keep handy
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥éšæ—¶æºå¸¦çš„æ¸…å•
- en: Do my critical data objects have consistent, stable shapes?
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘çš„ä¸´ç•Œæ•°æ®å¯¹è±¡æ˜¯å¦æœ‰ä¸€è‡´ã€ç¨³å®šçš„å½¢çŠ¶ï¼Ÿ
- en: Are my performance-critical functions monomorphic?
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘çš„æ€§èƒ½å…³é”®å‡½æ•°æ˜¯å¦æ˜¯å•å½¢çš„ï¼Ÿ
- en: Have I run `--trace-deopt` on my hot paths to check for optimization bailouts?
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯å¦åœ¨æˆ‘çš„çƒ­ç‚¹è·¯å¾„ä¸Šè¿è¡Œäº† `--trace-deopt` ä»¥æ£€æŸ¥ä¼˜åŒ–é€€å‡ºï¼Ÿ
- en: Have I profiled my application under load to confirm where the bottlenecks are?
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯å¦åœ¨è´Ÿè½½ä¸‹å¯¹åº”ç”¨ç¨‹åºè¿›è¡Œäº†æ€§èƒ½åˆ†æï¼Œä»¥ç¡®è®¤ç“¶é¢ˆåœ¨å“ªé‡Œï¼Ÿ
- en: Is the memory layout of my objects and arrays as efficient as possible (e.g.,
    avoiding holes, using Smis)?
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘çš„å¯¹è±¡å’Œæ•°ç»„çš„å†…å­˜å¸ƒå±€æ˜¯å¦å°½å¯èƒ½é«˜æ•ˆï¼ˆä¾‹å¦‚ï¼Œé¿å…ç©ºéš™ï¼Œä½¿ç”¨ Smisï¼‰ï¼Ÿ
- en: Have I measured the "before" and "after" to confirm my optimizations had a positive
    impact?
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯å¦æµ‹é‡äº†â€œä¹‹å‰â€å’Œâ€œä¹‹åâ€ï¼Œä»¥ç¡®è®¤æˆ‘çš„ä¼˜åŒ–äº§ç”Ÿäº†ç§¯æçš„å½±å“ï¼Ÿ
- en: 'Appendix: V8 profiling commands'
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•ï¼šV8 æ€§èƒ½åˆ†æå‘½ä»¤
- en: A quick reference for the commands you'll use most often.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨æœ€å¸¸ä½¿ç”¨çš„å‘½ä»¤çš„å¿«é€Ÿå‚è€ƒã€‚
- en: '**Basic CPU Profiling:**'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '**åŸºæœ¬ CPU æ€§èƒ½åˆ†æï¼š**'
- en: '[PRE15]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Remote Debugging & Profiling with Chrome DevTools:**'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨ Chrome å¼€å‘è€…å·¥å…·è¿›è¡Œè¿œç¨‹è°ƒè¯•å’Œæ€§èƒ½åˆ†æï¼š**'
- en: '[PRE16]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Then open `chrome://inspect` in your Chrome browser.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨æ‚¨çš„ Chrome æµè§ˆå™¨ä¸­æ‰“å¼€ `chrome://inspect`ã€‚
- en: '**Tracing JIT Compiler Behavior:**'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '**è·Ÿè¸ª JIT ç¼–è¯‘å™¨è¡Œä¸ºï¼š**'
- en: '[PRE17]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '**Using V8 Intrinsics for Benchmarking/Debugging:**'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨ V8 å†…ç½®å‡½æ•°è¿›è¡ŒåŸºå‡†æµ‹è¯•/è°ƒè¯•ï¼š**'
- en: '[PRE18]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Common intrinsics: `%HaveSameMap(obj1, obj2)`, `%GetOptimizationStatus(func)`,
    `%OptimizeFunctionOnNextCall(func)`.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¸è§å†…ç½®å‡½æ•°ï¼š%HaveSameMap(obj1, obj2)ï¼Œ%GetOptimizationStatus(func)ï¼Œ%OptimizeFunctionOnNextCall(func)ã€‚
- en: '* * *'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Closing - thinking like V8
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…³é—­ - æ€è€ƒåƒ V8 ä¸€æ ·
- en: 'We started this journey with a mystery: a simple line of code causing a 100x
    slowdown. The solution wasn''t a clever algorithm or a complex refactor. It''s
    about peeking under the hood to see what really makes your JavaScript go *vroom*.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼€å§‹è¿™æ®µæ—…ç¨‹æ—¶å¸¦ç€ä¸€ä¸ªè°œå›¢ï¼šä¸€è¡Œç®€å•çš„ä»£ç å¯¼è‡´æ€§èƒ½é™ä½äº† 100 å€ã€‚è§£å†³æ–¹æ¡ˆä¸æ˜¯ä¸€ç§å·§å¦™çš„ç®—æ³•æˆ–å¤æ‚çš„é‡æ„ã€‚è¿™æ˜¯å…³äºæ­å¼€ç›–å­ï¼Œçœ‹çœ‹çœŸæ­£è®©æ‚¨çš„ JavaScript
    å‘åŠ¨èµ·æ¥çš„åŸå› ã€‚
- en: 'The biggest shift you can make as a Node.js developer is to stop seeing V8
    as an unpredictable black box. It''s not. It''s a highly opinionated, deterministic
    system. It has strong preferences: it likes stable object shapes, it likes monomorphic
    functions, it likes integer arithmetic, and it hates unpredictability.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸º Node.js å¼€å‘è€…ï¼Œæ‚¨å¯ä»¥åšå‡ºçš„æœ€å¤§è½¬å˜æ˜¯åœæ­¢å°† V8 è§†ä¸ºä¸€ä¸ªä¸å¯é¢„æµ‹çš„é»‘ç›’ã€‚å®ƒä¸æ˜¯ã€‚å®ƒæ˜¯ä¸€ä¸ªé«˜åº¦æœ‰æ„è§ã€ç¡®å®šæ€§çš„ç³»ç»Ÿã€‚å®ƒæœ‰å¼ºçƒˆçš„åå¥½ï¼šå®ƒå–œæ¬¢ç¨³å®šçš„å¯¹è±¡å½¢çŠ¶ï¼Œå®ƒå–œæ¬¢å•å½¢å‡½æ•°ï¼Œå®ƒå–œæ¬¢æ•´æ•°è¿ç®—ï¼Œå®ƒè®¨åŒä¸å¯é¢„æµ‹æ€§ã€‚
- en: Your job isn't to outsmart the compiler. You will lose. Your job is to write
    code that makes the compiler's job easy. Feed it a steady diet of the simple,
    predictable patterns it's designed to devour, and it will reward you with sweet
    speed. Create chaos with dynamic shapes and polymorphic calls, and it will protect
    itself - and your application's correctness - by retreating to the slow path.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„å·¥ä½œä¸æ˜¯è¦æˆ˜èƒœç¼–è¯‘å™¨ã€‚ä½ ä¼šå¤±è´¥çš„ã€‚ä½ çš„å·¥ä½œæ˜¯è¦ç¼–å†™è®©ç¼–è¯‘å™¨å·¥ä½œå˜å¾—å®¹æ˜“çš„ä»£ç ã€‚ç»™å®ƒæä¾›å®ƒè®¾è®¡æ¥åå™¬çš„ç®€å•ã€å¯é¢„æµ‹çš„æ¨¡å¼çš„ç¨³å®šé¥®é£Ÿï¼Œå®ƒå°†ä¼šä»¥ç”œç¾çš„é€Ÿåº¦å›æŠ¥ä½ ã€‚é€šè¿‡åŠ¨æ€å½¢çŠ¶å’Œå¤šæ€è°ƒç”¨åˆ¶é€ æ··ä¹±ï¼Œå®ƒå°†ä¼šé€šè¿‡é€€å›åˆ°æ…¢é€Ÿè·¯å¾„æ¥ä¿æŠ¤è‡ªå·±â€”â€”ä»¥åŠä½ åº”ç”¨ç¨‹åºçš„æ­£ç¡®æ€§ã€‚
- en: 'The next time you''re facing a weird performance issue, don''t just look at
    your code''s logic. Ask yourself: "How would V8 see this?" Think about the hidden
    classes you''re creating. Think about the type feedback you''re generating. Think
    about how your code progresses through the 4-tier compilation pipeline. Think
    like V8, and the performance issues will start to solve themselves.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹æ¬¡ä½ é‡åˆ°å¥‡æ€ªçš„æ€§èƒ½é—®é¢˜æ—¶ï¼Œä¸è¦åªå…³æ³¨ä½ ä»£ç çš„é€»è¾‘ã€‚é—®é—®è‡ªå·±ï¼šâ€œV8ä¼šå¦‚ä½•çœ‹å¾…è¿™ä¸ªé—®é¢˜ï¼Ÿâ€æ€è€ƒä½ æ­£åœ¨åˆ›å»ºçš„éšè—ç±»ã€‚æ€è€ƒä½ æ­£åœ¨ç”Ÿæˆçš„ç±»å‹åé¦ˆã€‚æ€è€ƒä½ çš„ä»£ç æ˜¯å¦‚ä½•é€šè¿‡å››å±‚ç¼–è¯‘ç®¡é“çš„ã€‚åƒV8ä¸€æ ·æ€è€ƒï¼Œæ€§èƒ½é—®é¢˜å°†ä¼šå¼€å§‹è‡ªè¡Œè§£å†³ã€‚
- en: '* * *'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
