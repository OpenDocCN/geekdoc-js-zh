- en: 'Chapter 6 First Pass: The Parser'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://keleshev.com/compiling-to-assembly-from-scratch/06-first-pass-the-parser](https://keleshev.com/compiling-to-assembly-from-scratch/06-first-pass-the-parser)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Compiling to Assembly from Scratch](./#table-of-contents)'
  prefs: []
  type: TYPE_NORMAL
- en: by [Vladimir Keleshev](/)
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve got enough parsing machinery working, we can implement the parser
    that produces an AST from source for our compiler.
  prefs: []
  type: TYPE_NORMAL
- en: Whitespace and comments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let’s define parsers for whitespace and comments, which we collectively
    refer to as *ignored*. (When a parser is split into a lexer and a parser, parsing
    whitespace and comments is usually done at the lexer-level.)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We allow both single-line (`// …`) and multi-line (`/* … */`) comments. In
    JavaScript regular expressions, the dot matches any character, *except* newline.
    To implement multi-line comments, we need to match newline as well. It is possible
    to alter the meaning of the dot regular expression to match any character *including*
    newline by passing the “dot-all” flag “`s`” alongside the “sticky” flag “`y`”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We use character classes with a single character like `[*]` as a readable way
    to escape characters that have special meaning in regular expressions. Otherwise,
    they quickly start looking like a broken saw:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Tokens
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even though our parser is scanerless (or token-less), it is still useful to
    distinguish tokens as our syntactic building blocks. The idea is to build token-like
    parsers from simple character parsers, and only then build full parser on top
    of token-like parsers.
  prefs: []
  type: TYPE_NORMAL
- en: 'As customary, we will use the naming convention for tokens (in grammar rules
    and parsers): they will be upper-case.'
  prefs: []
  type: TYPE_NORMAL
- en: Tokens provide us a higher-level view of our source than single characters.
    They allow us to not deal with minute details like whitespace and comments. And
    this is precisely how we’ll use them here. We’ll define a `token` parser combinator
    (or, more precisely, constructor) that allows us to ignore whitespace and comments
    around our lexemes (or tokens).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: It takes a regular expression pattern and returns a parser that is a sequence
    of that pattern and an `ignored` rule that we defined previously to handle whitespace
    and comments. It produces the string value matched by the pattern but ignores
    the value of the `ignored` rule. We “pad” with `ignored` only on the right-hand-side,
    not around the pattern. The latter would be redundant in all but the first token,
    which we can handle specially. This is a common way to handle whitespace and comments
    in scanerless parsers.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start with defining tokens for keywords in our language, like `function`,
    `if`, `else`, `return`, `var`, and `while`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We’ve used a word-break escape sequence `\b` to make sure we don’t recognize
    `functional` as a keyword `function` followed by identifier `al`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, tokens for punctuation: commas, parenthesis, etc.:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Our baseline compiler will handle only decimal integer numbers *(base 10)*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We map the `[0-9]+` token to convert digits to a JavaScript number using `parseInt`
    JavaScript built-in function that takes a string and a base number (10 for decimal).
    Then we construct a `Number` AST node from it.
  prefs: []
  type: TYPE_NORMAL
- en: Identifiers start with a letter or an underscore and are followed by a number
    of letters, digits, and underscores. In other words, they can’t start with a digit.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In some cases, it will be useful for us to parse identifiers just for their
    string value, but sometimes it is more convenient to produce the AST node. That’s
    why we create an alias `id`, which is the same as `ID`, but instead of producing
    a string, it produces an AST node `Id`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the operator tokens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: We cannot construct a full AST node out of a single operator, but it will be
    handy to return the class of the AST node.
  prefs: []
  type: TYPE_NORMAL
- en: Grammar
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The grammar for our baseline compiler is split into two parts: *expressions*
    and *statements*. JavaScript (and TypeScript) is pretty relaxed about distinguishing
    the two. In general, expressions are constructs that produce a value like `1 +
    2`, and statements are something that has an effect but does not produce a value,
    like a `while` loop.'
  prefs: []
  type: TYPE_NORMAL
- en: Expression parser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will start by constructing a parser for a single expression. Here is the
    grammar for an expression in the baseline language.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It consists of infix operations such as `==`, `!=`, `+`, `-`, `*`, `/`, unary
    negation `!x`, identifiers, integer numbers, and function calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'The expression rule is split into several layers in order to handle operator
    precedence. The `expression` itself is just an alias to `comparison`. The `comparison`
    rule represents the operators with the lowest precedence: `==` and `!=`. The `comparison`
    itself is built out of `sum` in which operators have higher precedence: `+` and
    `-`. The `sum`, in turn, is built out of `product` rules with the highest precedence
    among infix operators: `*` and `/`. Those are built from `unary`, which represents
    unary operators, of which we have only negation: `!`. Negation has the highest
    precedence among all our operators. It is built upon a rule called `atom`. The
    `atom` rule represents the rules that are “atomic”, or require no precedence because
    of the way they are structured. For example, `ID` and `NUMBER` are single lexemes,
    so precedence doesn’t apply, while `call` and parenthesized expressions have explicit
    delimiters, so precedence doesn’t apply either. The `args` rule is extracted to
    simplify the `call` rule.'
  prefs: []
  type: TYPE_NORMAL
- en: This process of constructing parsers with increasing precedence is sometimes
    compared to adding beads to a rope.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can probably notice that the lowest-level rules, such as `atom` and `call`
    (via `args`) refer back to `expression`. This means that our grammar is *recursive*.
    This creates a slight problem for constructing a parser for this grammar. While
    JavaScript allows for recursive functions, it does not allow for recursive values.
    Other languages allow for so-called `let-rec` bindings, but not JavaScript. The
    way we handle this is by initially defining `expression` as an `error` parser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we are free to use it when constructing our parser. However, we must remember
    to change this parser in-place once we define `comparison` and before we use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Call parser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to implement `call` by first implementing `args`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Mechanically converting the `args` to a parser gives us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Like in the case of the `Call` AST node, we called it `args` instead of `arguments`,
    because `arguments` is a special JavaScript object, and we don’t want to clash
    with it.
  prefs: []
  type: TYPE_NORMAL
- en: 'We want this parser to return something useful, like an array of AST nodes.
    The `maybe` combinator returns `null` if it doesn’t match, but we want an empty
    array, so let’s replace it with `.or(constant([]))`. We need to bind the first
    expression, then the rest of the expressions, and then concatenate them. By doing
    that we end up with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The expression `zeroOrMore(COMMA.and(expression))` conveniently ignores the
    commas and produces an array of AST nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, implementing `call` mechanically from grammar gives us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We bind `ID` (that represents the name of the callee) and `args` to construct
    a `Call` node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Atom
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next parser is `atom`. To ensure that it produces an AST, we need to use
    `id` rule instead of `ID`. We also bind the `expression` to extract its value.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The order of the choices is important. If the rule started as `ID / call` instead,
    `call` would never match, since `call` itself begins with an `ID`.
  prefs: []
  type: TYPE_NORMAL
- en: Unary operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For unary parser, we bind both `NOT?` and `atom`. If `NOT` operator is present
    we construct the `Not` AST node, otherwise, we produce the underlying node.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We have bound the value of the `atom` to a name `term`, which we will use as
    a catch-all phrase when binding expressions or statements.
  prefs: []
  type: TYPE_NORMAL
- en: Infix operators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Infix operators are all constructed similarly, with lower precedence rules building
    upon higher precedence rules.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: You can probably remember that we made sure that operator rule parsers produce
    the class of the corresponding AST node. For example, the `EQUAL` token produces
    the `Equal` class. We will use that property.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll start with the `product` parser. Naive mechanical translation gives us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Binding the first `unary` is easy. However, constructing a nested AST from all
    of this is not.
  prefs: []
  type: TYPE_NORMAL
- en: We can map `(STAR / SLASH) unary` to an intermediate data structure `{operator,
    term}`, which is a pair constructed from `STAR / SLASH` and `unary` values. This
    way, we get an array of operator-term pairs. We bind the `unary` and call its
    value `first`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we were parsing a string `"x * y / z"`, then `first` would
    be `new Id("x")`, while `operatorTerms` would be an array like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: How do we reduce those into an AST node like the following?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Turns out that `array.reduce` is precisely the method that can accomplish this!
    Here’s the resulting code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Quite a mouthful! Fortunately, this is the most complicated rule that we will
    encounter. Even better, we can extract this repeating pattern into another parser
    combinator and use it again. We’ll call that combinator `infix`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We changed our `product` rule into a function that takes two parameters: `operatorParser`
    and `termParser`. We replaced `unary` with `termParser` and `STAR.or(SLASH)` with
    `operatorParser`. And now we’ve got a reusable combinator, which we can use not
    only for `product` but also for `sum` and `comparison`.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Associativity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When we parse `"x * y / z"` we want it to be interpreted as `"(x * y) / z"`
    and produce the corresponding AST:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Thus, we say that these operators are left-associative. At the moment we don’t
    have any right-associative operators, but if we did, we would use the same grammar
    rules, but we would have to use `array.reduceBack` instead of `array.reduce` to
    construct the AST, with some adjustments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Closing the loop: expression'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have defined `comparison`, we can finally define `expression` which
    had only a dummy implementation so far. We do that by overwriting the `parse`
    method of `expression`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Statement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next up is parsing statements. Here’s the grammar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The high-level structure is very similar, as in the case of expressions. It
    consists of several rules, with `statement` defined recursively. Again, we start
    with a dummy implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'First statement kind is `returnStatment` that produces the `Return` AST node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The `expressionStatement` is an `expression` delimited with a semicolon:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ifStatement` produces the `If` node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The `whileStatment` is syntactically similar to the `ifStatement`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The `varStatment` and the `assigmentStatement` are similar as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Technically speaking, in JavaScript, the assignment is an expression, but for
    simplicity, we defined it as a statement. That’s also how it is used most of the
    time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The block statement is a list of statements delimited with braces. It produces
    a `Block` node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Function parameters rule is very similar to the `args` rule that we defined
    previously (in terms of parser structure), but the parser produces an `Array<string>`
    instead of `Array<AST>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The function definition (which we also refer to as a statement) builds upon
    `parameters` and `blockStatement` to produce a `Function` node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: We define `statement` as one of the above statements, and we tie the recursive
    knot by modifying the original `statement.parser`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'And since our language should accept more than one statement, we need one final
    touch to complete our parser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: It starts with allowing the “ignored” whitespace and comments (which need to
    be explicitly ignored before the first logical token) and follows by zero or more
    statements that we convert to a `Block` node.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is essential to test the parser at each step of the way. The examples from
    the chapter *Abstract Syntax Tree* provide a good source of unit tests. And here’s
    an example of a possible integration test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The parser is now complete, and so is the first pass of our compiler.
  prefs: []
  type: TYPE_NORMAL
- en: '[Next: Chapter 7\. ARM Assembly Programming](./07-arm-assembly-programming)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
