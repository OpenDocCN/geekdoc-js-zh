["```js\nimport { Duplex } from \"stream\";\n class MinimalDuplex extends Duplex {\n _read(size) {\n // produce data for readable side\n this.push(\"readable data\");\n this.push(null);\n }\n _write(chunk, encoding, callback) {\n // consume data on writable side\n console.log(\"Received:\", chunk.toString());\n callback();\n }\n}\n```", "```js\nconst duplex = new MinimalDuplex();\n duplex.on(\"data\", (chunk) => {\n console.log(\"Read:\", chunk.toString());\n});\n duplex.write(\"written data\");\nduplex.end();\n```", "```js\nconst duplex = new Duplex({\n allowHalfOpen: false,\n read() {\n // readable implementation\n },\n write(chunk, encoding, callback) {\n // writable implementation\n callback();\n },\n});\n```", "```js\nclass BufferedDuplex extends Duplex {\n constructor(options) {\n super(options);\n this.buffer = [];\n }\n _write(chunk, encoding, callback) {\n this.buffer.push(chunk);\n callback();\n }\n _read(size) {\n if (this.buffer.length > 0) {\n this.push(this.buffer.shift());\n }\n }\n}\n```", "```js\nduplex.destroy(new Error(\"Fatal error\"));\n// Both readable and writable sides are now destroyed\n```", "```js\n_transform(chunk, encoding, callback)\n```", "```js\nimport { Transform } from \"stream\";\n class UppercaseTransform extends Transform {\n _transform(chunk, encoding, callback) {\n const upper = chunk.toString().toUpperCase();\n this.push(upper);\n callback();\n }\n}\n```", "```js\nconst upper = new UppercaseTransform();\n upper.on(\"data\", (chunk) => {\n console.log(chunk.toString());\n});\n upper.write(\"hello\");\nupper.write(\"world\");\nupper.end();\n```", "```js\n_transform(chunk, encoding, callback) {\n try {\n const result = JSON.parse(chunk.toString());\n this.push(JSON.stringify(result));\n callback();\n } catch (err) {\n callback(err);\n }\n}\n```", "```js\nclass LineSplitter extends Transform {\n _transform(chunk, encoding, callback) {\n const lines = chunk.toString().split(\"\\n\");\n for (const line of lines) {\n if (line.length > 0) {\n this.push(line + \"\\n\");\n }\n }\n callback();\n }\n}\n```", "```js\n_transform(chunk, encoding, callback) {\n const text = chunk.toString();\n if (!text.startsWith(\"#\")) {\n this.push(chunk);\n }\n callback();\n}\n```", "```js\nclass DelimiterParser extends Transform {\n constructor(delimiter, options) {\n super(options);\n this.delimiter = delimiter;\n this.buffer = \"\";\n }\n _transform(chunk, encoding, callback) {\n this.buffer += chunk.toString();\n const parts = this.buffer.split(this.delimiter);\n this.buffer = parts.pop(); // last part is incomplete\n for (const part of parts) {\n this.push(part);\n }\n callback();\n }\n}\n```", "```js\n_flush(callback)\n```", "```js\nclass DelimiterParser extends Transform {\n constructor(delimiter, options) {\n super(options);\n this.delimiter = delimiter;\n this.buffer = \"\";\n }\n _transform(chunk, encoding, callback) {\n this.buffer += chunk.toString();\n const parts = this.buffer.split(this.delimiter);\n this.buffer = parts.pop();\n for (const part of parts) {\n this.push(part);\n }\n callback();\n }\n _flush(callback) {\n if (this.buffer.length > 0) {\n this.push(this.buffer);\n }\n callback();\n }\n}\n```", "```js\n_flush(callback) {\n if (this.buffer.length > 0) {\n try {\n const parsed = this.parseBuffer(this.buffer);\n this.push(parsed);\n callback();\n } catch (err) {\n callback(err);\n }\n } else {\n callback();\n }\n}\n```", "```js\nclass NDJSONParser extends Transform {\n constructor(options) {\n super({ ...options, objectMode: true });\n this.buffer = \"\";\n }\n _transform(chunk, encoding, callback) {\n this.buffer += chunk.toString();\n const lines = this.buffer.split(\"\\n\");\n this.buffer = lines.pop();\n for (const line of lines) {\n if (line.trim().length > 0) {\n try {\n const obj = JSON.parse(line);\n this.push(obj);\n } catch (err) {\n return callback(err);\n }\n }\n }\n callback();\n }\n _flush(callback) {\n if (this.buffer.trim().length > 0) {\n try {\n const obj = JSON.parse(this.buffer);\n this.push(obj);\n callback();\n } catch (err) {\n callback(err);\n }\n } else {\n callback();\n }\n }\n}\n```", "```js\nclass NonEmptyLines extends Transform {\n _transform(chunk, encoding, callback) {\n const text = chunk.toString();\n if (text.trim().length > 0) {\n this.push(chunk);\n }\n callback();\n }\n}\n```", "```js\nclass FieldExtractor extends Transform {\n constructor(fields, options) {\n super({ ...options, objectMode: true });\n this.fields = fields;\n }\n _transform(obj, encoding, callback) {\n const extracted = {};\n for (const field of this.fields) {\n if (obj[field] !== undefined) {\n extracted[field] = obj[field];\n }\n }\n this.push(extracted);\n callback();\n }\n}\n```", "```js\nclass ChunkSplitter extends Transform {\n constructor(chunkSize, options) {\n super(options);\n this.chunkSize = chunkSize;\n this.buffer = Buffer.alloc(0);\n }\n _transform(chunk, encoding, callback) {\n this.buffer = Buffer.concat([this.buffer, chunk]);\n while (this.buffer.length >= this.chunkSize) {\n const piece = this.buffer.slice(0, this.chunkSize);\n this.buffer = this.buffer.slice(this.chunkSize);\n this.push(piece);\n }\n callback();\n }\n _flush(callback) {\n if (this.buffer.length > 0) {\n this.push(this.buffer);\n }\n callback();\n }\n}\n```", "```js\nclass BatchAccumulator extends Transform {\n constructor(batchSize, options) {\n super({ ...options, objectMode: true });\n this.batchSize = batchSize;\n this.batch = [];\n }\n _transform(obj, encoding, callback) {\n this.batch.push(obj);\n if (this.batch.length >= this.batchSize) {\n this.push(this.batch);\n this.batch = [];\n }\n callback();\n }\n _flush(callback) {\n if (this.batch.length > 0) {\n this.push(this.batch);\n }\n callback();\n }\n}\n```", "```js\nclass LengthPrefixedParser extends Transform {\n constructor(options) {\n super({ ...options, objectMode: true });\n this.buffer = Buffer.alloc(0);\n this.expectedLength = null;\n }\n _transform(chunk, encoding, callback) {\n this.buffer = Buffer.concat([this.buffer, chunk]);\n while (this.buffer.length >= 4) {\n if (this.expectedLength === null) {\n this.expectedLength = this.buffer.readUInt32BE(0);\n this.buffer = this.buffer.slice(4);\n }\n if (this.buffer.length >= this.expectedLength) {\n const message = this.buffer.slice(0, this.expectedLength);\n this.buffer = this.buffer.slice(this.expectedLength);\n this.expectedLength = null;\n this.push(message);\n } else {\n break;\n }\n }\n callback();\n }\n}\n```", "```js\nclass Parser extends Transform {\n constructor(options) {\n super(options);\n this.buffer = \"\";\n }\n _transform(chunk, encoding, callback) {\n this.buffer += chunk.toString();\n let unit;\n while ((unit = this.extractCompleteUnit(this.buffer))) {\n this.buffer = unit.remainder;\n this.push(unit.data);\n }\n callback();\n }\n _flush(callback) {\n if (this.buffer.length > 0) {\n // handle remaining data\n }\n callback();\n }\n extractCompleteUnit(buffer) {\n // return { data, remainder } or null\n }\n}\n```", "```js\nclass SimpleCSVParser extends Transform {\n constructor(options) {\n super({ ...options, objectMode: true });\n this.buffer = \"\";\n }\n _transform(chunk, encoding, callback) {\n this.buffer += chunk.toString();\n const lines = this.buffer.split(\"\\n\");\n this.buffer = lines.pop();\n for (const line of lines) {\n const fields = line.split(\",\");\n this.push(fields);\n }\n callback();\n }\n _flush(callback) {\n if (this.buffer.length > 0) {\n const fields = this.buffer.split(\",\");\n this.push(fields);\n }\n callback();\n }\n}\n```", "```js\n_transform(chunk, encoding, callback) {\n const transformed = this.transformData(chunk);\n const canContinue = this.push(transformed);\n if (!canContinue) {\n // readable side is full, but we have to process this chunk\n }\n callback();\n}\n```", "```js\n_transform(chunk, encoding, callback) {\n const parts = this.splitIntoParts(chunk);\n for (const part of parts) {\n const canContinue = this.push(part);\n if (!canContinue) {\n // readable side is full, buffer the rest\n this.bufferedParts = parts.slice(parts.indexOf(part) + 1);\n break;\n }\n }\n callback();\n}\n```", "```js\nimport { PassThrough } from \"stream\";\n const passthrough = new PassThrough();\n```", "```js\nimport { pipeline } from \"stream/promises\";\n const passthrough = new PassThrough();\n passthrough.on(\"data\", (chunk) => {\n console.log(\"Passing through:\", chunk.length, \"bytes\");\n});\n await pipeline(source, passthrough, destination);\n```", "```js\nclass MyPassThrough extends Transform {\n _transform(chunk, encoding, callback) {\n callback(null, chunk);\n }\n}\n```", "```js\nthis.push(chunk);\ncallback();\n```", "```js\nimport { createGzip } from \"zlib\";\n const gzip = createGzip();\ninput.pipe(gzip).pipe(output);\n```", "```js\nimport { connect } from \"net\";\n const socket = connect(3000, \"localhost\");\nsocket.write(\"request\");\nsocket.on(\"data\", (chunk) => {\n console.log(\"response:\", chunk);\n});\n```", "```js\nclass JSONLineStringifier extends Transform {\n constructor(options) {\n super({ ...options, writableObjectMode: true });\n }\n _transform(obj, encoding, callback) {\n try {\n const json = JSON.stringify(obj);\n this.push(json + \"\\n\");\n callback();\n } catch (err) {\n callback(err);\n }\n }\n}\n```", "```js\nclass LineCounter extends Transform {\n constructor(options) {\n super({ ...options, readableObjectMode: true });\n this.lineCount = 0;\n this.byteCount = 0;\n }\n _transform(chunk, encoding, callback) {\n this.byteCount += chunk.length;\n const lines = chunk.toString().split(\"\\n\").length - 1;\n this.lineCount += lines;\n callback();\n }\n _flush(callback) {\n this.push({\n lines: this.lineCount,\n bytes: this.byteCount,\n });\n callback();\n }\n}\n```", "```js\nclass RateLimiter extends Transform {\n constructor(bytesPerSecond, options) {\n super(options);\n this.bytesPerSecond = bytesPerSecond;\n this.tokens = bytesPerSecond;\n this.lastRefill = Date.now();\n }\n _transform(chunk, encoding, callback) {\n this._refillTokens();\n const wait =\n Math.max(0, chunk.length - this.tokens) / this.bytesPerSecond;\n setTimeout(() => {\n this.tokens = Math.max(0, this.tokens - chunk.length);\n this.push(chunk);\n callback();\n }, wait * 1000);\n }\n _refillTokens() {\n const now = Date.now();\n const elapsed = (now - this.lastRefill) / 1000;\n this.tokens = Math.min(\n this.bytesPerSecond,\n this.tokens + elapsed * this.bytesPerSecond\n );\n this.lastRefill = now;\n }\n}\n```", "```js\nclass Deduplicator extends Transform {\n constructor(keyField, options) {\n super({ ...options, objectMode: true });\n this.keyField = keyField;\n this.seen = new Set();\n }\n _transform(obj, encoding, callback) {\n const key = obj[this.keyField];\n if (!this.seen.has(key)) {\n this.seen.add(key);\n this.push(obj);\n }\n callback();\n }\n}\n```", "```js\n_transform(chunk, encoding, callback) {\n try {\n const result = this.process(chunk);\n this.push(result);\n callback();\n } catch (err) {\n callback(err);\n }\n}\n```", "```js\nasync _transform(chunk, encoding, callback) {\n try {\n const result = await this.processAsync(chunk);\n this.push(result);\n callback();\n } catch (err) {\n callback(err);\n }\n}\n```", "```js\nasync _transform(chunk, encoding) {\n const result = await this.processAsync(chunk);\n this.push(result);\n}\n```", "```js\n_destroy(err, callback) {\n this.cleanup();\n callback(err);\n}\n```", "```js\ntransform.on(\"error\", (err) => {\n console.error(\"Transform error:\", err);\n});\n```", "```js\nclass JSONParser extends Transform {\n constructor(options) {\n super({ ...options, readableObjectMode: true });\n }\n _transform(chunk, encoding, callback) {\n try {\n const obj = JSON.parse(chunk.toString());\n this.push(obj);\n callback();\n } catch (err) {\n callback(err);\n }\n }\n}\n```", "```js\nclass JSONStringifier extends Transform {\n constructor(options) {\n super({ ...options, writableObjectMode: true });\n }\n _transform(obj, encoding, callback) {\n try {\n const json = JSON.stringify(obj);\n this.push(json);\n callback();\n } catch (err) {\n callback(err);\n }\n }\n}\n```", "```js\nimport { Transform } from \"stream\";\n const uppercase = new Transform({\n transform(chunk, encoding, callback) {\n this.push(chunk.toString().toUpperCase());\n callback();\n },\n});\n```", "```js\nimport { pipeline } from \"stream/promises\";\n await pipeline(\n source,\n async function* (source) {\n for await (const chunk of source) {\n yield chunk.toString().toUpperCase();\n }\n },\n destination\n);\n```", "```js\nfor await (const obj of stream) {\n process(obj);\n}\n```", "```js\nfor await (const batch of batchedStream) {\n for (const obj of batch) {\n process(obj);\n }\n}\n```", "```js\nimport { Readable, Writable } from \"stream\";\nimport { pipeline } from \"stream/promises\";\n const input = Readable.from([\"hello\", \"world\"]);\nconst output = [];\n const collector = new Writable({\n write(chunk, encoding, callback) {\n output.push(chunk.toString());\n callback();\n },\n});\n await pipeline(input, myTransform, collector);\n assert.deepEqual(output, [\"HELLO\", \"WORLD\"]);\n```", "```js\nconst slow = new Writable({\n write(chunk, encoding, callback) {\n setTimeout(callback, 100);\n },\n});\n const start = Date.now();\nawait pipeline(fastSource, myTransform, slow);\nconst elapsed = Date.now() - start;\n assert(elapsed > expectedMinimum);\n```"]