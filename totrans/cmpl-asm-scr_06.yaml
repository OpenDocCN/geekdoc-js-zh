- en: Chapter 5 Parser Combinators
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 解析器组合器
- en: 原文：[https://keleshev.com/compiling-to-assembly-from-scratch/05-parser-combinators](https://keleshev.com/compiling-to-assembly-from-scratch/05-parser-combinators)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://keleshev.com/compiling-to-assembly-from-scratch/05-parser-combinators](https://keleshev.com/compiling-to-assembly-from-scratch/05-parser-combinators)
- en: '[Compiling to Assembly from Scratch](./#table-of-contents)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[从零开始编译汇编](./#table-of-contents)'
- en: by [Vladimir Keleshev](/)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Vladimir Keleshev](/) 提供
- en: A parser is a function that converts some textual source into structured data.
    In our case, it converts a program’s source into the corresponding AST.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器是一个函数，它将某些文本源转换为结构化数据。在我们的情况下，它将程序的源代码转换为相应的AST。
- en: There’s a myriad of parsing techniques and approaches. Which one to choose often
    depends on the source language and its syntactic features.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 有无数种解析技术和方法。选择哪一种通常取决于源语言及其句法特征。
- en: The technique that we’ll use is called *parser combinators*. We’ll also use
    some *regular expressions* since they are so handy in JavaScript.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的技术称为**解析器组合器**。我们还将使用一些**正则表达式**，因为它们在JavaScript中非常方便。
- en: The idea of parser combinators is to create a small number of *primitive* parsers
    that could be *combined* into more complex parsers. Each primitive parser is very
    simple and barely does anything useful on its own, but combining those we can
    parse increasingly complex languages.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器组合器的想法是创建少量**原始**解析器，这些解析器可以**组合**成更复杂的解析器。每个原始解析器都非常简单，单独使用时几乎没有任何有用的功能，但通过组合它们，我们可以解析越来越复杂的语言。
- en: Parser combinators can be used to implement pretty much any parsing algorithm.
    They can parse immediately, or produce a data structure representing grammar that
    is used later. They can even be used for code generation. In practice (and historically),
    many parser combinators are *scanerless* (token-less), *greedy*, *backtracking*,
    and with *prioritized choice*. (We’ll get to what these mean in a minute). And
    our parsing combinators will be no exception.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 解析器组合器可以用来实现几乎任何解析算法。它们可以立即解析，或者生成表示语法的用于后续的数据结构。它们甚至可以用于代码生成。在实践中（以及历史上），许多解析器组合器是无扫描器（无标记）、**贪婪**、**回溯**和具有**优先选择**的。我们将在稍后解释这些术语的含义。我们的解析器组合器也不例外。
- en: 'Parsing combinators are my go-to technique when I need to parse something “by
    hand”: they are easy to implement and are powerful. After implementing a few primitive
    combinator functions, you get something comparable to a full-blown parser generator.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我需要手动解析某些内容时，解析器组合器是我的首选技术：它们易于实现且功能强大。在实现几个原始组合器函数之后，你将得到一个类似于完整解析器生成器的功能。
- en: Lexing, scanning, or tokenization
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 词法分析、扫描或标记化
- en: Lexing, scanning, and tokenization are all synonymous when talking about parsing.
    They refer to convertion of the source program into an intermediate representation
    called *token stream*. The token stream structure consists of individual “words”
    of our program, also called *tokens*, *lexemes*, or *lexical elements*. This terminology
    originated in linguistics, the field which pioneered grammars and parsing.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈论解析时，词法分析、扫描和标记化都是同义词。它们指的是将源程序转换为称为**标记流**的中间表示。标记流结构由我们程序的各个“单词”组成，也称为**标记**、**词素**或**词法元素**。这个术语起源于语言学，该领域是语法和解析的先驱。
- en: A token stream is a linear representation, unlike the tree-like representation
    of AST.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 标记流是一种线性表示，与AST的树状表示不同。
- en: 'A lexer would convert source like `x + y` into linear token stream like this:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 词法分析器会将像`x + y`这样的源代码转换为如下线性标记流：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And only then a parser would convert this to an AST like `new Addition(new Id("x"),
    new Id("y"))`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在那时，解析器才会将其转换为像`new Addition(new Id("x"), new Id("y"))`这样的AST。
- en: We’ve represented it using an array, but more often, it is some kind of lazy
    or streaming collection.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用数组来表示它，但更常见的是某种懒加载或流式集合。
- en: 'This is all to say that we won’t use a lexer: our parser will be *scannerless*.
    The way to think about scannerless parsing is you treat each character as a token.
    However, we will still use the word token when we talk about parsing single logical
    lexical elements. We also won’t go into details of the benefits and shortcomings
    of lexing or scannerless parsing. Here we’ve picked scannerless because of the
    implementation simplicity.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是说，我们不会使用词法分析器：我们的解析器将是**无扫描器**的。无扫描器解析的思考方式是将每个字符视为一个标记。然而，当我们谈论解析单个逻辑词法元素时，我们仍然会使用“标记”这个词。我们也不会深入探讨词法分析或无扫描器解析的优缺点。在这里，我们选择无扫描器是因为其实施简单。
- en: Grammars
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语法
- en: When making parsers, we want to discuss what language constructs those parsers
    can recognize. For that, we will use *grammars*. There are several notations to
    describe grammars. You might have heard about *Extended Backus-Naur Form* (EBNF).
    In our case, we will use *Parsing Expression Grammar* (PEG) notation. PEG notation
    is a good fit for us because it’s designed for *scannerless*, *greedy*, *backtracking*
    parsers, and can express *prioritized choice*. It borrows notation from EBNF and
    regular expressions.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建解析器时，我们希望讨论这些解析器可以识别的语言结构。为此，我们将使用*语法*。描述语法的符号有几种。你可能听说过*扩展巴科斯-诺尔范式*（EBNF）。在我们的情况下，我们将使用*解析表达式语法*（PEG）符号。PEG符号非常适合我们，因为它是为*无扫描器*、*贪婪*、*回溯*解析器和表达*优先选择*而设计的。它借鉴了EBNF和正则表达式的符号。
- en: As we introduce each parser combinator, we will also show the corresponding
    grammar. You will see that our parser combinators are designed to mimic the grammar
    notation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们介绍每个解析器组合器时，我们也会展示相应的语法。你会发现我们的解析器组合器被设计成模仿语法符号。
- en: Interface
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接口
- en: Let’s say that a parser is an object with a `parse` method that takes something
    called `Source` and returns either something called `ParseResult` or `null`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设解析器是一个具有`parse`方法的对象，该方法接受称为`Source`的东西，并返回称为`ParseResult`的东西或`null`。
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: TypeScript allows us to explicitly say that the `parse` method may return `null`,
    and it will also enforce this in its *strict null checking* mode.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: TypeScript允许我们明确表示`parse`方法可能返回`null`，并且它还会在其*严格空检查*模式下强制执行此操作。
- en: What are `Source` and `ParseResult`? Why couldn’t we use `string` for the source?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`Source`和`ParseResult`是什么？为什么我们不能使用`string`作为源？'
- en: 'When parsing, we need to keep track of the string that we parse and the location
    in the string where we are currently matching. Thus, `Source` is a pair consisting
    of:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在解析时，我们需要跟踪我们解析的字符串以及我们当前匹配的字符串位置。因此，`Source`是一个由以下组成的对：
- en: the string that we parse, and
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们解析的字符串，以及
- en: the index into that string that points to where we are parsing right now.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前解析的字符串中的索引，指向我们当前解析的位置。
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: But also, `Source` allows us to avoid having tight coupling with the `string`
    type. For example, we can later make another implementation of `Source` that lazily
    reads from a file.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`Source`允许我们避免与`string`类型紧密耦合。例如，我们可以在以后实现`Source`的另一个版本，该版本可以从文件中懒加载。
- en: '`Source` will be quite efficient for our use case since most `Source` objects
    will share the same `string` during parsing.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的用例，`Source`将非常高效，因为大多数`Source`对象在解析期间将共享相同的`string`。
- en: What about `ParseResult`? It is a simple data object that can hold some value
    produced by the parser and the source with the updated index position. The `value`
    will often be an `AST`, in our case. The `source` signifies where the parser left
    off, so another parser can continue from there.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`ParseResult`，它是一个简单的数据对象，可以保存解析器生成的某些值以及带有更新索引位置的源。`value`通常是我们案例中的`AST`。`source`表示解析器停止的位置，因此另一个解析器可以从那里继续。
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'However, parsers are allowed to return not only `ParseResult`, but also `null`.
    When returning `null` parser signifies that it didn’t match anything. It is not
    an error: during a single pass, many rules will not match, but others will.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，解析器不仅可以返回`ParseResult`，还可以返回`null`。当返回`null`时，解析器表示它没有匹配任何内容。这不是错误：在单次遍历中，许多规则不会匹配，但其他规则会匹配。
- en: Right now, `Source` doesn’t have any operations defined. Many choices are possible.
    One of them is to expose a `match` method, very similar to `string.match` that
    takes a regular expression. The difference with `string.match` is that we need
    to match from a particular `source.index` position. This is possible with so-called
    “sticky” regular expressions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，`Source`没有定义任何操作。有许多选择。其中之一是公开一个`match`方法，它与`string.match`非常相似，它接受一个正则表达式。与`string.match`的不同之处在于，我们需要从特定的`source.index`位置进行匹配。这可以通过所谓的“粘性”正则表达式实现。
- en: 'Sticky regular expressions in JavaScript are specified with a flag “`y`”, like
    this: `/hello/y`. They are special in the way that they have a `lastIndex` property.
    By setting this property to some index, we can control where the regular expression
    will be matched. It’s an odd design, but it works for us. Other programming languages
    have different ways to match a regular expression from a particular index.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在JavaScript中，粘性正则表达式使用标志“`y`”指定，例如：`/hello/y`。它们特别之处在于它们有一个`lastIndex`属性。通过将此属性设置为某个索引，我们可以控制正则表达式将在何处匹配。这是一个奇特的设计，但它对我们有效。其他编程语言有不同的方式从特定索引匹配正则表达式。
- en: 'Let’s write our `match` method:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写我们的`match`方法：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'First, we assert that the regexp we got is sticky; otherwise, this will not
    work. Then we set `lastIndex` on the regexp to match from the source index. Then
    we delegate to `string.match` method to do the matching. If the match object is
    `null`, we return `null`: we couldn’t match the regular expression. Otherwise,
    we got a regexp “match” object. It is an array-like object where the first item
    is the substring that matched the regular expression. We use that substring in
    two ways: First, it’s the value of the `ParseResult` that we use. Second, we count
    the length of the matched string to advance the new `Source` index that we return
    as the second component of `ParseResult`.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们断言我们得到的正则表达式是粘性的；否则，这不会起作用。然后我们将正则表达式上的`lastIndex`设置为从源索引开始匹配。然后我们委托给`string.match`方法进行匹配。如果匹配对象是`null`，我们返回`null`：我们无法匹配正则表达式。否则，我们得到了一个正则表达式“match”对象。它是一个类似数组的对象，其中第一个项目是与正则表达式匹配的子串。我们以两种方式使用那个子串：首先，它是我们使用的`ParseResult`的值。其次，我们计算匹配字符串的长度，以前进我们返回的新`Source`索引，作为`ParseResult`的第二个组件。
- en: As you can see, `Source` already *almost* satisfies our `Parser` interface.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，`Source`几乎已经满足我们的`Parser`接口。
- en: 'A natural way to implement parser combinators that satisfy the `Parser` interface
    in TypeScript would be to create a class for each parser, with different `parser`
    methods. However, since `Parser` interface has only one method, and many of our
    parser combinators will have one-liner implementations, let’s use a more light-weight
    approach. Instead, we’ll have a single `Parser` class that takes `parse` method
    (as an arrow function) as a parameter:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在TypeScript中实现满足`Parser`接口的解析器组合器的一种自然方式是为每个解析器创建一个类，并具有不同的`parser`方法。然而，由于`Parser`接口只有一个方法，并且我们的大多数解析器组合器将具有单行实现，让我们使用一种更轻量级的方法。相反，我们将有一个单一的`Parser`类，它接受`parse`方法（作为一个箭头函数）作为参数：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Primitive combinators
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原始组合器
- en: 'Now, let’s start defining the *primitive* parser combinators. Some of them
    will be `Parser` instance methods; some will be static methods. We pick one or
    another purely based on notation: whether `f(x)` or `x.f()` is more readable for
    each combinator. While making this choice, we will try to mimic the corresponding
    grammar.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始定义*原始*解析器组合器。其中一些将是`Parser`实例方法；一些将是静态方法。我们纯粹基于符号来选择一个或另一个：对于每个组合器，`f(x)`或`x.f()`哪个更易读。在做出这个选择时，我们将尝试模仿相应的语法。
- en: Regexp combinator
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则表达式组合器
- en: Our first combinator called `regexp` creates a parser that matches a regexp.
    It only delegates to the `source.match` method that we’ve just defined.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们第一个名为`regexp`的组合器创建了一个匹配正则表达式的解析器。它只委托给刚刚定义的`source.match`方法。
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When using this combinator, we must remember to pass “sticky” regular expressions
    with the “`y`” flag. Otherwise, the assertion that we defined earlier will remind
    us.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用这个组合器时，我们必须记住传递带有“`y`”标志的“粘性”正则表达式。否则，我们之前定义的断言会提醒我们。
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The corresponding PEG grammar is:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对应的PEG语法是：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The arrow defines a grammar rule called `hello`. As you can see, the PEG notation
    borrows from regular expression notation. A string in double-quotes matches literally,
    while `[0-9]` is a character class, a concept borrowed from regular expressions.
    Outside the quotes and the character class, whitespace does not matter.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 箭头定义了一个名为`hello`的语法规则。如您所见，PEG符号借鉴了正则表达式符号。双引号中的字符串匹配字面意义，而`[0-9]`是一个字符类，这是一个从正则表达式借用的概念。在引号和字符类之外，空白字符不重要。
- en: 'Let’s try to use our `hello` parser to parse a string:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用我们的`hello`解析器来解析一个字符串：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here we create a new source from string `"hello1 bye2"`. We want it to parse
    from the beginning so we set the source index to zero. We call `parse` with the
    constructed source, and we get back a `ParseResult` object. Then we assert that
    the value being parsed is `"hello1"` and the resulting source index has advanced
    to column six, where the rest of the string is located: `" bye2"`.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们从一个字符串`"hello1 bye2"`创建一个新的源。我们希望它从开始解析，因此我们将源索引设置为零。我们用构造的源调用`parse`，并返回一个`ParseResult`对象。然后我们断言正在解析的值是`"hello1"`，并且结果源索引已经前进到第六列，那里是字符串的其余部分：“`bye2`”。
- en: Constant combinator
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常量组合器
- en: 'Next combinator might seem a little silly: it’s a parser that always succeeds,
    returns a constant value, does not consume any input (so, does not advance the
    source). We call it `constant`. How is it good for anything? Soon, you will see.
    For now, let’s say that it allows, when combined with other parsers, to change
    the return value (and the type) of a parser.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个组合器可能看起来有点愚蠢：它是一个总是成功的解析器，返回一个常量值，不消耗任何输入（因此，不前进源）。我们称它为 `constant`。它有什么好处呢？很快你就会看到。现在，让我们说它允许，当与其他解析器组合时，改变解析器的返回值（和类型）。
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In PEG it would correspond to an empty string:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PEG 中，它对应于一个空字符串：
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The notation does not concern itself with what value is produced, only with
    what string is recognized.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该表示法不关心产生什么值，只关心识别什么字符串。
- en: Error combinator
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误组合器
- en: 'Next is `error`: a parser that just throws an exception. The exception is not
    intended to be handled. It is expected to terminate the program.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是 `error`：一个仅抛出异常的解析器。这个异常并不打算被处理。它预期将终止程序。
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: There’s no correspondence with PEG notation.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 它与 PEG 表示法没有对应关系。
- en: '**Explore**'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**探索**'
- en: ''
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A better implementation of the `error` combinator would inspect the source,
    convert the source index into a line-column pair, and display it together with
    the offending line and some context.
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`error` 组合器的更好实现会检查源，将源索引转换为行-列对，并将其与有问题的行和一些上下文一起显示。'
- en: 'We can use these combinators with a fully qualified names, like `Parser.regexp`,
    or we can “import” them into the current namespace:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用完全限定的名称使用这些组合器，例如 `Parser.regexp`，或者我们可以将它们“导入”到当前命名空间中：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: From now on, we will assume that the names of the parser combinators we define
    are imported, and we don’t need to qualify them.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在起，我们将假设我们定义的解析器组合器的名称已导入，我们不需要限定它们。
- en: Choice operator
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择运算符
- en: 'Next primitive parser combinator is the *choice operator* that we define as
    the `or` instance method on parsers. It allows us to select between two (or more)
    alternative parser choices. Unlike the previous primitive combinators, this is
    an instance method, not a static method. We use an instance method here purely
    for syntactic reasons. We would like to write `x.or(y).or(z)`, instead of `or(or(x,
    y), z)`, so it mimics the corresponding PEG grammar: `x / y / z`.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个原始解析器组合器是 *选择运算符*，我们将其定义为解析器的 `or` 实例方法。它允许我们在两个（或更多）替代解析器选择之间进行选择。与之前的原始组合器不同，这是一个实例方法，而不是静态方法。我们在这里使用实例方法纯粹是出于语法原因。我们希望写
    `x.or(y).or(z)`，而不是 `or(or(x, y), z)`，因此它模仿相应的 PEG 语法：`x / y / z`。
- en: A parser like `left.or(right)` first tries to parse using the `left` parser.
    If successful, the result is returned. If not, the `right` parser is tried, and
    its result is returned.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 `left.or(right)` 的解析器首先尝试使用 `left` 解析器进行解析。如果成功，则返回结果。如果不成功，则尝试 `right`
    解析器，并返回其结果。
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Such choice operator is called *prioritized choice* operator. In contrast with
    *unordered choice* operator, it tries the alternative parsers in a (prioritized)
    order from left to right.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这种选择运算符被称为 *优先选择* 运算符。与 *无序选择* 运算符相比，它从左到右按（优先级）顺序尝试替代解析器。
- en: PEG notation helps us be precise about the fact that we use prioritized choice
    by using forward slash (`/`) as opposed to the unordered choice operator, which
    is usually denoted with a horizontal bar (`|`).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: PEG 表示法通过使用正斜杠 (`/`) 作为优先选择运算符，而不是通常用水平线 (`|`) 表示的无序选择运算符，帮助我们精确地表达我们使用优先选择的事实。
- en: 'Unordered choice can be handled in different ways too: a parser could explore
    several choices simultaneously, or the choice that could be determined unresolvable
    by looking at one (or *n* characters) could be rejected outright, ahead of any
    parsing.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 无序选择也可以以不同的方式处理：解析器可以同时探索几个选择，或者如果通过查看一个（或 *n* 个字符）无法确定选择是否可解析，则可以提前直接拒绝该选择，在任何解析之前。
- en: The choice operator is one of the central topics in parsing, and its choice
    is often the decisive factor in parser performance and recognition power.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 选择运算符是解析中的核心主题之一，其选择往往是解析器性能和识别能力的决定性因素。
- en: Given a parser like `left.or(right)`, we say that it *backtracks* because it
    will try parser `left` and, if that does not succeed, will *backtrack* (or return)
    to the same source index and try the `right` parser. We say that our parser has
    *unlimited look-ahead* because it will try to parse `left` completely, no matter
    how long the match is, in other words, without any *limit*. Other techniques look
    ahead at one (or *n* characters, or tokens) to decide which choice to take.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个如 `left.or(right)` 的解析器，我们称它为**回溯**，因为它将尝试解析器 `left`，如果它不成功，将**回溯**（或返回）到相同的源索引并尝试
    `right` 解析器。我们说我们的解析器有**无限前瞻**，因为它将尝试完全解析 `left`，无论匹配有多长，换句话说，没有任何**限制**。其他技术前瞻一个（或
    *n* 个字符，或标记）来决定选择哪个。
- en: Theoretically, the way we implemented our choice operator is not very efficient
    and could be improved with caching. However, if we take some care with combining
    our parsers, it could be a non-problem. The key is not to combine parsers that
    can parse the same long prefix, but instead combine alternative parsers so that
    they can quickly recognize that they don’t match and move to the next one.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上讲，我们实现选择运算符的方式不是很高效，可以通过缓存来改进。然而，如果我们小心地组合我们的解析器，它可能不是问题。关键是不要组合可以解析相同长前缀的解析器，而是组合替代解析器，这样它们可以快速识别它们不匹配并移动到下一个。
- en: 'Consider a parser constructed from the following two: one matches a hundred
    consecutive characters “a” followed by a single “b”, and another matches a hundred
    consecutive characters “a” followed by a single “c”. Given an input that matches
    the latter, it will have to scan one hundred characters *twice*:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑由以下两个解析器构建的解析器：一个匹配连续一百个字符“a”后跟一个单独的“b”，另一个匹配连续一百个字符“a”后跟一个单独的“c”。给定一个匹配后者的输入，它将不得不扫描一百个字符**两次**：
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: On the other hand, if we have one parser that parses a letter, and another one
    that parses a digit, we can combine them with `or` and it takes only one character
    to check if the first parser matches or not, before moving to the next parser.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果我们有一个解析字母的解析器，另一个解析数字的解析器，我们可以用 `or` 组合它们，并且只需要一个字符来检查第一个解析器是否匹配，然后再移动到下一个解析器。
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This parser can be described with the following grammar:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解析器可以用以下语法来描述：
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Repetition: zero or more'
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重复：零次或多次
- en: The next primitive parser combinator is `zeroOrMore` that handles repetition.
    Given a parser that returns some result, it will return a new parser that returns
    an array of results, instead. The implementation is as follows.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个原始解析器组合器是 `zeroOrMore`，它处理重复。给定一个返回某些结果的解析器，它将返回一个新的解析器，该解析器返回一个结果数组。其实现如下。
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We apply the same parser several times in a `while` loop. Each time we advance
    the `source` and push the resulting value into an array. As soon as one of the
    parses does not match and returns `null`, we return that array as the result in
    a new `ParseResult` object that bundles the last `source`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `while` 循环中多次应用相同的解析器。每次我们前进 `source` 并将结果值推入数组。一旦其中一个解析器不匹配并返回 `null`，我们就返回该数组作为新
    `ParseResult` 对象的结果，该对象捆绑了最后的 `source`。
- en: For example, this parser will match zero or more letters or digits, given `letterOrDigit`
    that we have just defined.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这个解析器将匹配零个或多个字母或数字，给定我们刚刚定义的 `letterOrDigit`。
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This combinator function corresponds to the star (`*`) operator in PEG, similar
    to the regular expressions notation.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这个组合函数对应于 PEG 中的星号 (`*`) 运算符，类似于正则表达式表示法。
- en: '[PRE20]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We can also inline `letterOrDigit` and rewrite this as:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以内联 `letterOrDigit` 并将其重写为：
- en: '[PRE21]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We say that our `zeroOrMore` or “star” operator is *greedy*. It matches the
    PEG semantics, but differs from regular expressions. A regular expression like
    `a*a` will match one or more letters `a`. However, `a*a` in PEG (and our parser
    combinators) will never match anything: the `a*` part of the expression will “greedily”
    consume input as long as it can match, and without any respect for what follows
    it.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称我们的 `zeroOrMore` 或“星号”运算符为**贪婪**。它符合 PEG 语义，但与正则表达式不同。正则表达式如 `a*a` 将匹配一个或多个字母
    `a`。然而，PEG（以及我们的解析器组合器）中的 `a*` 部分将永远不会匹配任何内容：表达式中的 `a*` 部分会“贪婪”地消费输入，只要它能匹配，而不考虑其后的内容。
- en: Bind
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 绑定
- en: The next parser combinator is an interesting one. It is another key combinator,
    on par with the choice operator. As the name alludes, it *binds* a value that
    is being parsed to a name. By binding a value to a name, we can manipulate and
    construct values that our parser produces.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个解析器组合器非常有趣。它是一个关键的组合器，与选择操作符相当。正如其名所暗示的，它*绑定*一个正在解析的值到一个名称。通过将值绑定到名称，我们可以操作和构建解析器生成的值。
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: It takes a callback, which usually will be an arrow function. The callback takes
    the parsed result as the parameter and returns a new parser that should continue
    parsing. This way, we can combine several parsers and bind their values to construct
    a new return value.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 它接受一个回调，这通常将是一个箭头函数。回调函数将解析结果作为参数，并返回一个应该继续解析的新解析器。这样，我们可以组合几个解析器并将它们的值绑定以构建新的返回值。
- en: For example, here we are constructing a parser for comma-separated pairs of
    numbers, like `"12,34"`.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里我们正在构建一个解析逗号分隔的数字对的解析器，例如`"12,34"`。
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We bind the first numeric parser to the `first` parameter. We ignore the result
    of the comma regexp (by binding it to an underscore), then bind the second numeric
    regexp to the `second` parameter. From those, we construct an array, and we “return”
    this array by constructing a constant parser.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将第一个数值解析器绑定到`first`参数。我们忽略逗号正则表达式的结果（通过将其绑定到下划线），然后将第二个数值正则表达式绑定到`second`参数。从这些中，我们构建一个数组，并通过构建一个常量解析器“返回”这个数组。
- en: 'The corresponding grammar is:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的语法是：
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: As always, the grammar ignores the value of the parser constructs; it is only
    concerned with which language constructs it can recognize.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，语法忽略了解析器构造的值；它只关心它能识别的语言构造。
- en: Non-primitive parsers
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 非原始解析器
- en: In the first example of using `bind`, we have seen two patterns that keep repeating
    when you use `bind` in practice. That’s why we will introduce them now as non-primitive
    parsers.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`bind`的第一个例子中，我们已经看到了在实际上使用`bind`时反复出现的两种模式。这就是为什么我们现在将它们作为非原始解析器引入。
- en: And and map
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并且和map
- en: 'The first repeating pattern is using `bind`, but ignoring the value. It effectively
    creates a sequence of parsers. We call this non-primitive combinator `and`. It
    allows to sequence parsers just like `bind`, but without binding a value to a
    name:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个重复的模式是使用`bind`，但忽略值。它有效地创建了一系列解析器。我们称这个非原始组合器为`and`。它允许像`bind`一样按顺序排列解析器，但不需要将值绑定到名称：
- en: '[PRE25]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The next pattern that we’ll see a lot is binding name only to return a constant
    parser immediately. We call it `map`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来会看到很多的是只绑定名称以立即返回一个常量解析器的模式。我们称之为`map`。
- en: '[PRE26]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: It is worth mentioning that this `map` method is in a way similar to the `array.map`
    method.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，这个`map`方法在某种程度上类似于`array.map`方法。
- en: '* * *'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Now, let’s try to rewrite our pair parser using the new methods:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试使用新方法重写我们的配对解析器：
- en: '[PRE27]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note that the value produced by the left parser in `left.and(right)` is ignored.
    If you don’t want to ignore it, you need to `bind` it.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`left.and(right)`中左解析器产生的值被忽略了。如果你不想忽略它，你需要`bind`它。
- en: Writing code in this way is not unlike writing code that involves JavaScript
    promises. It can be tricky sometimes, but fortunately, given a grammar, we can
    make the corresponding parser almost mechanically.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式编写代码并不像编写涉及JavaScript promises的代码。有时可能会很棘手，但幸运的是，给定一个语法，我们可以几乎机械地制作相应的解析器。
- en: 'Let’s look at it in another way. Let’s say we have in mind a grammar, like
    our pair grammar:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从另一个角度来看它。假设我们心中有一个语法，比如我们的配对语法：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Say, we want to produce a parser for it. We use `let` to define the named rule,
    and use the `and` method for all sequences (and the `or` method for any alternatives):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要生成一个解析器。我们使用`let`来定义命名规则，并使用`and`方法对所有序列（以及`or`方法对任何替代）进行操作：
- en: '[PRE29]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'And now, we should think about which values we want to extract. We want to
    extract the two numeric values, so we replace `and` with `bind` for them:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们应该考虑我们想要提取哪些值。我们想要提取两个数值，所以我们将`and`替换为`bind`：
- en: '[PRE30]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'And in the last bind we construct the value we want with the `constant` parser:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个绑定中，我们使用`constant`解析器构建我们想要的值：
- en: '[PRE31]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We’re done, but if we want, we can replace the second `bind` with `map` since
    it returns a constant parser:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完成了，但如果愿意，我们可以将第二个`bind`替换为`map`，因为它返回一个常量解析器：
- en: '[PRE32]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Maybe
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 也许
- en: 'The `maybe` combinator allows us to parse something, or return `null`, optionally.
    We can achieve this by combining the `or` operator with `constant(null)` parser:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`maybe`组合器允许我们解析某些内容，或者可选地返回`null`。我们可以通过将`or`操作符与`constant(null)`解析器组合来实现这一点：'
- en: '[PRE33]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Here we are optionally parsing a letter or a digit:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可选地解析一个字母或一个数字：
- en: '[PRE34]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This combinator corresponds to the “`?`” operator in PEG, also similar to the
    regular expressions notation:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这个组合器对应于 PEG 中的“`?`”运算符，也类似于正则表达式的表示法：
- en: '[PRE35]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Like in PEG, and unlike regular expressions, our `maybe` combinator is *greedy*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在 PEG 中一样，与正则表达式不同，我们的 `maybe` 组合器是 *贪婪的*。
- en: Often it is useful to have a different default rather than `null`, for example,
    an empty array. In those cases we can simply say `parser.or(constant([]))`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有时使用一个不同的默认值而不是 `null`，例如一个空数组，是非常有用的。在这些情况下，我们可以说 `parser.or(constant([]))`。
- en: Parsing a string
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析字符串
- en: Although each parser has a `parse` method, this method is more convenient for
    composing parsers rather than using them in practice. So let’s define a helper
    method, that’s a little different, called `parseStringToCompletion`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然每个解析器都有一个 `parse` 方法，但这个方法在组合解析器时比在实际使用中更方便。所以让我们定义一个稍微不同的辅助方法，称为 `parseStringToCompletion`。
- en: '[PRE36]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: As the name suggests, instead of taking a `Source` object, this method takes
    a string. It makes it more convenient for testing and using the resulting parsers.
    This method creates a `Source` for you and calls the `parse` method. However,
    unlike the `parse` method, it throws an exception if the result could not be parsed,
    and in case the parsing did not consume all of the input string. It also unpacks
    the `ParseResult` to give us only the resulting value.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名所示，这个方法不是接受一个 `Source` 对象，而是接受一个字符串。这使得测试和使用生成的解析器更加方便。这个方法会为你创建一个 `Source`
    对象并调用 `parse` 方法。然而，与 `parse` 方法不同，如果结果无法解析，或者解析没有消耗掉整个输入字符串，它会抛出一个异常。它还会解包 `ParseResult`，只给我们结果值。
- en: '* * *'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Now that we have learned how to construct parsers, let’s make the parser pass
    for our baseline compiler!
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何构建解析器，让我们让解析器通过我们的基线编译器！
- en: '[Next: Chapter 6\. First Pass: The Parser](./06-first-pass-the-parser)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[下一章：第 6 章. 第一次遍历：解析器](./06-first-pass-the-parser)'
- en: '* * *'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
