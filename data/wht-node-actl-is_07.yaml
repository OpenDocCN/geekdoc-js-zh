- en: Buffer Allocation Patterns
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¼“å†²åŒºåˆ†é…æ¨¡å¼
- en: åŸæ–‡ï¼š[https://www.thenodebook.com/buffers/allocation-patterns](https://www.thenodebook.com/buffers/allocation-patterns)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://www.thenodebook.com/buffers/allocation-patterns](https://www.thenodebook.com/buffers/allocation-patterns)
- en: TL;DR - for the impatient
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TL;DR - å¯¹äºæ²¡æœ‰è€å¿ƒçš„äººæ¥è¯´
- en: Now that you have an idea about what a `Buffer` is, let's take this understanding
    forward - in a more practical way. Let's suppose your service is either leaking
    secrets or running slower than a sloth in molasses because of how you're allocating
    Buffers. How do you identify the cause?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ å·²ç»å¯¹`Buffer`æœ‰äº†æ¦‚å¿µï¼Œè®©æˆ‘ä»¬å°†è¿™ç§ç†è§£å‘å‰æ¨è¿›â€”â€”ä»¥ä¸€ç§æ›´å®é™…çš„æ–¹å¼ã€‚å‡è®¾ä½ çš„æœåŠ¡ç”±äºä½ åˆ†é…ç¼“å†²åŒºçš„æ–¹å¼è€Œæ­£åœ¨æ³„éœ²ç§˜å¯†æˆ–è¿è¡Œé€Ÿåº¦æ¯”åœ¨ç³–æµ†ä¸­çš„æ ‘æ‡’è¿˜è¦æ…¢ã€‚ä½ å¦‚ä½•è¯†åˆ«åŸå› ï¼Ÿ
- en: There are three main ways to end up in that situation, and each has a specific
    way to ruin your day.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸‰ç§ä¸»è¦æ–¹å¼ä¼šå¯¼è‡´è¿™ç§æƒ…å†µï¼Œæ¯ç§æ–¹å¼éƒ½æœ‰ä¸€ç§ç‰¹å®šçš„æ–¹å¼æ¥ç ´åä½ çš„æ—¥å­ã€‚
- en: '**`Buffer.alloc(size)`** is your slow, safe, dependable friend. It asks for
    memory and then instantly writes zeros over every single byte before handing it
    to you. This guarantees you never see old, sensitive data from other parts of
    the system. The catch? That "zero-filling" takes time. In a tight loop, on a hot
    path, this can become your single biggest CPU bottleneck, pinning your service
    at 100% and tanking your throughput. You use this by default, and only change
    when a profiler screams at you that this specific line is your problem.'
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**`Buffer.alloc(size)`** æ˜¯ä½ çš„æ…¢é€Ÿã€å®‰å…¨ã€å¯é çš„ä¼™ä¼´ã€‚å®ƒä¼šè¯·æ±‚å†…å­˜ï¼Œç„¶åç«‹å³åœ¨ä½ ç»™å‡ºçš„æ¯ä¸ªå­—èŠ‚ä¸Šå†™å…¥é›¶ã€‚è¿™ä¿è¯äº†ä½ æ°¸è¿œä¸ä¼šçœ‹åˆ°æ¥è‡ªç³»ç»Ÿå…¶ä»–éƒ¨åˆ†çš„æ—§æ•æ„Ÿæ•°æ®ã€‚é—®é¢˜æ˜¯ï¼Ÿâ€œé›¶å¡«å……â€éœ€è¦æ—¶é—´ã€‚åœ¨ä¸€ä¸ªç´§å¯†çš„å¾ªç¯ä¸­ï¼Œåœ¨ä¸€ä¸ªçƒ­ç‚¹è·¯å¾„ä¸Šï¼Œè¿™å¯èƒ½ä¼šæˆä¸ºä½ æœ€å¤§çš„CPUç“¶é¢ˆï¼Œå°†ä½ çš„æœåŠ¡é”å®šåœ¨100%ï¼Œå¹¶é™ä½ä½ çš„ååé‡ã€‚ä½ é»˜è®¤ä½¿ç”¨è¿™ä¸ªé€‰é¡¹ï¼Œåªæœ‰å½“åˆ†æå™¨å¤§å£°ç–¾å‘¼è¿™æ¡ç‰¹å®šçš„è¡Œæ˜¯ä½ çš„é—®é¢˜æ—¶ï¼Œä½ æ‰ä¼šæ›´æ”¹å®ƒã€‚'
- en: '**`Buffer.allocUnsafe(size)`** is the "move fast and break things" option,
    and by "things," I mean your data privacy and security posture. It''s really fast
    because it just grabs a chunk of memory and gives it to you, garbage or whatever.
    That "garbage" could be anything - fragments of a previous user''s session token,
    database credentials, personally identifiable information (PII), or API keys that
    were in memory moments before. If you use this and don''t **immediately overwrite
    every single byte**, you are actively leaking data. It might be to a log file,
    over a network socket, or into a cache. It''s a time bomb, and the only time to
    even *think* about using it is when you''ve proven `Buffer.alloc()` is too slow
    and you have a function that will fill the buffer completely, like `fs.readSync`.'
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**`Buffer.allocUnsafe(size)`** æ˜¯â€œå¿«é€Ÿç§»åŠ¨å¹¶ç ´åäº‹ç‰©â€é€‰é¡¹ï¼Œè¿™é‡Œçš„â€œäº‹ç‰©â€æŒ‡çš„æ˜¯ä½ çš„æ•°æ®éšç§å’Œå®‰å…¨çŠ¶æ€ã€‚å®ƒéå¸¸å¿«ï¼Œå› ä¸ºå®ƒåªæ˜¯æŠ“å–ä¸€å—å†…å­˜å¹¶ç»™ä½ ï¼Œä¸ç®¡æ˜¯ä»€ä¹ˆåƒåœ¾ã€‚è¿™â€œåƒåœ¾â€å¯ä»¥æ˜¯ä»»ä½•ä¸œè¥¿â€”â€”å‰ä¸€ä¸ªç”¨æˆ·ä¼šè¯ä»¤ç‰Œçš„ç‰‡æ®µã€æ•°æ®åº“å‡­è¯ã€ä¸ªäººä¿¡æ¯ï¼ˆPIIï¼‰æˆ–å†…å­˜ä¸­å‡ åˆ†é’Ÿå‰çš„APIå¯†é’¥ã€‚å¦‚æœä½ ä½¿ç”¨è¿™ä¸ªé€‰é¡¹å¹¶ä¸”æ²¡æœ‰**ç«‹å³è¦†ç›–æ¯ä¸ªå­—èŠ‚**ï¼Œä½ æ­£åœ¨ç§¯ææ³„éœ²æ•°æ®ã€‚å®ƒå¯èƒ½æ˜¯ä¸€ä¸ªæ—¥å¿—æ–‡ä»¶ã€é€šè¿‡ç½‘ç»œå¥—æ¥å­—ï¼Œæˆ–è€…è¿›å…¥ç¼“å­˜ã€‚è¿™æ˜¯ä¸€ä¸ªå®šæ—¶ç‚¸å¼¹ï¼Œå”¯ä¸€å¯ä»¥è€ƒè™‘ä½¿ç”¨å®ƒçš„æ—¶å€™æ˜¯å½“ä½ å·²ç»è¯æ˜`Buffer.alloc()`å¤ªæ…¢ï¼Œå¹¶ä¸”ä½ æœ‰ä¸€ä¸ªä¼šå®Œå…¨å¡«å……ç¼“å†²åŒºçš„å‡½æ•°ï¼Œæ¯”å¦‚`fs.readSync`ã€‚'
- en: '**`Buffer.from(source)`** is the chameleon. It seems convenient, but its behavior
    and performance profile change dramatically based on what you pass it. Give it
    a string, and it spends CPU cycles encoding it. Give it an array of numbers, and
    it iterates and copies them one by one. Give it another Buffer, and it creates
    a full copy. But give it certain kinds of underlying memory like an `ArrayBuffer`''s
    `.buffer`, and it might create a *view* into that memory instead of a copy. This
    means if the original memory changes, your "immutable" Buffer silently corrupts
    itself. If you''re not careful, `Buffer.from()` leads to subtle data corruption
    bugs that are a nightmare to track down in production.'
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**`Buffer.from(source)`** æ˜¯å˜è‰²é¾™ã€‚å®ƒçœ‹èµ·æ¥å¾ˆæ–¹ä¾¿ï¼Œä½†å®ƒçš„è¡Œä¸ºå’Œæ€§èƒ½ç‰¹å¾ä¼šæ ¹æ®ä½ ä¼ é€’ç»™å®ƒçš„å†…å®¹è€Œå¤§å¹…å˜åŒ–ã€‚ç»™å®ƒä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå®ƒä¼šæ¶ˆè€—CPUå‘¨æœŸè¿›è¡Œç¼–ç ã€‚ç»™å®ƒä¸€ä¸ªæ•°å­—æ•°ç»„ï¼Œå®ƒä¼šè¿­ä»£å¹¶é€ä¸ªå¤åˆ¶å®ƒä»¬ã€‚ç»™å®ƒå¦ä¸€ä¸ªBufferï¼Œå®ƒä¼šåˆ›å»ºä¸€ä¸ªå®Œæ•´çš„å‰¯æœ¬ã€‚ä½†æ˜¯ï¼Œå¦‚æœå®ƒæ¥æ”¶åˆ°çš„åº•å±‚å†…å­˜æ˜¯åƒ`ArrayBuffer`çš„`.buffer`è¿™æ ·çš„ç‰¹å®šç±»å‹ï¼Œå®ƒå¯èƒ½ä¼šåˆ›å»ºå¯¹è¯¥å†…å­˜çš„*è§†å›¾*è€Œä¸æ˜¯å‰¯æœ¬ã€‚è¿™æ„å‘³ç€å¦‚æœåŸå§‹å†…å­˜å‘ç”Ÿå˜åŒ–ï¼Œä½ çš„â€œä¸å¯å˜â€Bufferä¼šé»˜é»˜åœ°ç ´åè‡ªå·±ã€‚å¦‚æœä½ ä¸å°å¿ƒï¼Œ`Buffer.from()`å¯èƒ½ä¼šå¯¼è‡´å¾®å¦™çš„å†…å­˜æŸåé”™è¯¯ï¼Œè¿™åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿½è¸ªèµ·æ¥æ˜¯ä¸€åœºå™©æ¢¦ã€‚'
- en: In short - start with `alloc()`. Use `allocUnsafe()` only when a profiler forces
    you to and you can guarantee a full, immediate overwrite. And triple-check what
    you're passing to `from()`, because its convenience hides dangerous complexity.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€è€Œè¨€ä¹‹ - ä»`alloc()`å¼€å§‹ã€‚åªæœ‰åœ¨åˆ†æå™¨å¼ºåˆ¶ä½ è¿™æ ·åšï¼Œå¹¶ä¸”ä½ å¯ä»¥ä¿è¯å®Œå…¨ã€ç«‹å³è¦†ç›–æ—¶æ‰ä½¿ç”¨`allocUnsafe()`ã€‚å¹¶ä¸”ä¸‰å€æ£€æŸ¥ä½ ä¼ é€’ç»™`from()`çš„å†…å®¹ï¼Œå› ä¸ºå®ƒçš„ä¾¿åˆ©æ€§éšè—äº†å±é™©å¤æ‚æ€§ã€‚
- en: You leaked passwords in un-initialized memory
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½ åœ¨æœªåˆå§‹åŒ–çš„å†…å­˜ä¸­æ³„éœ²äº†å¯†ç 
- en: Let's create an hypothetical scenario to make things interesting.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡è®¾åœºæ™¯æ¥ä½¿äº‹æƒ…å˜å¾—æœ‰è¶£ã€‚
- en: Imagine your'e working late night on a project trying to wrap tings up, and
    a tester living in a different timezone is screaming at you. Not for a crash,
    but for a high-priority customer ticket. A user is reporting that when they tried
    to download a PDF of their invoice, the file was corrupted. Weirdly, the corrupted
    file seems to contain a snippet of what looks like another user's API key. You
    dismiss it as a fluke, some bizarre client-side rendering bug. You apologize,
    manually regenerate the invoice, and try to go back to sleep.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹ä½ æ­£åœ¨æ·±å¤œä¸ºä¸€ä¸ªé¡¹ç›®å·¥ä½œï¼Œè¯•å›¾æŠŠäº‹æƒ…æå®šï¼Œè€Œä¸€ä¸ªç”Ÿæ´»åœ¨ä¸åŒæ—¶åŒºçš„æµ‹è¯•å‘˜æ­£åœ¨å¯¹ä½ å¤§å–Šå¤§å«ã€‚ä¸æ˜¯å´©æºƒï¼Œè€Œæ˜¯ä¸€å¼ é«˜ä¼˜å…ˆçº§çš„å®¢æˆ·å·¥å•ã€‚ä¸€ä¸ªç”¨æˆ·æŠ¥å‘Šè¯´ï¼Œå½“ä»–ä»¬å°è¯•ä¸‹è½½ä»–ä»¬çš„å‘ç¥¨PDFæ—¶ï¼Œæ–‡ä»¶è¢«æŸåäº†ã€‚å¥‡æ€ªçš„æ˜¯ï¼Œè¿™ä¸ªæŸåçš„æ–‡ä»¶ä¼¼ä¹åŒ…å«äº†ä¸€æ®µçœ‹èµ·æ¥åƒæ˜¯å¦ä¸€ä¸ªç”¨æˆ·çš„APIå¯†é’¥çš„ç‰‡æ®µã€‚ä½ æŠŠå®ƒå½“ä½œä¸€ä¸ªå¶ç„¶äº‹ä»¶ï¼Œä¸€äº›å¥‡æ€ªçš„å®¢æˆ·ç«¯æ¸²æŸ“é”™è¯¯ã€‚ä½ é“æ­‰ï¼Œæ‰‹åŠ¨é‡æ–°ç”Ÿæˆå‘ç¥¨ï¼Œç„¶åè¯•å›¾å›å»ç¡è§‰ã€‚
- en: But you can't. The "API key" part is nagging at you.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ä½ æ— æ³•åšåˆ°ã€‚é‚£ä¸ªâ€œAPIå¯†é’¥â€éƒ¨åˆ†è®©ä½ æ„Ÿåˆ°å›°æ‰°ã€‚
- en: 'You pull up the logs for the user''s request. There''s an error, but it''s
    not what you expect. It''s a downstream service complaining about a malformed
    request you sent it. You look at the payload logged for that outbound request.
    And... thatâ€™s when you realize something is seriously wrong. The JSON payload,
    which should contain invoice data, is mangled. It starts correctly, but then it''s
    trailed by gibberish. And in that gibberish, you see it plain as day - `...","line_items":
    [...], "total": 19.99}} ... bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...`. It''s
    a goddamn JSON Web Token. A session token from another user''s request, just sitting
    there, embedded in the middle of a corrupted invoice payload.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä½ è°ƒå‡ºç”¨æˆ·çš„è¯·æ±‚æ—¥å¿—ã€‚æœ‰ä¸€ä¸ªé”™è¯¯ï¼Œä½†ä¸æ˜¯ä½ é¢„æœŸçš„ã€‚æ˜¯ä¸‹æ¸¸æœåŠ¡æŠ±æ€¨ä½ å‘é€çš„è¯·æ±‚æ ¼å¼ä¸æ­£ç¡®ã€‚ä½ æŸ¥çœ‹è®°å½•çš„å‡ºç«™è¯·æ±‚çš„æœ‰æ•ˆè´Ÿè½½ã€‚ç„¶å...ä½ æ„è¯†åˆ°å‡ºäº†å¤§é—®é¢˜ã€‚åº”è¯¥åŒ…å«å‘ç¥¨æ•°æ®çš„JSONæœ‰æ•ˆè´Ÿè½½è¢«ç ´åäº†ã€‚å®ƒå¼€å§‹æ˜¯æ­£ç¡®çš„ï¼Œä½†éšåè¢«ä¹±ç æ‰€å°¾éšã€‚åœ¨é‚£ä¹±ç ä¸­ï¼Œä½ æ¸…æ¥šåœ°çœ‹åˆ°â€”â€”`...","line_items":
    [...], "total": 19.99}} ... bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...`ã€‚è¿™æ˜¯ä¸€ä¸ªè¯¥æ­»çš„JSON
    Web Tokenã€‚æ¥è‡ªå¦ä¸€ä¸ªç”¨æˆ·è¯·æ±‚çš„ä¼šè¯ä»¤ç‰Œï¼Œå°±é‚£æ ·é™é™åœ°ååœ¨ä¸€ä¸ªæŸåçš„å‘ç¥¨æœ‰æ•ˆè´Ÿè½½çš„ä¸­é—´ã€‚'
- en: How is this even possible? You trace the code from the invoice generation to
    the downstream API call. It's a simple workflow. Generate HTML for the invoice,
    convert it to a PDF stream, buffer the stream, and send it. You find the line
    where the buffer for the outbound request is created.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ€ä¹ˆå¯èƒ½å‘¢ï¼Ÿä½ è¿½è¸ªä»£ç ä»å‘ç¥¨ç”Ÿæˆåˆ°ä¸‹æ¸¸APIè°ƒç”¨çš„è¿‡ç¨‹ã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æµç¨‹ã€‚ç”Ÿæˆå‘ç¥¨çš„HTMLï¼Œå°†å…¶è½¬æ¢ä¸ºPDFæµï¼Œç¼“å†²æµï¼Œç„¶åå‘é€ã€‚ä½ æ‰¾åˆ°äº†åˆ›å»ºå‡ºç«™è¯·æ±‚ç¼“å†²åŒºçš„ä»£ç è¡Œã€‚
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`Buffer.allocUnsafe`. But why? You know what "unsafe" means in this context.
    It doesn''t mean "might throw an error." It means "contains uninitialized memory."
    It means you asked the operating system for a chunk of memory, and it gave you
    a pointer to a location that was just used by something else, without bothering
    to clean it up first. In this case, "something else" was a different request handler
    that had just finished processing another user''s authenticated request. Their
    JWT was still sitting in that memory segment.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`Buffer.allocUnsafe`ã€‚ä½†ä¸ºä»€ä¹ˆï¼Ÿä½ çŸ¥é“åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­â€œunsafeâ€æ„å‘³ç€ä»€ä¹ˆã€‚å®ƒå¹¶ä¸æ„å‘³ç€â€œå¯èƒ½ä¼šæŠ›å‡ºé”™è¯¯â€ã€‚å®ƒçš„æ„æ€æ˜¯â€œåŒ…å«æœªåˆå§‹åŒ–çš„å†…å­˜â€ã€‚å®ƒçš„æ„æ€æ˜¯ï¼Œä½ å‘æ“ä½œç³»ç»Ÿè¯·æ±‚äº†ä¸€å—å†…å­˜ï¼Œå®ƒç»™äº†ä½ ä¸€ä¸ªæŒ‡å‘åˆšåˆšè¢«å…¶ä»–ä¸œè¥¿ä½¿ç”¨çš„ä½ç½®çš„æŒ‡é’ˆï¼Œè€Œå®ƒæ²¡æœ‰å…ˆæ¸…ç†å®ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œâ€œå…¶ä»–ä¸œè¥¿â€æ˜¯ä¸€ä¸ªåˆšåˆšå¤„ç†å®Œå¦ä¸€ä¸ªç”¨æˆ·è®¤è¯è¯·æ±‚çš„ä¸åŒè¯·æ±‚å¤„ç†å™¨ã€‚ä»–ä»¬çš„JWTä»ç„¶ååœ¨é‚£ä¸ªå†…å­˜æ®µä¸­ã€‚'
- en: Your code calculated the `estimatedSize` incorrectly. It was too large. Your
    application wrote the valid invoice data into the beginning of the buffer but
    never overwrote the garbage at the end. And then it sent that entire buffer -
    your data plus another user's secrets - to the downstream service. And logged
    it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„ä»£ç è®¡ç®—äº†`estimatedSize`é”™è¯¯ã€‚å®ƒå¤ªå¤§ã€‚ä½ çš„åº”ç”¨ç¨‹åºå°†æœ‰æ•ˆçš„å‘ç¥¨æ•°æ®å†™å…¥ç¼“å†²åŒºçš„å¼€å§‹å¤„ï¼Œä½†ä»æœªè¦†ç›–æœ«å°¾çš„åƒåœ¾æ•°æ®ã€‚ç„¶åå®ƒå‘é€äº†æ•´ä¸ªç¼“å†²åŒºâ€”â€”ä½ çš„æ•°æ®å’Œå¦ä¸€ä¸ªç”¨æˆ·çš„ç§˜å¯†â€”â€”åˆ°ä¸‹æ¸¸æœåŠ¡ï¼Œå¹¶è®°å½•äº†å®ƒã€‚
- en: You start searching the logs for "bearer" and "password". The results scroll
    for what feels like an eternity. You've been leaking fragments of user secrets
    for months, ever since that "performance optimization" was checked in. Every time
    a buffer was allocated with `allocUnsafe` and not fully written to, you were playing
    Russian Roulette with your users' data. Tonight, the bullet landed. This isn't
    just a bug, instead it's a full-blown security breach, born from a single, misunderstood
    line of code.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¼€å§‹æœç´¢æ—¥å¿—ä¸­çš„â€œbearerâ€å’Œâ€œpasswordâ€ã€‚ç»“æœæ»šåŠ¨èµ·æ¥æ„Ÿè§‰åƒæ°¸æ’ã€‚è‡ªä»é‚£æ¬¡â€œæ€§èƒ½ä¼˜åŒ–â€è¢«æäº¤ä»¥æ¥ï¼Œä½ å·²ç»æ³„éœ²äº†å‡ ä¸ªæœˆçš„ç”¨æˆ·ç§˜å¯†ç‰‡æ®µã€‚æ¯æ¬¡ä½¿ç”¨`allocUnsafe`åˆ†é…ç¼“å†²åŒºè€Œæ²¡æœ‰å®Œå…¨å†™å…¥æ—¶ï¼Œä½ éƒ½åœ¨ç©ä¿„ç½—æ–¯è½®ç›˜èµŒï¼ŒèµŒçš„æ˜¯ç”¨æˆ·çš„æ•°æ®ã€‚ä»Šæ™šï¼Œå­å¼¹è½ä¸‹äº†ã€‚è¿™ä¸ä»…ä»…æ˜¯ä¸€ä¸ªé”™è¯¯ï¼Œè€Œæ˜¯ä¸€åœºå…¨é¢çš„å®‰å…¨æ¼æ´ï¼Œæºäºä¸€è¡Œè¢«è¯¯è§£çš„å•è¡Œä»£ç ã€‚
- en: Understanding Buffer Memory Architecture
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç†è§£ç¼“å†²å†…å­˜æ¶æ„
- en: Before we can really dissect the mess we've just found, we need to talk about
    how Node.js even handles memory. When you think about memory in a Node application,
    you're probably thinking about the V8 heap. This is where your JavaScript objects,
    strings, numbers, and functions live. It's managed by the V8 garbage collector
    (GC), which does a fantastic job of cleaning up objects you're no longer using.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çœŸæ­£å‰–ææˆ‘ä»¬åˆšåˆšæ‰¾åˆ°çš„æ··ä¹±ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è°ˆè°ˆ Node.js æ˜¯å¦‚ä½•å¤„ç†å†…å­˜çš„ã€‚å½“ä½ è€ƒè™‘ Node åº”ç”¨ç¨‹åºä¸­çš„å†…å­˜æ—¶ï¼Œä½ å¯èƒ½ä¼šæƒ³åˆ° V8 å †ã€‚è¿™æ˜¯ä½ çš„
    JavaScript å¯¹è±¡ã€å­—ç¬¦ä¸²ã€æ•°å­—å’Œå‡½æ•°æ‰€åœ¨çš„åœ°æ–¹ã€‚å®ƒç”± V8 åƒåœ¾æ”¶é›†å™¨ï¼ˆGCï¼‰ç®¡ç†ï¼Œå®ƒå‡ºè‰²åœ°æ¸…ç†äº†ä½ ä¸å†ä½¿ç”¨çš„å¯¹è±¡ã€‚
- en: However, Buffers are special. They are designed to handle binary data efficiently,
    often large amounts of it. Shoving megabytes of raw binary data into the V8 heap
    would be incredibly inefficient and would put immense pressure on the garbage
    collector. V8 is optimized for lots of small, interconnected JavaScript objects,
    not monolithic binary blobs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œç¼“å†²åŒºæ˜¯ç‰¹æ®Šçš„ã€‚å®ƒä»¬è¢«è®¾è®¡ç”¨æ¥é«˜æ•ˆåœ°å¤„ç†äºŒè¿›åˆ¶æ•°æ®ï¼Œé€šå¸¸æ˜¯å¤§é‡çš„æ•°æ®ã€‚å°†å…†å­—èŠ‚çš„åŸå§‹äºŒè¿›åˆ¶æ•°æ®å¡å…¥ V8 å †ä¼šéå¸¸ä½æ•ˆï¼Œå¹¶ä¸”ä¼šç»™åƒåœ¾æ”¶é›†å™¨å¸¦æ¥å·¨å¤§çš„å‹åŠ›ã€‚V8
    ä¼˜åŒ–ç”¨äºå¤§é‡å°å‹ã€ç›¸äº’å…³è”çš„ JavaScript å¯¹è±¡ï¼Œè€Œä¸æ˜¯å•ä¸€çš„äºŒè¿›åˆ¶å¤§å—ã€‚
- en: So, Node.js does something clever. A `Buffer` instance you create in your JavaScript
    code is actually a small object on the V8 heap that acts as a pointer or a handle.
    The *actual* binary data for the buffer lives *outside* the V8 heap in what's
    called "off-heap" memory. This is raw memory that Node.js requests directly from
    the underlying operating system, managed by Node's C++ core.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒNode.js åšäº†ä¸€äº›å·§å¦™çš„äº‹æƒ…ã€‚ä½ åœ¨ JavaScript ä»£ç ä¸­åˆ›å»ºçš„ `Buffer` å®ä¾‹å®é™…ä¸Šæ˜¯åœ¨ V8 å †ä¸Šçš„ä¸€ä¸ªå°å¯¹è±¡ï¼Œå®ƒå……å½“æŒ‡é’ˆæˆ–å¥æŸ„ã€‚ç¼“å†²åŒºçš„
    *å®é™…* äºŒè¿›åˆ¶æ•°æ®ç”Ÿæ´»åœ¨ V8 å †ä¹‹å¤–çš„æ‰€è°“ "å †å¤–" å†…å­˜ä¸­ã€‚è¿™æ˜¯ Node.js ç›´æ¥ä»åº•å±‚æ“ä½œç³»ç»Ÿè¯·æ±‚çš„åŸå§‹å†…å­˜ï¼Œç”± Node çš„ C++ æ ¸å¿ƒç®¡ç†ã€‚
- en: When you run `const buf = Buffer.alloc(1000)`, hereâ€™s what happens -
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ è¿è¡Œ `const buf = Buffer.alloc(1000)` æ—¶ï¼Œä»¥ä¸‹æ˜¯å‘ç”Ÿçš„æƒ…å†µ -
- en: Node's C++ side asks the OS for 1000 bytes of memory.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: èŠ‚ç‚¹çš„ C++ å±‚è¯·æ±‚æ“ä½œç³»ç»Ÿåˆ†é… 1000 å­—èŠ‚çš„å†…å­˜ã€‚
- en: The OS finds a free block and gives Node a memory address.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ“ä½œç³»ç»Ÿæ‰¾åˆ°ä¸€ä¸ªç©ºé—²å—ï¼Œå¹¶å°†å†…å­˜åœ°å€åˆ†é…ç»™èŠ‚ç‚¹ã€‚
- en: Node's C++ layer wraps this memory address.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: èŠ‚ç‚¹çš„ C++ å±‚å°è£…äº†è¿™ä¸ªå†…å­˜åœ°å€ã€‚
- en: Back in JavaScript, a small `Buffer` object is created on the V8 heap. This
    object contains properties like `length`, but most importantly, it holds an internal
    reference to that off-heap memory address.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å›åˆ° JavaScriptï¼Œä¸€ä¸ªå°çš„ `Buffer` å¯¹è±¡åœ¨ V8 å †ä¸Šåˆ›å»ºã€‚è¿™ä¸ªå¯¹è±¡åŒ…å« `length` ç­‰å±æ€§ï¼Œä½†æœ€é‡è¦çš„æ˜¯ï¼Œå®ƒæŒæœ‰å¯¹è¯¥å †å¤–å†…å­˜åœ°å€çš„å†…éƒ¨å¼•ç”¨ã€‚
- en: This separation is key to performance. You can pass these Buffers around in
    your JS code, and you're only ever moving the small V8 heap object, not the potentially
    huge chunk of binary data itself. The C++ bindings in Node's core (for things
    like `fs` and `net`) can then operate directly on that off-heap memory without
    having to constantly copy data back and forth between the JavaScript world and
    the C++ world.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§åˆ†ç¦»å¯¹äºæ€§èƒ½è‡³å…³é‡è¦ã€‚ä½ å¯ä»¥åœ¨ä½ çš„ JS ä»£ç ä¸­ä¼ é€’è¿™äº›ç¼“å†²åŒºï¼Œè€Œä½ åªæ˜¯åœ¨ç§»åŠ¨å°çš„ V8 å †å¯¹è±¡ï¼Œè€Œä¸æ˜¯å¯èƒ½å·¨å¤§çš„äºŒè¿›åˆ¶æ•°æ®å—æœ¬èº«ã€‚Node çš„æ ¸å¿ƒä¸­çš„
    C++ ç»‘å®šï¼ˆå¦‚ `fs` å’Œ `net`ï¼‰å¯ä»¥ç›´æ¥æ“ä½œè¿™ç§å †å¤–å†…å­˜ï¼Œè€Œæ— éœ€åœ¨ JavaScript ä¸–ç•Œå’Œ C++ ä¸–ç•Œä¹‹é—´ä¸æ–­å¤åˆ¶æ•°æ®ã€‚
- en: You can see this yourself. Run a simple Node script and check the memory usage.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥äº²è‡ªæŸ¥çœ‹ã€‚è¿è¡Œä¸€ä¸ªç®€å•çš„ Node è„šæœ¬å¹¶æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µã€‚
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The output will look something like this -
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå°†ç±»ä¼¼äºä»¥ä¸‹å†…å®¹ -
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Look at `heapUsed` versus `external`. The V8 heap is only using about 3.64 MB
    for the script's objects. But the `external` property shows the ~53 MB we allocated
    for our buffer. That's the off-heap memory in action.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹ä¸ `heapUsed` å’Œ `external` çš„å¯¹æ¯”ã€‚V8 å †åªä¸ºè„šæœ¬å¯¹è±¡ä½¿ç”¨äº†å¤§çº¦ 3.64 MB çš„å†…å­˜ã€‚ä½† `external` å±æ€§æ˜¾ç¤ºäº†ä¸ºæˆ‘ä»¬çš„ç¼“å†²åŒºåˆ†é…çš„
    ~53 MBã€‚è¿™å°±æ˜¯å †å¤–å†…å­˜çš„ä½œç”¨ã€‚
- en: This is also where the danger of `allocUnsafe` comes from. The memory managed
    by the V8 heap is always zeroed-out for security reasons when a new object is
    created. V8 will not show you leftover data from other objects. But the off-heap
    memory that Node manages is a different story. It's closer to the metal. When
    you use `allocUnsafe`, Node asks the OS for memory and just passes you the pointer.
    It skips the step of clearing that memory. The runtime allocator, for performance
    reasons, doesn't clear memory when it's **freed*.** It just marks it as "available."
    So you get whatever was there last. This is the fundamental architectural detail
    that creates the security risks we're about to explore.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿæ˜¯`allocUnsafe`å±é™©æ¥æºçš„åœ°æ–¹ã€‚å‡ºäºå®‰å…¨åŸå› ï¼ŒV8å †åœ¨åˆ›å»ºæ–°å¯¹è±¡æ—¶æ€»æ˜¯å°†å…¶å†…å­˜æ¸…é›¶ã€‚V8ä¸ä¼šæ˜¾ç¤ºæ¥è‡ªå…¶ä»–å¯¹è±¡é—ç•™çš„æ•°æ®ã€‚ä½†æ˜¯Nodeç®¡ç†çš„å †å¤–å†…å­˜æ˜¯å¦ä¸€å›äº‹ã€‚å®ƒæ›´æ¥è¿‘åº•å±‚ã€‚å½“ä½ ä½¿ç”¨`allocUnsafe`æ—¶ï¼ŒNodeä¼šå‘æ“ä½œç³»ç»Ÿè¯·æ±‚å†…å­˜ï¼Œç„¶åç›´æ¥å°†æŒ‡é’ˆä¼ é€’ç»™ä½ ã€‚å®ƒè·³è¿‡äº†æ¸…é™¤å†…å­˜çš„æ­¥éª¤ã€‚ä¸ºäº†æ€§èƒ½åŸå› ï¼Œè¿è¡Œæ—¶åˆ†é…å™¨åœ¨**é‡Šæ”¾**å†…å­˜æ—¶ä¸ä¼šæ¸…é™¤å†…å­˜ã€‚å®ƒåªæ˜¯å°†å…¶æ ‡è®°ä¸ºâ€œå¯ç”¨â€ã€‚æ‰€ä»¥ä½ å¾—åˆ°çš„æ˜¯ä¹‹å‰ç•™ä¸‹çš„ä»»ä½•ä¸œè¥¿ã€‚è¿™æ˜¯å³å°†æ¢è®¨çš„å®‰å…¨é£é™©çš„æ ¹æœ¬æ¶æ„ç»†èŠ‚ã€‚
- en: â„¹ï¸Note
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: '***When** your program frees memory, the allocator frequently hands that same
    memory back out later without wiping it. Nodeâ€™s buffer pool uses those reused
    pieces, so Buffer.allocUnsafe() can return bytes left over from earlier work.
    The operating system will zero memory when mapping it into another process, but
    it wonâ€™t always clear memory thatâ€™s being recycled inside your own process.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '***å½“ä½ çš„ç¨‹åºé‡Šæ”¾å†…å­˜æ—¶ï¼Œåˆ†é…å™¨ç»å¸¸åœ¨ç¨åæ²¡æœ‰æ“¦é™¤çš„æƒ…å†µä¸‹å°†ç›¸åŒçš„å†…å­˜è¿”å›ã€‚Nodeçš„ç¼“å†²æ± ä½¿ç”¨è¿™äº›é‡ç”¨çš„éƒ¨åˆ†ï¼Œæ‰€ä»¥Buffer.allocUnsafe()å¯ä»¥è¿”å›ä¹‹å‰å·¥ä½œç•™ä¸‹çš„å­—èŠ‚ã€‚æ“ä½œç³»ç»Ÿåœ¨å°†å…¶æ˜ å°„åˆ°å¦ä¸€ä¸ªè¿›ç¨‹æ—¶ä¼šå°†å†…å­˜æ¸…é›¶ï¼Œä½†ä¸ä¼šæ€»æ˜¯æ¸…é™¤ä½ è‡ªå·±çš„è¿›ç¨‹å†…éƒ¨æ­£åœ¨å›æ”¶çš„å†…å­˜**ã€‚'
- en: '`Buffer.alloc()`'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`Buffer.alloc()`'
- en: '`Buffer.alloc(size)` is the function you should be reaching for 99% of the
    time. It''s your safety net. Its behavior is simple, predictable, and secure.
    When you call it, it performs two distinct operations -'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`Buffer.alloc(size)`æ˜¯ä½ åœ¨99%çš„æƒ…å†µä¸‹åº”è¯¥ä½¿ç”¨çš„å‡½æ•°ã€‚å®ƒæ˜¯ä½ çš„å®‰å…¨ç½‘ã€‚å®ƒçš„è¡Œä¸ºç®€å•ã€å¯é¢„æµ‹ä¸”å®‰å…¨ã€‚å½“ä½ è°ƒç”¨å®ƒæ—¶ï¼Œå®ƒæ‰§è¡Œä¸¤ä¸ªä¸åŒçš„æ“ä½œ
    -'
- en: It requests a chunk of off-heap memory of the specified `size`, which is called
    **Allocation**.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ƒè¯·æ±‚æŒ‡å®š`size`çš„å †å¤–å†…å­˜å—ï¼Œè¿™è¢«ç§°ä¸º**åˆ†é…**ã€‚
- en: It then iterates over every single byte of that newly allocated memory and writes
    a `0x00` to it, and that's called **Zero-filling**.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åå®ƒéå†æ–°åˆ†é…å†…å­˜çš„æ¯ä¸€ä¸ªå­—èŠ‚ï¼Œå¹¶å°†å®ƒä»¬å†™å…¥`0x00`ï¼Œè¿™è¢«ç§°ä¸º**é›¶å¡«å……**ã€‚
- en: This second step is the crucial one. It guarantees that the buffer you receive
    is clean. It contains no leftover data from previous operations, no secrets, no
    garbage. It's a blank slate.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒæ­¥æ˜¯å…³é”®ã€‚å®ƒä¿è¯äº†ä½ æ”¶åˆ°çš„ç¼“å†²åŒºæ˜¯å¹²å‡€çš„ã€‚å®ƒä¸åŒ…å«æ¥è‡ªå…ˆå‰æ“ä½œé—ç•™çš„æ•°æ®ï¼Œæ²¡æœ‰ç§˜å¯†ï¼Œæ²¡æœ‰åƒåœ¾ã€‚å®ƒæ˜¯ä¸€å¼ ç™½çº¸ã€‚
- en: Let's see this in practice.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å®é™…æ“ä½œã€‚
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: No matter how many times you run this, no matter what your application was doing
    a millisecond before, the result is always the same - a buffer full of zeros.
    This predictability is why it's the default choice. You don't have to think about
    it. It just works. You can write data into it, knowing you started from a known-good
    state.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºä½ è¿è¡Œå¤šå°‘æ¬¡ï¼Œæ— è®ºä½ çš„åº”ç”¨ç¨‹åºåœ¨æ¯«ç§’å‰åšäº†ä»€ä¹ˆï¼Œç»“æœæ€»æ˜¯ç›¸åŒçš„â€”â€”ä¸€ä¸ªå……æ»¡é›¶çš„ç¼“å†²åŒºã€‚è¿™ç§å¯é¢„æµ‹æ€§æ˜¯å®ƒæˆä¸ºé»˜è®¤é€‰æ‹©çš„åŸå› ã€‚ä½ ä¸å¿…å»æƒ³å®ƒã€‚å®ƒåªæ˜¯å·¥ä½œã€‚ä½ å¯ä»¥å‘å…¶ä¸­å†™å…¥æ•°æ®ï¼ŒçŸ¥é“ä½ ä»ä¸€ä¸ªå·²çŸ¥è‰¯å¥½çš„çŠ¶æ€å¼€å§‹ã€‚
- en: But this safety comes at a cost. That zero-filling step is not free. It's a
    `memset(0)` call down in C++, which is a loop that writes to memory. For small
    buffers, this cost is negligible, lost in the noise of your application. But what
    happens when you're dealing with larger buffers, or you're allocating many smaller
    buffers in a tight loop?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™ç§å®‰å…¨æ˜¯æœ‰ä»£ä»·çš„ã€‚é‚£ä¸ªé›¶å¡«å……æ­¥éª¤ä¸æ˜¯å…è´¹çš„ã€‚åœ¨C++ä¸­ï¼Œè¿™æ˜¯ä¸€ä¸ª`memset(0)`è°ƒç”¨ï¼Œå®ƒæ˜¯ä¸€ä¸ªå†™å…¥å†…å­˜çš„å¾ªç¯ã€‚å¯¹äºå°ç¼“å†²åŒºï¼Œè¿™ä¸ªæˆæœ¬æ˜¯å¯ä»¥å¿½ç•¥ä¸è®¡çš„ï¼Œè¢«åº”ç”¨ç¨‹åºçš„å™ªéŸ³æ‰€æ©ç›–ã€‚ä½†æ˜¯å½“ä½ å¤„ç†å¤§ç¼“å†²åŒºï¼Œæˆ–è€…ä½ åœ¨ç´§å¯†å¾ªç¯ä¸­åˆ†é…è®¸å¤šå°ç¼“å†²åŒºæ—¶ä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ
- en: This brings us to our second hypothetical scenario, **The Mysterious Memory
    Spike**.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¼•å‡ºäº†æˆ‘ä»¬çš„ç¬¬äºŒä¸ªå‡è®¾åœºæ™¯ï¼Œ**ç¥ç§˜çš„å†…å­˜å³°å€¼**ã€‚
- en: You're on the team responsible for a high-throughput image processing service.
    The service receives image uploads, resizes them, and stores the results. For
    weeks, everything has been fine. But as traffic scales up, you start getting high-CPU
    alerts during peak hours. The service nodes are running at 95-100% CPU, latency
    skyrockets, and requests start timing out.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æ˜¯è´Ÿè´£ä¸€ä¸ªé«˜ååé‡å›¾åƒå¤„ç†æœåŠ¡çš„å›¢é˜Ÿçš„ä¸€å‘˜ã€‚è¯¥æœåŠ¡æ¥æ”¶å›¾åƒä¸Šä¼ ï¼Œè°ƒæ•´å¤§å°ï¼Œå¹¶å­˜å‚¨ç»“æœã€‚å‡ å‘¨æ¥ï¼Œä¸€åˆ‡éƒ½å¾ˆé¡ºåˆ©ã€‚ä½†éšç€æµé‡çš„å¢åŠ ï¼Œä½ åœ¨é«˜å³°æ—¶æ®µå¼€å§‹æ”¶åˆ°é«˜CPUè­¦æŠ¥ã€‚æœåŠ¡èŠ‚ç‚¹ä»¥95-100%çš„CPUè¿è¡Œï¼Œå»¶è¿Ÿé£™å‡ï¼Œè¯·æ±‚å¼€å§‹è¶…æ—¶ã€‚
- en: You pull a CPU profile from one of the struggling instances. You expect to see
    the bottleneck in the image resizing library (`sharp` or something similar), as
    that's the most computationally expensive work you're doing. But the profiler
    tells a different story. The hottest function, the one consuming the most CPU
    time, is internal to Node.js, and it's being called from one place in your code.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä»ä¸€ä¸ªè‹¦è‹¦æŒ£æ‰çš„å®ä¾‹ä¸­æ‹‰å–äº† CPU é…ç½®æ–‡ä»¶ã€‚ä½ é¢„è®¡ä¼šåœ¨å›¾åƒç¼©æ”¾åº“ï¼ˆ`sharp` æˆ–ç±»ä¼¼åº“ï¼‰ä¸­çœ‹åˆ°ç“¶é¢ˆï¼Œå› ä¸ºé‚£æ˜¯æœ€æ˜‚è´µçš„è®¡ç®—å·¥ä½œã€‚ä½†åˆ†æå™¨å‘Šè¯‰äº†ä¸€ä¸ªä¸åŒçš„æ•…äº‹ã€‚æœ€çƒ­çš„å‡½æ•°ï¼Œæ¶ˆè€—æœ€å¤š
    CPU æ—¶é—´çš„å‡½æ•°ï¼Œæ˜¯ Node.js å†…éƒ¨çš„ï¼Œå¹¶ä¸”å®ƒè¢«è°ƒç”¨åœ¨æ‚¨çš„ä»£ç ä¸­çš„ä¸€ä¸ªåœ°æ–¹ã€‚
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The service is handling thousands of chunks per second, and each one allocates
    a new, zero-filled buffer. The sheer volume of `Buffer.alloc()` calls means the
    CPUs are spending a significant portion of their time just... writing zeros to
    memory. The image processing logic is fast, but it's being starved of CPU cycles
    by the memory allocation strategy.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æœåŠ¡æ¯ç§’å¤„ç†æ•°åƒä¸ªå—ï¼Œæ¯ä¸ªå—éƒ½ä¼šåˆ†é…ä¸€ä¸ªæ–°çš„ã€é›¶å¡«å……çš„ç¼“å†²åŒºã€‚`Buffer.alloc()` è°ƒç”¨çš„å·¨å¤§æ•°é‡æ„å‘³ç€ CPU çš„å¤§é‡æ—¶é—´éƒ½èŠ±åœ¨äº†ä»…ä»…...å‘å†…å­˜å†™å…¥é›¶ä¸Šã€‚å›¾åƒå¤„ç†é€»è¾‘å¾ˆå¿«ï¼Œä½†å®ƒæ­£è¢«å†…å­˜åˆ†é…ç­–ç•¥æ‰€æ¶ˆè€—çš„
    CPU å‘¨æœŸæ‰€æ‹–ç´¯ã€‚
- en: This is the trade-off of `Buffer.alloc()`. Its safety and predictability are
    paid for in CPU cycles. In most web applications, handling JSON APIs or database
    results, this cost is utterly irrelevant. The network I/O or database query time
    will dwarf the allocation time. But in high-performance, data-intensive applications
    like video streaming, real-time data processing, or our image service, that cost
    can become the primary performance bottleneck.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ `Buffer.alloc()` çš„æƒè¡¡ã€‚å®ƒçš„å®‰å…¨æ€§å’Œå¯é¢„æµ‹æ€§æ˜¯ä»¥ CPU å‘¨æœŸä¸ºä»£ä»·çš„ã€‚åœ¨å¤§å¤šæ•° Web åº”ç”¨ä¸­ï¼Œå¤„ç† JSON API æˆ–æ•°æ®åº“ç»“æœï¼Œè¿™ç§æˆæœ¬å®Œå…¨æ— å…³ç´§è¦ã€‚ç½‘ç»œ
    I/O æˆ–æ•°æ®åº“æŸ¥è¯¢æ—¶é—´å°†è¿œè¿œè¶…è¿‡åˆ†é…æ—¶é—´ã€‚ä½†åœ¨é«˜æ€§èƒ½ã€æ•°æ®å¯†é›†å‹åº”ç”¨ï¼Œå¦‚è§†é¢‘æµã€å®æ—¶æ•°æ®å¤„ç†æˆ–æˆ‘ä»¬çš„å›¾åƒæœåŠ¡ä¸­ï¼Œè¿™ç§æˆæœ¬å¯èƒ½æˆä¸ºä¸»è¦çš„æ€§èƒ½ç“¶é¢ˆã€‚
- en: ğŸ’¡Tip
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡æç¤º
- en: If you're writing CPU/data-intensive applications in Node.js, stop right there.
    There are always better tools for different tasks. Do not limit yourself for the
    sake of sticking to a single language or framework. Node.js shines for I/O-bound,
    event-driven workloads, but when it comes to heavy computation, consider alternatives
    like Rust, Go, C++, or even offloading the work to specialized services. You donâ€™t
    need to use Node.js everywhere.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ­£åœ¨ Node.js ä¸­ç¼–å†™ CPU/æ•°æ®å¯†é›†å‹åº”ç”¨ç¨‹åºï¼Œè¯·ç«‹å³åœæ­¢ã€‚å¯¹äºä¸åŒçš„ä»»åŠ¡ï¼Œæ€»æœ‰æ›´å¥½çš„å·¥å…·ã€‚ä¸è¦ä¸ºäº†åšæŒå•ä¸€è¯­è¨€æˆ–æ¡†æ¶è€Œé™åˆ¶è‡ªå·±ã€‚Node.js
    åœ¨ I/O å¯†é›†å‹ã€äº‹ä»¶é©±åŠ¨çš„å·¥ä½œè´Ÿè½½ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å½“æ¶‰åŠåˆ°é‡è®¡ç®—æ—¶ï¼Œè¯·è€ƒè™‘æ›¿ä»£æ–¹æ¡ˆï¼Œå¦‚ Rustã€Goã€C++ï¼Œç”šè‡³å°†å·¥ä½œå¸è½½åˆ°ä¸“ç”¨æœåŠ¡ã€‚æ‚¨ä¸éœ€è¦åœ¨æ‰€æœ‰åœ°æ–¹éƒ½ä½¿ç”¨
    Node.jsã€‚
- en: Knowing this, a developer on your team might be tempted to "optimize" the code
    by switching to `Buffer.allocUnsafe()`. And without understanding the consequences,
    they are about to trade a performance problem for a security catastrophe.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: äº†è§£è¿™ä¸€ç‚¹åï¼Œæ‚¨çš„å›¢é˜Ÿä¸­çš„ä¸€ä½å¼€å‘è€…å¯èƒ½ä¼šè¢«è¯±æƒ‘é€šè¿‡åˆ‡æ¢åˆ° `Buffer.allocUnsafe()` æ¥â€œä¼˜åŒ–â€ä»£ç ã€‚è€Œä¸”åœ¨ä¸ç†è§£åæœçš„æƒ…å†µä¸‹ï¼Œä»–ä»¬å³å°†ç”¨æ€§èƒ½é—®é¢˜æ¢å–ä¸€åœºå®‰å…¨ç¾éš¾ã€‚
- en: '`Buffer.allocUnsafe()`'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`Buffer.allocUnsafe()`'
- en: This is the function that gets people into trouble. `Buffer.allocUnsafe(size)`
    is the evil twin of `Buffer.alloc()`. They both ask the OS for memory, but `allocUnsafe`
    completely skips the second step - the zero-filling. It returns the raw, untouched
    memory segment. This makes it significantly faster, because it does less work.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯è®©äººä»¬é™·å…¥éº»çƒ¦çš„å‡½æ•°ã€‚`Buffer.allocUnsafe(size)` æ˜¯ `Buffer.alloc()` çš„é‚ªæ¶åŒèƒèƒã€‚å®ƒä»¬éƒ½å‘æ“ä½œç³»ç»Ÿè¯·æ±‚å†…å­˜ï¼Œä½†
    `allocUnsafe` å®Œå…¨è·³è¿‡äº†ç¬¬äºŒæ­¥â€”â€”é›¶å¡«å……ã€‚å®ƒè¿”å›åŸå§‹çš„ã€æœªä¿®æ”¹çš„å†…å­˜æ®µã€‚è¿™ä½¿å¾—å®ƒæ˜¾è‘—æ›´å¿«ï¼Œå› ä¸ºå®ƒåšçš„å·¥ä½œæ›´å°‘ã€‚
- en: How much faster? We'll look at hard numbers later, but for a large allocation,
    it can be an order of magnitude or more. It's the kind of performance gain that
    makes engineers feel clever. It's also the kind of "cleverness" that leads to
    security breaches like the one in our opening story.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šå¿«ï¼Ÿæˆ‘ä»¬ç¨åä¼šçœ‹åˆ°ç¡¬æ•°æ®ï¼Œä½†å¯¹äºå¤§é‡åˆ†é…ï¼Œå®ƒå¯èƒ½æ˜¯ä¸€ä¸ªæ•°é‡çº§æˆ–æ›´å¤šã€‚è¿™æ˜¯é‚£ç§è®©å·¥ç¨‹å¸ˆæ„Ÿåˆ°èªæ˜çš„æ€§èƒ½æå‡ã€‚å®ƒä¹Ÿæ˜¯é‚£ç§å¯¼è‡´å®‰å…¨æ¼æ´çš„â€œèªæ˜â€ï¼Œå°±åƒæˆ‘ä»¬å¼€å¤´æ•…äº‹ä¸­çš„é‚£æ ·ã€‚
- en: Here's a more realistic scenario. Imagine a web server handling two concurrent
    requests -
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªæ›´ç°å®çš„åœºæ™¯ã€‚æƒ³è±¡ä¸€ä¸ªå¤„ç†ä¸¤ä¸ªå¹¶å‘è¯·æ±‚çš„ Web æœåŠ¡å™¨ -
- en: '**Request A (User 1) -**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¯·æ±‚ Aï¼ˆç”¨æˆ· 1ï¼‰-**'
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Request B (User 2) -**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¯·æ±‚ Bï¼ˆç”¨æˆ· 2ï¼‰-**'
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If Request B runs just after Request A, the memory slot used for `sessionBuffer`
    might be (in a rare event) immediately reused for `reportBuffer`. When User 2
    receives their report, it will contain 500 bytes of valid data, followed by 524
    bytes of whatever was left over in memory - which could very well be User 1's
    admin session token. You have now leaked admin credentials to a regular user.
    This is the direct, predictable outcome of misusing this API.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœè¯·æ±‚Bç´§æ¥åœ¨è¯·æ±‚Aä¹‹åè¿è¡Œï¼Œç”¨äº`sessionBuffer`çš„å†…å­˜æ§½ä½å¯èƒ½ä¼šï¼ˆåœ¨ç½•è§äº‹ä»¶ä¸­ï¼‰ç«‹å³è¢«é‡æ–°ç”¨äº`reportBuffer`ã€‚å½“ç”¨æˆ·2æ”¶åˆ°ä»–ä»¬çš„æŠ¥å‘Šæ—¶ï¼Œå®ƒå°†åŒ…å«500å­—èŠ‚çš„æœ‰æ•ˆæ•°æ®ï¼Œéšåæ˜¯524å­—èŠ‚çš„å†…å­˜ä¸­å‰©ä½™çš„ä»»ä½•å†…å®¹â€”â€”è¿™å¯èƒ½æ˜¯ç”¨æˆ·1çš„ç®¡ç†ä¼šè¯ä»¤ç‰Œã€‚ä½ ç°åœ¨å·²ç»å°†ç®¡ç†å‡­è¯æ³„éœ²ç»™äº†æ™®é€šç”¨æˆ·ã€‚è¿™æ˜¯è¯¯ç”¨æ­¤APIçš„ç›´æ¥ã€å¯é¢„æµ‹çš„ç»“æœã€‚
- en: So when is it ever acceptable to use `Buffer.allocUnsafe()`? There is only one
    rule - **You must use it only when you can guarantee that you will write to every
    single byte of the buffer's memory range immediately after allocation.**
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œä½•æ—¶ä½¿ç”¨`Buffer.allocUnsafe()`æ˜¯å¯æ¥å—çš„ï¼Ÿåªæœ‰ä¸€ä¸ªè§„åˆ™â€”â€”**ä½ å¿…é¡»ç¡®ä¿åœ¨åˆ†é…åç«‹å³å†™å…¥ç¼“å†²åŒºå†…å­˜èŒƒå›´çš„æ¯ä¸ªå­—èŠ‚ã€‚**
- en: A perfect example is reading from a file.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå®Œç¾çš„ä¾‹å­æ˜¯ä»æ–‡ä»¶ä¸­è¯»å–ã€‚
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: â„¹ï¸Note
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: You can prefer `allocUnsafeSlow()` as an alternative that never uses the internal
    pool (less prone to pool-based reuse) if pool reuse is a concern.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ‹…å¿ƒæ± çš„é‡å¤ä½¿ç”¨ï¼Œä½ å¯ä»¥é€‰æ‹©`allocUnsafeSlow()`ä½œä¸ºæ›¿ä»£æ–¹æ¡ˆï¼Œå®ƒæ°¸è¿œä¸ä¼šä½¿ç”¨å†…éƒ¨æ± ï¼ˆä¸å¤ªå¯èƒ½åŸºäºæ± çš„é‡å¤ä½¿ç”¨ï¼‰ã€‚
- en: In this case, we allocate a buffer, and in the very next instruction, we hand
    it to a system call (`fs.readSync`) that promises to fill it from start to finish
    with data from the disk. The window where the uninitialized data could be exposed
    is infinitesimally small and contained entirely within this single operation.
    This is a valid, safe, and performant use of `allocUnsafe`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åˆ†é…ä¸€ä¸ªç¼“å†²åŒºï¼Œåœ¨æ¥ä¸‹æ¥çš„æŒ‡ä»¤ä¸­ï¼Œæˆ‘ä»¬å°†å…¶ä¼ é€’ç»™ä¸€ä¸ªç³»ç»Ÿè°ƒç”¨ï¼ˆ`fs.readSync`ï¼‰ï¼Œè¯¥è°ƒç”¨æ‰¿è¯ºä»ç£ç›˜ä»å¤´åˆ°å°¾å¡«å……æ•°æ®ã€‚æœªåˆå§‹åŒ–æ•°æ®å¯èƒ½æš´éœ²çš„çª—å£æå°ï¼Œå¹¶ä¸”å®Œå…¨åŒ…å«åœ¨è¿™ä¸ªå•ä¸€æ“ä½œä¸­ã€‚è¿™æ˜¯æœ‰æ•ˆã€å®‰å…¨ä¸”é«˜æ•ˆçš„`allocUnsafe`ä½¿ç”¨ã€‚
- en: If your code has any logic - any `if` statement, any loop that might terminate
    early, any chance of error - between the `allocUnsafe` call and the point where
    the buffer is fully overwritten, you are creating a security vulnerability. It's
    not a matter of "if," but "when" it will burn you.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çš„ä»£ç åœ¨`allocUnsafe`è°ƒç”¨å’Œç¼“å†²åŒºè¢«å®Œå…¨è¦†ç›–çš„ç‚¹ä¹‹é—´æœ‰ä»»ä½•é€»è¾‘â€”â€”ä»»ä½•`if`è¯­å¥ã€ä»»ä½•å¯èƒ½æå‰ç»ˆæ­¢çš„å¾ªç¯ã€ä»»ä½•é”™è¯¯çš„å¯èƒ½æ€§â€”â€”ä½ æ­£åœ¨åˆ›å»ºä¸€ä¸ªå®‰å…¨æ¼æ´ã€‚è¿™ä¸æ˜¯â€œæ˜¯å¦â€çš„é—®é¢˜ï¼Œè€Œæ˜¯â€œä½•æ—¶â€ä¼šçƒ§æ¯ä½ çš„é—®é¢˜ã€‚
- en: '`Buffer.from()`'
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`Buffer.from()`'
- en: At first glance, `Buffer.from()` seems like the most helpful of the bunch. It's
    a versatile *factory* function that creates a buffer from almost anything you
    throw at it - a string, an array, another buffer, an `ArrayBuffer`. This convenience
    is its greatest strength and its most dangerous trap. Unlike `alloc` and `allocUnsafe`,
    which are about memory initialization, `Buffer.from()` is about data interpretation
    and copying, and its behavior can have subtle and disastrous consequences for
    both performance and data integrity.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹ä¸€çœ‹ï¼Œ`Buffer.from()`ä¼¼ä¹æ˜¯å…¶ä¸­æœ€æœ‰å¸®åŠ©çš„ã€‚å®ƒæ˜¯ä¸€ä¸ªé€šç”¨çš„*å·¥å‚*å‡½æ•°ï¼Œå¯ä»¥ä»ä½ æ‰”ç»™å®ƒçš„å‡ ä¹æ‰€æœ‰ä¸œè¥¿ä¸­åˆ›å»ºä¸€ä¸ªç¼“å†²åŒºâ€”â€”ä¸€ä¸ªå­—ç¬¦ä¸²ã€ä¸€ä¸ªæ•°ç»„ã€å¦ä¸€ä¸ªç¼“å†²åŒºã€ä¸€ä¸ª`ArrayBuffer`ã€‚è¿™ç§ä¾¿åˆ©æ€§æ˜¯å…¶æœ€å¤§çš„ä¼˜åŠ¿ï¼Œä¹Ÿæ˜¯å…¶æœ€å±é™©çš„é™·é˜±ã€‚ä¸`alloc`å’Œ`allocUnsafe`ä¸åŒï¼Œå®ƒä»¬å…³äºå†…å­˜åˆå§‹åŒ–ï¼Œ`Buffer.from()`å…³äºæ•°æ®è§£é‡Šå’Œå¤åˆ¶ï¼Œå…¶è¡Œä¸ºå¯èƒ½ä¼šå¯¹æ€§èƒ½å’Œæ•°æ®å®Œæ•´æ€§äº§ç”Ÿå¾®å¦™å’Œç¾éš¾æ€§çš„åæœã€‚
- en: Let's break down its different forms.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åˆ†è§£å®ƒçš„ä¸åŒå½¢å¼ã€‚
- en: '**`Buffer.from(string, [encoding])`**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Buffer.from(string, [encoding])`**'
- en: This is the most common use case. You have a string, and you want its binary
    representation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æœ€å¸¸è§çš„ç”¨ä¾‹ã€‚ä½ æœ‰ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä½ æƒ³è¦å®ƒçš„äºŒè¿›åˆ¶è¡¨ç¤ºã€‚
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This looks simple, but it's not a zero-cost operation. Node has to iterate through
    the string and transcode the characters into the specified encoding. For UTF-8,
    this is usually fast. But if you're working with other encodings or very large
    strings in a hot path, this transcoding can show up on a CPU profile. More importantly,
    it allocates a *new* buffer and *copies* the resulting bytes into it. This is
    generally what you want, but you need to be aware that it's a copy, not a view.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœ‹èµ·æ¥å¾ˆç®€å•ï¼Œä½†å¹¶ä¸æ˜¯é›¶æˆæœ¬æ“ä½œã€‚Nodeå¿…é¡»éå†å­—ç¬¦ä¸²å¹¶å°†å­—ç¬¦è½¬æ¢ä¸ºæŒ‡å®šçš„ç¼–ç ã€‚å¯¹äºUTF-8ï¼Œè¿™é€šå¸¸å¾ˆå¿«ã€‚ä½†å¦‚æœä½ åœ¨çƒ­è·¯å¾„ä¸Šå¤„ç†å…¶ä»–ç¼–ç æˆ–éå¸¸å¤§çš„å­—ç¬¦ä¸²ï¼Œè¿™ç§è½¬æ¢å¯èƒ½ä¼šå‡ºç°åœ¨CPUåˆ†æä¸­ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå®ƒåˆ†é…äº†ä¸€ä¸ª*æ–°*ç¼“å†²åŒºå¹¶å°†ç”Ÿæˆçš„å­—èŠ‚å¤åˆ¶åˆ°å…¶ä¸­ã€‚è¿™é€šå¸¸æ˜¯ä½ è¦çš„ï¼Œä½†ä½ éœ€è¦æ„è¯†åˆ°è¿™æ˜¯ä¸€ä¸ªå¤åˆ¶ï¼Œè€Œä¸æ˜¯è§†å›¾ã€‚
- en: '**`Buffer.from(buffer)`**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Buffer.from(buffer)`**'
- en: This also creates a copy. If you pass an existing buffer to `Buffer.from()`,
    it will allocate a new buffer of the same size and copy the full contents of the
    source buffer into the new one.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿä¼šåˆ›å»ºä¸€ä¸ªå‰¯æœ¬ã€‚å¦‚æœä½ å°†ç°æœ‰çš„ç¼“å†²åŒºä¼ é€’ç»™`Buffer.from()`ï¼Œå®ƒå°†åˆ†é…ä¸€ä¸ªå¤§å°ç›¸åŒçš„æ–°ç¼“å†²åŒºï¼Œå¹¶å°†æºç¼“å†²åŒºçš„å…¨éƒ¨å†…å®¹å¤åˆ¶åˆ°æ–°ç¼“å†²åŒºä¸­ã€‚
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Modifying `buf2` does not affect `buf1`. This is safe and predictable, but again,
    be mindful of the performance implication of copying large buffers.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä¿®æ”¹`buf2`ä¸ä¼šå½±å“`buf1`ã€‚è¿™æ˜¯å®‰å…¨ä¸”å¯é¢„æµ‹çš„ï¼Œä½†åŒæ ·ï¼Œè¦æ³¨æ„å¤åˆ¶å¤§å‹ç¼“å†²åŒºçš„æ€§èƒ½å½±å“ã€‚
- en: '**`Buffer.from(array)`**'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Buffer.from(array)`**'
- en: You can create a buffer from an array of bytes.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ä»å­—èŠ‚æ•°ç»„åˆ›å»ºä¸€ä¸ªç¼“å†²åŒºã€‚
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is handy for constructing buffers from constants, but it's slow for large
    arrays. Node has to iterate the JavaScript array, check each element, and copy
    the value into the off-heap buffer. It's much less efficient than working with
    buffers directly.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¹äºä»å¸¸é‡æ„é€ ç¼“å†²åŒºå¾ˆæœ‰ç”¨ï¼Œä½†å¯¹äºå¤§å‹æ•°ç»„æ¥è¯´é€Ÿåº¦è¾ƒæ…¢ã€‚Nodeå¿…é¡»è¿­ä»£JavaScriptæ•°ç»„ï¼Œæ£€æŸ¥æ¯ä¸ªå…ƒç´ ï¼Œå¹¶å°†å€¼å¤åˆ¶åˆ°å †å¤–ç¼“å†²åŒºã€‚è¿™æ¯”ç›´æ¥å¤„ç†ç¼“å†²åŒºè¦ä½æ•ˆå¾—å¤šã€‚
- en: '**`Buffer.from(arrayBuffer)`**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Buffer.from(arrayBuffer)`**'
- en: This is the trickiest one.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å…¶ä¸­æœ€å¤æ‚çš„ä¸€ä¸ªã€‚
- en: An `ArrayBuffer` is a raw binary data object in JavaScript. They are often used
    by browser APIs (like `fetch` or `FileReader`) and some Node libraries. The key
    difference is that `Buffer.from(arrayBuffer)` can, depending on the context, create
    a *view* that shares the same underlying memory as the `ArrayBuffer`, not a copy.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨JavaScriptä¸­ï¼Œ`ArrayBuffer`æ˜¯ä¸€ä¸ªåŸå§‹çš„äºŒè¿›åˆ¶æ•°æ®å¯¹è±¡ã€‚å®ƒä»¬é€šå¸¸ç”±æµè§ˆå™¨APIï¼ˆå¦‚`fetch`æˆ–`FileReader`ï¼‰å’Œä¸€äº›Nodeåº“ä½¿ç”¨ã€‚å…³é”®åŒºåˆ«åœ¨äº`Buffer.from(arrayBuffer)`å¯ä»¥æ ¹æ®ä¸Šä¸‹æ–‡åˆ›å»ºä¸€ä¸ªä¸`ArrayBuffer`å…±äº«ç›¸åŒåº•å±‚å†…å­˜çš„*è§†å›¾*ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå‰¯æœ¬ã€‚
- en: Imagine a file upload service. A library gives you the uploaded file as an `ArrayBuffer`.
    Your code needs to process the first few bytes to detect the file type, and another
    part of your application needs to scan the whole file for viruses.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸ªæ–‡ä»¶ä¸Šä¼ æœåŠ¡ã€‚ä¸€ä¸ªåº“ç»™ä½ ä¸Šä¼ çš„æ–‡ä»¶ä½œä¸º`ArrayBuffer`ã€‚ä½ çš„ä»£ç éœ€è¦å¤„ç†å‰å‡ ä¸ªå­—èŠ‚ä»¥æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼Œè€Œåº”ç”¨ç¨‹åºçš„å¦ä¸€ä¸ªéƒ¨åˆ†éœ€è¦æ‰«ææ•´ä¸ªæ–‡ä»¶ä»¥æŸ¥æ‰¾ç—…æ¯’ã€‚
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Your `headerBuffer` looks correct at first. You read the magic numbers and determine
    it's a JPEG file. But while you're processing it, the `sanitizeFileInMemory` function
    runs. It modifies the original `arrayBuffer` directly. Because your `headerBuffer`
    is just a view into that *same memory*, its contents are now silently changed
    out from under you.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„`headerBuffer`ä¸€å¼€å§‹çœ‹èµ·æ¥æ˜¯æ­£ç¡®çš„ã€‚ä½ è¯»å–äº†é­”æ•°å¹¶ç¡®å®šå®ƒæ˜¯ä¸€ä¸ªJPEGæ–‡ä»¶ã€‚ä½†åœ¨ä½ å¤„ç†å®ƒçš„æ—¶å€™ï¼Œ`sanitizeFileInMemory`å‡½æ•°è¿è¡Œäº†ã€‚å®ƒç›´æ¥ä¿®æ”¹äº†åŸå§‹çš„`arrayBuffer`ã€‚å› ä¸ºä½ çš„`headerBuffer`åªæ˜¯å¯¹é‚£ä¸ª*ç›¸åŒå†…å­˜*çš„ä¸€ä¸ªè§†å›¾ï¼Œæ‰€ä»¥å®ƒçš„å†…å®¹ç°åœ¨åœ¨ä½ ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹è¢«é»˜é»˜åœ°æ”¹å˜äº†ã€‚
- en: Suddenly, your file type detection logic fails intermittently. Data you thought
    was constant and immutable has been corrupted by a completely different part of
    your application. This is a nightmare to debug. There are no errors, no crashes
    - just inconsistent results. You might spend days chasing race conditions in your
    logic, when the root cause is a misunderstanding of whether `Buffer.from()` is
    performing a copy or creating a shared-memory view.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: çªç„¶ï¼Œä½ çš„æ–‡ä»¶ç±»å‹æ£€æµ‹é€»è¾‘é—´æ­‡æ€§å¤±è´¥ã€‚ä½ æœ¬ä»¥ä¸ºæ’å®šä¸å˜çš„æ•°æ®å·²ç»è¢«åº”ç”¨ç¨‹åºçš„å¦ä¸€ä¸ªå®Œå…¨ä¸åŒçš„éƒ¨åˆ†æŸåäº†ã€‚è¿™è®©äººéš¾ä»¥è°ƒè¯•ã€‚æ²¡æœ‰é”™è¯¯ï¼Œæ²¡æœ‰å´©æºƒï¼Œåªæœ‰ä¸ä¸€è‡´çš„ç»“æœã€‚ä½ å¯èƒ½è¦èŠ±å‡ å¤©æ—¶é—´è¿½è¸ªä½ çš„é€»è¾‘ä¸­çš„ç«äº‰æ¡ä»¶ï¼Œè€Œæ ¹æœ¬åŸå› æ˜¯å¯¹`Buffer.from()`æ˜¯åœ¨æ‰§è¡Œå¤åˆ¶è¿˜æ˜¯åˆ›å»ºå…±äº«å†…å­˜è§†å›¾çš„ç†è§£é”™è¯¯ã€‚
- en: Let's walk through the sequence of events to understand how this can cause issues.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡äº‹ä»¶çš„é¡ºåºæ¥äº†è§£è¿™å¯èƒ½ä¼šå¼•èµ·çš„é—®é¢˜ã€‚
- en: First, the code does its initial check on the file header. It reads the first
    few bytes from `headerBuffer`, confirms it's a valid PNG file, and feels good
    about itself. Based on this, it decides to kick off an asynchronous operation,
    like looking up user permissions in a database before it continues processing
    the image.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œä»£ç å¯¹å…¶æ–‡ä»¶å¤´è¿›è¡Œåˆå§‹æ£€æŸ¥ã€‚å®ƒä»`headerBuffer`ä¸­è¯»å–å‰å‡ ä¸ªå­—èŠ‚ï¼Œç¡®è®¤å®ƒæ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„PNGæ–‡ä»¶ï¼Œå¹¶å¯¹è‡ªå·±æ„Ÿåˆ°æ»¡æ„ã€‚åŸºäºæ­¤ï¼Œå®ƒå†³å®šå¯åŠ¨ä¸€ä¸ªå¼‚æ­¥æ“ä½œï¼Œæ¯”å¦‚åœ¨ç»§ç»­å¤„ç†å›¾åƒä¹‹å‰ï¼Œå…ˆåœ¨æ•°æ®åº“ä¸­æŸ¥æ‰¾ç”¨æˆ·æƒé™ã€‚
- en: While your code is waiting for the database to respond, it yields control (we
    already learnt about this in a previous chapter). The JavaScript event loop, looks
    around for other work to do. It's not going to just sit idle. It sees another
    task waiting in the queue, a security function we wrote called `sanitizeFileInMemory`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ çš„ä»£ç ç­‰å¾…æ•°æ®åº“å“åº”æ—¶ï¼Œå®ƒé‡Šæ”¾äº†æ§åˆ¶æƒï¼ˆæˆ‘ä»¬å·²ç»åœ¨ä¹‹å‰çš„ç« èŠ‚ä¸­å­¦ä¹ äº†è¿™ä¸€ç‚¹ï¼‰ã€‚JavaScriptäº‹ä»¶å¾ªç¯ä¼šå¯»æ‰¾å…¶ä»–å¯ä»¥æ‰§è¡Œçš„å·¥ä½œã€‚å®ƒä¸ä¼šåªæ˜¯é—²ç½®ã€‚å®ƒçœ‹åˆ°é˜Ÿåˆ—ä¸­è¿˜æœ‰å¦ä¸€ä¸ªä»»åŠ¡ç­‰å¾…ï¼Œè¿™æ˜¯æˆ‘ä»¬ç¼–å†™çš„åä¸º`sanitizeFileInMemory`çš„å®‰å…¨å‡½æ•°ã€‚
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This is the critical moment. The `sanitizeFileInMemory` function was designed
    to scan the *entire file* and scrub any potentially malicious byte patterns. It
    gets passed the original `arrayBuffer`. It finds something it doesn't like at,
    say, byte number 10, and overwrites it with zeros.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å…³é”®æ—¶åˆ»ã€‚`sanitizeFileInMemory`å‡½æ•°è¢«è®¾è®¡ä¸ºæ‰«æ*æ•´ä¸ªæ–‡ä»¶*å¹¶æ¸…é™¤ä»»ä½•æ½œåœ¨çš„æ¶æ„å­—èŠ‚æ¨¡å¼ã€‚å®ƒæ¥æ”¶åŸå§‹çš„`arrayBuffer`ã€‚å®ƒåœ¨ç¬¬10ä¸ªå­—èŠ‚å¤„å‘ç°äº†ä¸€äº›å®ƒä¸å–œæ¬¢çš„ä¸œè¥¿ï¼Œå¹¶ç”¨é›¶è¦†ç›–äº†å®ƒã€‚
- en: Because `headerBuffer` is just a view pointing to that same memory, the data
    it's looking at has just been changed out from under it. There's no warning, no
    error. The memory was altered, and since `headerBuffer` is just a window into
    that memory, its contents are now different.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸º`headerBuffer`åªæ˜¯ä¸€ä¸ªæŒ‡å‘ç›¸åŒå†…å­˜çš„è§†å›¾ï¼Œæ‰€ä»¥å®ƒæ‰€æŸ¥çœ‹çš„æ•°æ®å·²ç»è¢«ä»å…¶ä¸‹æ›´æ”¹ã€‚æ²¡æœ‰è­¦å‘Šï¼Œæ²¡æœ‰é”™è¯¯ã€‚å†…å­˜è¢«æ›´æ”¹äº†ï¼Œè€Œ`headerBuffer`åªæ˜¯è¯¥å†…å­˜çš„ä¸€ä¸ªçª—å£ï¼Œå…¶å†…å®¹ç°åœ¨ä¸åŒäº†ã€‚
- en: A few milliseconds later, our database query finishes. Your original function
    wakes up, ready to finish its work. It now tries to use `headerBuffer` again,
    perhaps to read the image dimensions. But the data at byte 10 is no longer what
    it expects. The header is now corrupt from its point of view. Your logic fails,
    maybe it throws a weird error, or maybe it just produces garbage data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ æ¯«ç§’åï¼Œæˆ‘ä»¬çš„æ•°æ®åº“æŸ¥è¯¢å®Œæˆã€‚ä½ çš„åŸå§‹å‡½æ•°é†’æ¥ï¼Œå‡†å¤‡å®Œæˆå…¶å·¥ä½œã€‚ç°åœ¨å®ƒè¯•å›¾å†æ¬¡ä½¿ç”¨`headerBuffer`ï¼Œå¯èƒ½ç”¨äºè¯»å–å›¾åƒå°ºå¯¸ã€‚ä½†å­—èŠ‚10çš„æ•°æ®ä¸å†æ˜¯å®ƒé¢„æœŸçš„ã€‚ä»å®ƒçš„è§’åº¦æ¥çœ‹ï¼Œæ ‡é¢˜ç°åœ¨å·²æŸåã€‚ä½ çš„é€»è¾‘å¤±è´¥äº†ï¼Œå¯èƒ½æŠ›å‡ºä¸€ä¸ªå¥‡æ€ªçš„é”™è¯¯ï¼Œæˆ–è€…å¯èƒ½åªæ˜¯äº§ç”Ÿåƒåœ¾æ•°æ®ã€‚
- en: And that's the bug. It only happens when the sanitizer runs in that tiny window
    of time after you've checked the header but before you're done using it. It's
    a classic race condition, where two separate parts of your program are racing
    to use and modify a shared piece of memory, and the outcome depends on the exact
    order they run in. This is why it's so hard to debug - when you try to trace it,
    the timing changes, and the bug disappears.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯bugã€‚å®ƒåªåœ¨ä½ æ£€æŸ¥æ ‡é¢˜åä½†åœ¨å®Œæˆä½¿ç”¨å®ƒä¹‹å‰è¿è¡Œçš„å¾®å°æ—¶é—´çª—å£ä¸­å‘ç”Ÿã€‚è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„ç«æ€æ¡ä»¶ï¼Œå…¶ä¸­ä½ çš„ç¨‹åºçš„ä¸¤ä¸ªä¸åŒéƒ¨åˆ†æ­£åœ¨äº‰å¤ºä½¿ç”¨å’Œä¿®æ”¹å…±äº«å†…å­˜ï¼Œç»“æœå–å†³äºå®ƒä»¬è¿è¡Œçš„ç²¾ç¡®é¡ºåºã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒå¦‚æ­¤éš¾ä»¥è°ƒè¯•â€”â€”å½“ä½ å°è¯•è¿½è¸ªå®ƒæ—¶ï¼Œæ—¶é—´ä¼šæ”¹å˜ï¼Œbugå°±ä¼šæ¶ˆå¤±ã€‚
- en: The rule of thumb - when you receive data from an external source (especially
    as an `ArrayBuffer`), and you need to ensure its integrity for an operation, create
    an explicit copy with `Buffer.alloc()` and `.copy()` rather than relying on the
    ambiguous behavior of `Buffer.from()`.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¸è§„è§„åˆ™â€”â€”å½“ä½ ä»å¤–éƒ¨æºï¼ˆå°¤å…¶æ˜¯ä½œä¸º`ArrayBuffer`ï¼‰æ¥æ”¶æ•°æ®ï¼Œå¹¶ä¸”éœ€è¦ç¡®ä¿å…¶å®Œæ•´æ€§è¿›è¡Œæ“ä½œæ—¶ï¼Œä½¿ç”¨`Buffer.alloc()`å’Œ`.copy()`åˆ›å»ºä¸€ä¸ªæ˜¾å¼çš„å‰¯æœ¬ï¼Œè€Œä¸æ˜¯ä¾èµ–äº`Buffer.from()`çš„æ¨¡ç³Šè¡Œä¸ºã€‚
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Buffer Pooling and the 8KB Secret
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¼“å†²åŒºæ± å’Œ8KBçš„ç§˜å¯†
- en: We've talked about how `allocUnsafe` gives you memory with "old data" in it,
    but where does that old data come from? Is it random junk from other processes
    on the server? Sometimes. But more often, and more dangerously, it comes from
    *your own process*. This is due to an internal performance optimization in Node.js
    called Buffer pooling.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»è®¨è®ºäº†`allocUnsafe`å¦‚ä½•ç»™ä½ å¸¦æœ‰â€œæ—§æ•°æ®â€çš„å†…å­˜ï¼Œä½†é‚£äº›æ—§æ•°æ®ä»ä½•è€Œæ¥ï¼Ÿæ˜¯æ¥è‡ªæœåŠ¡å™¨ä¸Šå…¶ä»–è¿›ç¨‹çš„éšæœºåƒåœ¾æ•°æ®ï¼Ÿæœ‰æ—¶æ˜¯ã€‚ä½†æ›´å¸¸è§ä¸”æ›´å±é™©çš„æ˜¯ï¼Œå®ƒä»¬æ¥è‡ª**ä½ è‡ªå·±çš„è¿›ç¨‹**ã€‚è¿™æ˜¯ç”±äºNode.jså†…éƒ¨çš„ä¸€ä¸ªæ€§èƒ½ä¼˜åŒ–ï¼Œç§°ä¸ºBufferæ± ã€‚
- en: Constantly asking the operating system for small chunks of memory is inefficient.
    There's a certain amount of overhead to each `malloc` call. To speed things up,
    for Buffers smaller than a certain threshold, Node.js doesn't allocate them one
    by one. Instead, it pre-allocates a larger, 8KB chunk of memory - the pool.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æŒç»­å‘æ“ä½œç³»ç»Ÿè¯·æ±‚å°å—å†…å­˜æ˜¯ä¸é«˜æ•ˆçš„ã€‚æ¯æ¬¡`malloc`è°ƒç”¨éƒ½ä¼šäº§ç”Ÿä¸€å®šçš„å¼€é”€ã€‚ä¸ºäº†åŠ å¿«é€Ÿåº¦ï¼Œå¯¹äºå°äºæŸä¸ªé˜ˆå€¼çš„ç¼“å†²åŒºï¼ŒNode.jsä¸ä¼šé€ä¸ªåˆ†é…å®ƒä»¬ã€‚ç›¸åï¼Œå®ƒä¼šé¢„å…ˆåˆ†é…ä¸€ä¸ªæ›´å¤§çš„ã€8KBçš„å†…å­˜å—â€”â€”å³æ± ã€‚
- en: When you call `Buffer.allocUnsafe(100)`, Node doesn't ask the OS for 100 bytes.
    It checks its internal 8KB pool. If there's space, it slices off 100 bytes from
    the pool and gives you a Buffer that points to that slice. When your Buffer is
    garbage collected, that 100-byte slice isn't returned to the OS - it's just marked
    as available again within the pool.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ è°ƒç”¨`Buffer.allocUnsafe(100)`æ—¶ï¼ŒNodeä¸ä¼šå‘æ“ä½œç³»ç»Ÿè¯·æ±‚100å­—èŠ‚ã€‚å®ƒä¼šæ£€æŸ¥å…¶å†…éƒ¨çš„8KBæ± ã€‚å¦‚æœæœ‰ç©ºé—´ï¼Œå®ƒä¼šä»æ± ä¸­åˆ‡å‡º100å­—èŠ‚å¹¶ç»™ä½ ä¸€ä¸ªæŒ‡å‘è¯¥åˆ‡ç‰‡çš„Bufferã€‚å½“ä½ çš„Bufferè¢«åƒåœ¾å›æ”¶æ—¶ï¼Œé‚£100å­—èŠ‚çš„åˆ‡ç‰‡ä¸ä¼šè¿”å›ç»™æ“ä½œç³»ç»Ÿâ€”â€”å®ƒåªæ˜¯åœ¨æ± ä¸­æ ‡è®°ä¸ºå¯ç”¨ã€‚
- en: This is a huge performance win. It makes allocating small Buffers incredibly
    fast. Both `Buffer.allocUnsafe()` and `Buffer.from()` use this pool for small
    allocations. `Buffer.alloc()` *can* use it, but since it has to zero-fill the
    memory anyway, the performance benefit is less about reuse and more about avoiding
    the `malloc` overhead.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„æ€§èƒ½æå‡ã€‚å®ƒä½¿å¾—åˆ†é…å°å—Bufferå˜å¾—éå¸¸å¿«ã€‚`Buffer.allocUnsafe()`å’Œ`Buffer.from()`éƒ½ä½¿ç”¨è¿™ä¸ªæ± è¿›è¡Œå°åˆ†é…ã€‚`Buffer.alloc()`ä¹Ÿå¯ä»¥ä½¿ç”¨å®ƒï¼Œä½†ç”±äºå®ƒå¿…é¡»ç”¨é›¶å¡«å……å†…å­˜ï¼Œæ€§èƒ½ä¼˜åŠ¿æ›´å¤šåœ°ä¸é‡ç”¨æ— å…³ï¼Œè€Œæ˜¯ä¸é¿å…`malloc`å¼€é”€æœ‰å…³ã€‚
- en: Now, connect this to the security implications.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå°†è¿™è¿æ¥åˆ°å®‰å…¨å½±å“ã€‚
- en: The data you find in an `allocUnsafe` buffer is very likely to be data from
    another Buffer, from your own application, that was recently used and discarded.
    The 8KB pool is a hotbed of recently-used sensitive information.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨`allocUnsafe`ç¼“å†²åŒºä¸­æ‰¾åˆ°çš„æ•°æ®å¾ˆå¯èƒ½æ¥è‡ªå¦ä¸€ä¸ªBufferï¼Œæ¥è‡ªæ‚¨è‡ªå·±çš„åº”ç”¨ï¼Œè¿™æ˜¯æœ€è¿‘ä½¿ç”¨å¹¶ä¸¢å¼ƒçš„æ•°æ®ã€‚8KBæ± æ˜¯æœ€è¿‘ä½¿ç”¨æ•æ„Ÿä¿¡æ¯çš„æ¸©åºŠã€‚
- en: Let's revisit our JWT leak scenario with this knowledge.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨è¿™ä¸ªçŸ¥è¯†å›é¡¾æˆ‘ä»¬çš„JWTæ³„éœ²åœºæ™¯ã€‚
- en: '**Request 1** comes in for User A. Your code creates a 200-byte Buffer to hold
    their session data. This buffer is sliced from the 8KB internal pool.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è¯·æ±‚1**ä¸ºç”¨æˆ·Aåˆ°æ¥ã€‚æ‚¨çš„ä»£ç åˆ›å»ºä¸€ä¸ª200å­—èŠ‚çš„Bufferæ¥ä¿å­˜ä»–ä»¬çš„ä¼šè¯æ•°æ®ã€‚è¿™ä¸ªç¼“å†²åŒºæ˜¯ä»8KBå†…éƒ¨æ± ä¸­åˆ‡åˆ†çš„ã€‚'
- en: The request finishes. The session buffer is no longer referenced and becomes
    eligible for garbage collection. Its 200-byte slice within the pool is now considered
    "free." The data (the JWT) is still sitting there.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯·æ±‚å®Œæˆã€‚ä¼šè¯ç¼“å†²åŒºä¸å†è¢«å¼•ç”¨ï¼Œå¹¶ç¬¦åˆåƒåœ¾å›æ”¶çš„æ¡ä»¶ã€‚å®ƒåœ¨æ± ä¸­çš„200å­—èŠ‚åˆ‡ç‰‡ç°åœ¨è¢«è®¤ä¸ºæ˜¯â€œç©ºé—²â€çš„ã€‚æ•°æ®ï¼ˆJWTï¼‰ä»ç„¶åœ¨é‚£é‡Œã€‚
- en: '**Request 2** comes in for User B, milliseconds later. Your code calls `Buffer.allocUnsafe(500)`.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è¯·æ±‚2**åœ¨å‡ æ¯«ç§’åä¸ºç”¨æˆ·Båˆ°æ¥ã€‚æ‚¨çš„ä»£ç è°ƒç”¨`Buffer.allocUnsafe(500)`ã€‚'
- en: Node sees this is less than 8KB and goes to the pool. It finds a free slot -
    perhaps the very same 200-byte slice from Request 1, plus the 300 bytes next to
    it - and gives it to you.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nodeçœ‹åˆ°è¿™å°äº8KBï¼Œå°±è½¬å‘æ± ä¸­ã€‚å®ƒæ‰¾åˆ°ä¸€ä¸ªç©ºé—²æ§½ä½â€”â€”å¯èƒ½æ˜¯æ¥è‡ªè¯·æ±‚1çš„200å­—èŠ‚åˆ‡ç‰‡ï¼Œä»¥åŠæ—è¾¹çš„300å­—èŠ‚â€”â€”ç„¶åå°†å…¶åˆ†é…ç»™æ‚¨ã€‚
- en: Your `allocUnsafe` buffer now contains, as its first 200 bytes, the complete
    session data for User A.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‚¨çš„`allocUnsafe`ç¼“å†²åŒºç°åœ¨åŒ…å«çš„å‰200å­—èŠ‚æ˜¯ç”¨æˆ·Açš„å®Œæ•´ä¼šè¯æ•°æ®ã€‚
- en: This isn't a theoretical risk. It's the mechanism by which your application
    will leak its own secrets to itself. The pool turns your application's memory
    space into a tiny, high-speed ecosystem of data recycling. Using `allocUnsafe`
    is like drinking from that recycling system without filtering it first.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸æ˜¯ç†è®ºé£é™©ã€‚è¿™æ˜¯æ‚¨çš„åº”ç”¨å°†è‡ªèº«ç§˜å¯†æ³„éœ²ç»™è‡ªèº«çš„æœºåˆ¶ã€‚æ± å°†æ‚¨çš„åº”ç”¨å†…å­˜ç©ºé—´å˜æˆä¸€ä¸ªå¾®å°ã€é«˜é€Ÿçš„æ•°æ®å›æ”¶ç”Ÿæ€ç³»ç»Ÿã€‚ä½¿ç”¨`allocUnsafe`å°±åƒåœ¨æ²¡æœ‰è¿‡æ»¤çš„æƒ…å†µä¸‹ä»å›æ”¶ç³»ç»Ÿä¸­å–æ°´ã€‚
- en: The default pool size is 8KB (`Buffer.poolSize`). You can change it, but you
    shouldn't. Changing it is a signal that you're trying to micro-optimize something
    you likely don't fully understand. The sane default exists for a reason.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: é»˜è®¤æ± å¤§å°æ˜¯8KBï¼ˆ`Buffer.poolSize`ï¼‰ã€‚æ‚¨å¯ä»¥æ›´æ”¹å®ƒï¼Œä½†æ‚¨ä¸åº”è¯¥ã€‚æ›´æ”¹å®ƒæ˜¯ä¸€ä¸ªä¿¡å·ï¼Œè¡¨æ˜æ‚¨æ­£åœ¨å°è¯•å¾®ä¼˜åŒ–æ‚¨å¯èƒ½ä¸å®Œå…¨ç†è§£çš„ä¸œè¥¿ã€‚åˆç†çš„é»˜è®¤å€¼å­˜åœ¨æ˜¯æœ‰åŸå› çš„ã€‚
- en: The takeaway is simple. The Buffer pool makes small, unsafe allocations even
    more dangerous because it increases the probability that the "uninitialized" data
    you get back is not just random noise, but highly sensitive, structured data from
    another part of your own application.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ç‚¹å¾ˆç®€å•ã€‚ç¼“å†²åŒºæ± ä½¿å¾—å°å‹ã€ä¸å®‰å…¨çš„åˆ†é…æ›´åŠ å±é™©ï¼Œå› ä¸ºå®ƒå¢åŠ äº†æ‚¨å¾—åˆ°â€œæœªåˆå§‹åŒ–â€çš„æ•°æ®ä¸æ˜¯éšæœºå™ªå£°ï¼Œè€Œæ˜¯æ¥è‡ªæ‚¨è‡ªå·±åº”ç”¨å¦ä¸€éƒ¨åˆ†é«˜åº¦æ•æ„Ÿã€ç»“æ„åŒ–æ•°æ®çš„æ¦‚ç‡ã€‚
- en: Let's measure the performance
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥è¡¡é‡ä¸€ä¸‹æ€§èƒ½
- en: Let's put some hard numbers behind these claims. The performance difference
    between `alloc` and `allocUnsafe` isn't sutle, it's a cliff.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨ä¸€äº›ç¡¬æ€§æ•°å­—æ¥æ”¯æŒè¿™äº›è¯´æ³•ã€‚`alloc`å’Œ`allocUnsafe`ä¹‹é—´çš„æ€§èƒ½å·®å¼‚å¹¶ä¸ç»†å¾®ï¼Œè€Œæ˜¯ä¸€ä¸ªæ‚¬å´–ã€‚
- en: We'll run a simple benchmark. Allocate a buffer of a specific size 10,000 times
    and measure how long it takes. The code for these benchmarks can be found in `examples/buffer-allocation-patterns/benchmark.js`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è¿è¡Œä¸€ä¸ªç®€å•çš„åŸºå‡†æµ‹è¯•ã€‚åˆ†é…ä¸€ä¸ªç‰¹å®šå¤§å°çš„ç¼“å†²åŒº10,000æ¬¡ï¼Œå¹¶æµ‹é‡æ‰€éœ€æ—¶é—´ã€‚è¿™äº›åŸºå‡†æµ‹è¯•çš„ä»£ç å¯ä»¥åœ¨`examples/buffer-allocation-patterns/benchmark.js`ä¸­æ‰¾åˆ°ã€‚
- en: '[PRE14]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Scenario 1 - Small Allocations (100 bytes)
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœºæ™¯1 - å°å‹åˆ†é…ï¼ˆ100å­—èŠ‚ï¼‰
- en: This is the case where buffer pooling is active.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç¼“å†²åŒºæ± æ´»è·ƒçš„æƒ…å†µã€‚
- en: '[PRE15]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Here, `allocUnsafe` is about **2.5 times faster**. The cost of zero-filling
    100 bytes is small, but repeated 10,000 times, it adds up. `allocUnsafe` just
    grabs a slice from the pre-allocated pool, which is extremely fast.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œ`allocUnsafe`å¤§çº¦**å¿«äº†2.5å€**ã€‚å¡«å……100å­—èŠ‚çš„æˆæœ¬å¾ˆå°ï¼Œä½†é‡å¤10,000æ¬¡ï¼Œå°±ä¼šç´¯ç§¯èµ·æ¥ã€‚`allocUnsafe`åªæ˜¯ä»é¢„åˆ†é…çš„æ± ä¸­æŠ“å–ä¸€ä¸ªåˆ‡ç‰‡ï¼Œè¿™éå¸¸å¿«ã€‚
- en: Scenario 2 - Medium Allocations (10KB)
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœºæ™¯2 - ä¸­å‹åˆ†é…ï¼ˆ10KBï¼‰
- en: This is just above the default 8KB pool size, so every allocation has to go
    to the OS.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åˆšåˆšè¶…è¿‡é»˜è®¤çš„8KBæ± å¤§å°ï¼Œå› æ­¤æ¯æ¬¡åˆ†é…éƒ½å¿…é¡»è½¬åˆ°æ“ä½œç³»ç»Ÿã€‚
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Interestingly, in this case `allocUnsafe` is actually **1.3 times slower** on
    this system. Here, the overhead is a mix of the `malloc` call itself and the time
    spent zero-filling the 10KB of memory.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è¶£çš„æ˜¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ`allocUnsafe`åœ¨è¿™ä¸ªç³»ç»Ÿä¸Šå®é™…ä¸Š**æ…¢äº†1.3å€**ã€‚è¿™é‡Œçš„å¼€é”€æ˜¯`malloc`è°ƒç”¨æœ¬èº«å’Œå¡«å……10KBå†…å­˜æ‰€èŠ±è´¹çš„æ—¶é—´çš„æ··åˆã€‚
- en: Scenario 3 - Large Allocations (1MB)
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœºæ™¯3 - å¤§å‹åˆ†é…ï¼ˆ1MBï¼‰
- en: This is where you're handling file uploads, video streams, or other large binary
    data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ‚¨å¤„ç†æ–‡ä»¶ä¸Šä¼ ã€è§†é¢‘æµæˆ–å…¶ä»–å¤§å‹äºŒè¿›åˆ¶æ•°æ®çš„åœ°æ–¹ã€‚
- en: '[PRE17]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now look at that. `Buffer.allocUnsafe` is **1.2 times faster**. This is a notable
    performance difference, though less dramatic than on some systems. The cost of
    asking the OS for a megabyte of memory is still dwarfed by the cost of writing
    zeros to all 1,048,576 bytes of it. 1151ms is a huge amount of time to spend just
    allocating memory. If this is in the path of a user request, you've just added
    significant latency for no reason other than memory initialization.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨çœ‹çœ‹è¿™ä¸ªã€‚`Buffer.allocUnsafe`æ˜¯**1.2å€æ›´å¿«**ã€‚è¿™æ˜¯ä¸€ä¸ªæ˜æ˜¾çš„æ€§èƒ½å·®å¼‚ï¼Œå°½ç®¡åœ¨æŸäº›ç³»ç»Ÿä¸Šä¸å¦‚ä¹‹å‰é‚£ä¹ˆæˆå‰§åŒ–ã€‚å‘æ“ä½œç³»ç»Ÿè¯·æ±‚1MBå†…å­˜çš„æˆæœ¬ä»ç„¶è¢«å†™å…¥æ‰€æœ‰1,048,576ä¸ªå­—èŠ‚çš„é›¶çš„æˆæœ¬æ‰€æ·¹æ²¡ã€‚1151msæ˜¯åœ¨ä»…åˆ†é…å†…å­˜ä¸ŠèŠ±è´¹çš„å¤§é‡æ—¶é—´ã€‚å¦‚æœè¿™æ˜¯ç”¨æˆ·è¯·æ±‚çš„è·¯å¾„ï¼Œä½ åªæ˜¯å› ä¸ºå†…å­˜åˆå§‹åŒ–è€Œæ·»åŠ äº†æ˜¾è‘—çš„å»¶è¿Ÿã€‚
- en: When a profiler tells you that you're spending 80% of your CPU time in `Buffer.alloc`,
    even a 1.2x speedup can be tempting. It feels like free performance. But as we've
    established, the cost isn't paid in CPU cycles; it's paid in security risk.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ€§èƒ½åˆ†æå™¨å‘Šè¯‰ä½ ä½ åœ¨`Buffer.alloc`ä¸ŠèŠ±è´¹äº†80%çš„CPUæ—¶é—´ï¼Œå³ä½¿1.2å€çš„é€Ÿåº¦æå‡ä¹Ÿå¯èƒ½å¾ˆæœ‰å¸å¼•åŠ›ã€‚è¿™æ„Ÿè§‰åƒæ˜¯å…è´¹çš„æ€§èƒ½ã€‚ä½†æ­£å¦‚æˆ‘ä»¬å·²ç»å»ºç«‹çš„ï¼Œæˆæœ¬ä¸æ˜¯ä»¥CPUå‘¨æœŸæ¥æ”¯ä»˜çš„ï¼›å®ƒæ˜¯æ”¯ä»˜åœ¨å®‰å…¨é£é™©ä¸Šã€‚
- en: '`Buffer.from()` Performance'
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`Buffer.from()` æ€§èƒ½'
- en: What about `Buffer.from()`? Its performance is entirely dependent on the source.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆ`Buffer.from()`å‘¢ï¼Ÿå®ƒçš„æ€§èƒ½å®Œå…¨å–å†³äºæºã€‚
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Creating a 1MB buffer from a 1MB string takes about **1.42ms**. This is the
    cost of UTF-8 encoding and copying.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ä»1MBå­—ç¬¦ä¸²åˆ›å»ºä¸€ä¸ª1MBç¼“å†²åŒºå¤§çº¦éœ€è¦**1.42ms**ã€‚è¿™æ˜¯UTF-8ç¼–ç å’Œå¤åˆ¶çš„æˆæœ¬ã€‚
- en: Copying an existing 1MB buffer takes only **0.24ms**. This is a highly optimized
    `memcpy` operation. It's incredibly fast, but still a cost to be aware of if you're
    doing it in a loop.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: å¤åˆ¶ç°æœ‰çš„1MBç¼“å†²åŒºåªéœ€**0.24ms**ã€‚è¿™æ˜¯ä¸€ä¸ªé«˜åº¦ä¼˜åŒ–çš„`memcpy`æ“ä½œã€‚å®ƒéå¸¸å¿«ï¼Œä½†å¦‚æœä½ åœ¨å¾ªç¯ä¸­è¿™æ ·åšï¼Œä»ç„¶æ˜¯ä¸€ä¸ªéœ€è¦æ„è¯†åˆ°çš„æˆæœ¬ã€‚
- en: These numbers give you a mental model for making decisions. Is your allocation
    size small? The performance difference is likely negligible. Is it large? The
    difference is massive, and you need to think carefully. Is the allocation on a
    hot path that runs thousands of times per second? Even small differences can add
    up. The only way to know for sure is to **profile your application under realistic
    load**. Don't guess. Don't optimize prematurely. Measure, identify the bottleneck,
    and then use these numbers to understand the trade-offs of your solution.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ•°å­—ä¸ºä½ æä¾›äº†ä¸€ä¸ªå¿ƒç†æ¨¡å‹æ¥åšå‡ºå†³ç­–ã€‚ä½ çš„åˆ†é…å¤§å°å°å—ï¼Ÿæ€§èƒ½å·®å¼‚å¯èƒ½å¾®ä¸è¶³é“ã€‚å¤§å—ï¼Ÿå·®å¼‚å·¨å¤§ï¼Œä½ éœ€è¦ä»”ç»†æ€è€ƒã€‚åˆ†é…åœ¨æ¯ç§’è¿è¡Œæ•°åƒæ¬¡çš„â€œçƒ­ç‚¹è·¯å¾„â€ä¸Šå—ï¼Ÿå³ä½¿æ˜¯å°çš„å·®å¼‚ä¹Ÿå¯èƒ½ç´¯ç§¯èµ·æ¥ã€‚å”¯ä¸€ç¡®å®šçš„æ–¹æ³•æ˜¯åœ¨**å®é™…è´Ÿè½½ä¸‹å¯¹åº”ç”¨ç¨‹åºè¿›è¡Œæ€§èƒ½åˆ†æ**ã€‚ä¸è¦çŒœæµ‹ã€‚ä¸è¦è¿‡æ—©ä¼˜åŒ–ã€‚æµ‹é‡ï¼Œè¯†åˆ«ç“¶é¢ˆï¼Œç„¶åä½¿ç”¨è¿™äº›æ•°å­—æ¥ç†è§£ä½ è§£å†³æ–¹æ¡ˆçš„æƒè¡¡ã€‚
- en: Security Implications and Attack Vectors
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®‰å…¨å½±å“å’Œæ”»å‡»å‘é‡
- en: We've focused on the most obvious security hole - leaking sensitive data through
    uninitialized memory from `allocUnsafe`. But the implications are broader and
    more subtle than that one catastrophic failure mode. Let's think like an attacker.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»å…³æ³¨äº†æœ€æ˜æ˜¾çš„å®‰å…¨æ¼æ´â€”â€”é€šè¿‡`allocUnsafe`æœªåˆå§‹åŒ–çš„å†…å­˜æ³„éœ²æ•æ„Ÿæ•°æ®ã€‚ä½†å½±å“æ¯”è¿™ç§ç¾éš¾æ€§çš„å¤±è´¥æ¨¡å¼æ›´å¹¿æ³›ã€æ›´å¾®å¦™ã€‚è®©æˆ‘ä»¬åƒæ”»å‡»è€…ä¸€æ ·æ€è€ƒã€‚
- en: Direct Information Disclosure (The Obvious One)
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç›´æ¥ä¿¡æ¯æ³„éœ²ï¼ˆæ˜¾è€Œæ˜“è§çš„ä¸€ç§ï¼‰
- en: This is the `allocUnsafe` scenario we've covered extensively. An attacker receives
    a response, a file, or triggers an error log that contains data from another user
    or the system itself. This data can include -
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬å·²ç»å¹¿æ³›è®¨è®ºè¿‡çš„`allocUnsafe`åœºæ™¯ã€‚æ”»å‡»è€…æ”¶åˆ°ä¸€ä¸ªå“åº”ã€ä¸€ä¸ªæ–‡ä»¶æˆ–è§¦å‘ä¸€ä¸ªåŒ…å«æ¥è‡ªå…¶ä»–ç”¨æˆ·æˆ–ç³»ç»Ÿæœ¬èº«çš„æ•°æ®çš„é”™è¯¯æ—¥å¿—ã€‚è¿™äº›æ•°æ®å¯ä»¥åŒ…æ‹¬
    -
- en: Session tokens, API keys, JWTs
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¼šè¯ä»¤ç‰Œã€APIå¯†é’¥ã€JWT
- en: Passwords, password hashes, or salts in transit
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ä¼ è¾“ä¸­çš„å¯†ç ã€å¯†ç æ•£åˆ—æˆ–ç›
- en: Database credentials or connection strings
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®åº“å‡­æ®æˆ–è¿æ¥å­—ç¬¦ä¸²
- en: PII (personally identifiable information) like names, emails, addresses
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PIIï¼ˆä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼‰å¦‚å§“åã€ç”µå­é‚®ä»¶ã€åœ°å€
- en: Encryption keys
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŠ å¯†å¯†é’¥
- en: Fragments of TLS certificates or private keys
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TLSè¯ä¹¦æˆ–ç§é’¥ç‰‡æ®µ
- en: The key vulnerability is any place where `Buffer.allocUnsafe(size)` is called,
    and the subsequent logic fails to overwrite the *entire* buffer. This can happen
    due to incorrect size calculations, early-`return` error paths, or optimistic
    `try...catch` blocks that don't properly handle the partially-filled buffer.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: å…³é”®æ¼æ´æ˜¯ä»»ä½•è°ƒç”¨`Buffer.allocUnsafe(size)`çš„åœ°æ–¹ï¼Œåç»­é€»è¾‘æœªèƒ½è¦†ç›–**æ•´ä¸ª**ç¼“å†²åŒºã€‚è¿™å¯èƒ½æ˜¯ç”±äºé”™è¯¯çš„å°ºå¯¸è®¡ç®—ã€æ—©æœŸçš„`return`é”™è¯¯è·¯å¾„ï¼Œæˆ–è€…ä¹è§‚çš„`try...catch`å—æ²¡æœ‰æ­£ç¡®å¤„ç†éƒ¨åˆ†å¡«å……çš„ç¼“å†²åŒºã€‚
- en: Leaking Cryptographic Material
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ³„éœ²åŠ å¯†ææ–™
- en: This is a particularly nasty subset of information disclosure. If your application
    handles encryption or decryption, the keys, nonces, or plaintext/ciphertext data
    will exist in Buffers in memory for brief periods. The buffer pool makes it highly
    likely that if you `allocUnsafe` a buffer for a mundane purpose (like building
    a JSON response), it could contain the remnants of a private key used to sign
    a token moments earlier in another request. An attacker who can repeatedly trigger
    this unsafe allocation might be able to piece together enough leaked fragments
    to compromise your entire cryptographic infrastructure.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¿¡æ¯æ³„éœ²çš„ä¸€ä¸ªç‰¹åˆ«æ¶åŠ£çš„å­é›†ã€‚å¦‚æœæ‚¨çš„åº”ç”¨ç¨‹åºå¤„ç†åŠ å¯†æˆ–è§£å¯†ï¼Œå¯†é’¥ã€nonceæˆ–æ˜æ–‡/å¯†æ–‡æ•°æ®å°†åœ¨å†…å­˜ä¸­çš„ç¼“å†²åŒºä¸­å­˜åœ¨ä¸€æ®µæ—¶é—´ã€‚ç¼“å†²æ± ä½¿å¾—å¦‚æœä¸ºäº†æ™®é€šç›®çš„ï¼ˆå¦‚æ„å»ºJSONå“åº”ï¼‰ä½¿ç”¨`allocUnsafe`åˆ†é…ç¼“å†²åŒºï¼Œå®ƒå¯èƒ½åŒ…å«ç”¨äºåœ¨å¦ä¸€ä¸ªè¯·æ±‚ä¸­è¾ƒæ—©æ—¶åˆ»ç­¾åä»¤ç‰Œçš„ç§é’¥çš„æ®‹ç•™éƒ¨åˆ†ã€‚å¦‚æœæ”»å‡»è€…å¯ä»¥é‡å¤è§¦å‘è¿™ç§ä¸å®‰å…¨åˆ†é…ï¼Œä»–ä»¬å¯èƒ½èƒ½å¤Ÿæ‹¼å‡‘è¶³å¤Ÿçš„æ³„éœ²ç‰‡æ®µï¼Œä»è€Œå±å®³æ‚¨çš„æ•´ä¸ªåŠ å¯†åŸºç¡€è®¾æ–½ã€‚
- en: Denial of Service (DoS) via `Buffer.from()`
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é€šè¿‡`Buffer.from()`è¿›è¡Œæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰
- en: This is a more subtle attack. Imagine an API endpoint that accepts a JSON payload,
    and one of the fields is expected to be a base64 encoded string which you then
    turn into a buffer.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæ›´ä¸ºå¾®å¦™çš„æ”»å‡»ã€‚æƒ³è±¡ä¸€ä¸ªæ¥å—JSONæœ‰æ•ˆè´Ÿè½½çš„APIç«¯ç‚¹ï¼Œå…¶ä¸­ä¸€ä¸ªå­—æ®µé¢„æœŸæ˜¯ä¸€ä¸ªbase64ç¼–ç çš„å­—ç¬¦ä¸²ï¼Œç„¶åæ‚¨å°†å…¶è½¬æ¢ä¸ºç¼“å†²åŒºã€‚
- en: '[PRE19]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `Buffer.from()` call with string input allocates a new buffer based on the
    *decoded* size of the string. An attacker can send a relatively small payload
    that, when decoded, expands into a massive buffer. A few of these requests can
    exhaust the server's memory, causing it to crash or become unresponsive to legitimate
    traffic. While this is a general application-level DoS vector, `Buffer.from`'s
    convenience can make it an easy vulnerability to introduce if you don't enforce
    strict limits on the input string length *before* you try to allocate a buffer
    from it.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å­—ç¬¦ä¸²è¾“å…¥çš„`Buffer.from()`è°ƒç”¨æ ¹æ®å­—ç¬¦ä¸²çš„*è§£ç *å¤§å°åˆ†é…ä¸€ä¸ªæ–°çš„ç¼“å†²åŒºã€‚æ”»å‡»è€…å¯ä»¥å‘é€ä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„æœ‰æ•ˆè´Ÿè½½ï¼Œè§£ç åæ‰©å±•æˆå·¨å¤§çš„ç¼“å†²åŒºã€‚å‡ ä¸ªè¿™æ ·çš„è¯·æ±‚å¯èƒ½ä¼šè€—å°½æœåŠ¡å™¨çš„å†…å­˜ï¼Œå¯¼è‡´å…¶å´©æºƒæˆ–å¯¹åˆæ³•æµé‡æ— å“åº”ã€‚è™½ç„¶è¿™æ˜¯ä¸€ä¸ªé€šç”¨åº”ç”¨å±‚DoSå‘é‡ï¼Œä½†å¦‚æœæ‚¨åœ¨å°è¯•ä»å®ƒåˆ†é…ç¼“å†²åŒºä¹‹å‰ä¸å¯¹è¾“å…¥å­—ç¬¦ä¸²é•¿åº¦æ–½åŠ ä¸¥æ ¼é™åˆ¶ï¼Œ`Buffer.from`çš„ä¾¿åˆ©æ€§å¯èƒ½ä¼šä½¿å…¶æˆä¸ºä¸€ä¸ªå®¹æ˜“å¼•å…¥çš„æ¼æ´ã€‚
- en: Timing Attacks
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ—¶é—´æ”»å‡»
- en: This is more theoretical and less likely to be possible - but the chances are
    not zero in specific cryptographic contexts. The time it takes for `Buffer.alloc()`
    to complete is directly proportional to the size of the buffer, because it has
    to zero-fill it. `Buffer.allocUnsafe()` takes a roughly constant (and very short)
    time for all pooled sizes. If an attacker can influence the size of an allocation
    and precisely measure the server's response time, they might be able to infer
    information. For example, if a buffer's size depends on the length of a secret,
    the difference in allocation time between `alloc` and `allocUnsafe` could potentially
    leak information about that **length***. This is an advanced attack vector, but
    it highlights how even performance characteristics can have security consequences.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ›´åå‘äºç†è®ºï¼Œä¸”ä¸å¤ªå¯èƒ½å®ç°â€”â€”ä½†åœ¨ç‰¹å®šçš„åŠ å¯†ç¯å¢ƒä¸­ï¼Œå¯èƒ½æ€§å¹¶éä¸ºé›¶ã€‚`Buffer.alloc()`å®Œæˆæ‰€éœ€çš„æ—¶é—´ä¸ç¼“å†²åŒºçš„å¤§å°æˆæ­£æ¯”ï¼Œå› ä¸ºå®ƒå¿…é¡»å°†å…¶æ¸…é›¶ã€‚`Buffer.allocUnsafe()`å¯¹äºæ‰€æœ‰æ± åŒ–å¤§å°éƒ½èŠ±è´¹å¤§çº¦æ’å®šï¼ˆä¸”éå¸¸çŸ­ï¼‰çš„æ—¶é—´ã€‚å¦‚æœæ”»å‡»è€…å¯ä»¥å½±å“åˆ†é…çš„å¤§å°å¹¶ç²¾ç¡®æµ‹é‡æœåŠ¡å™¨çš„å“åº”æ—¶é—´ï¼Œä»–ä»¬å¯èƒ½èƒ½å¤Ÿæ¨æ–­ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœç¼“å†²åŒºçš„å¤§å°å–å†³äºç§˜å¯†çš„é•¿åº¦ï¼Œ`alloc`å’Œ`allocUnsafe`ä¹‹é—´çš„åˆ†é…æ—¶é—´å·®å¼‚å¯èƒ½ä¼šæ³„éœ²æœ‰å…³è¯¥**é•¿åº¦**çš„ä¿¡æ¯ã€‚è¿™æ˜¯ä¸€ä¸ªé«˜çº§æ”»å‡»å‘é‡ï¼Œä½†å®ƒçªå‡ºäº†å³ä½¿æ˜¯æ€§èƒ½ç‰¹å¾ä¹Ÿå¯èƒ½æœ‰å®‰å…¨åæœã€‚
- en: â„¹ï¸Note
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: '***In** practice, attackers face noise (OS scheduling, network latency, CPU
    contention). This is an advanced/edge-case vector worth mentioning for cryptographic
    code, but itâ€™s not a common practical exploit against typical web apps. Included
    to make you aware that this attack vector exists.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**å®é™…ä¸Š**ï¼Œæ”»å‡»è€…ä¼šé¢ä¸´å™ªå£°ï¼ˆæ“ä½œç³»ç»Ÿè°ƒåº¦ã€ç½‘ç»œå»¶è¿Ÿã€CPUç«äº‰ï¼‰ã€‚è¿™æ˜¯ä¸€ä¸ªå€¼å¾—åœ¨åŠ å¯†ä»£ç ä¸­æåŠçš„å…ˆè¿›/è¾¹ç¼˜æƒ…å†µå‘é‡ï¼Œä½†å¹¶ä¸æ˜¯é’ˆå¯¹å…¸å‹Webåº”ç”¨çš„å¸¸è§å®é™…æ”»å‡»æ‰‹æ®µã€‚åŠ å…¥æ­¤å†…å®¹æ˜¯ä¸ºäº†è®©æ‚¨æ„è¯†åˆ°è¿™ç§æ”»å‡»å‘é‡å­˜åœ¨ã€‚'
- en: Your primary defense is simple. **Treat any data coming from an `allocUnsafe`
    buffer as untrusted and potentially radioactive until you have overwritten it
    yourself.** Code reviews must be ruthless about this. Any use of `allocUnsafe`
    needs to be challenged with the question - "Can you prove, under all possible
    code paths and error conditions, that this entire buffer is overwritten before
    it is read from or sent anywhere?" If the answer isn't a confident and obvious
    "yes," it must be refactored to `Buffer.alloc()`.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„ä¸»è¦é˜²å¾¡æªæ–½å¾ˆç®€å•ã€‚**å°†æ¥è‡ª `allocUnsafe` ç¼“å†²åŒºçš„ä»»ä½•æ•°æ®è§†ä¸ºä¸å¯ä¿¡ä¸”å¯èƒ½å…·æœ‰æ”¾å°„æ€§çš„ï¼Œç›´åˆ°ä½ äº²è‡ªè¦†ç›–å®ƒä¸ºæ­¢ã€‚**ä»£ç å®¡æŸ¥å¿…é¡»å¯¹æ­¤æ¯«ä¸ç•™æƒ…ã€‚ä»»ä½•ä½¿ç”¨
    `allocUnsafe` çš„ä»£ç éƒ½éœ€è¦è¢«è´¨ç–‘â€”â€”"ä½ èƒ½å¦è¯æ˜ï¼Œåœ¨æ‰€æœ‰å¯èƒ½çš„ä»£ç è·¯å¾„å’Œé”™è¯¯æ¡ä»¶ä¸‹ï¼Œè¿™ä¸ªæ•´ä¸ªç¼“å†²åŒºåœ¨è¯»å–æˆ–å‘é€åˆ°ä»»ä½•åœ°æ–¹ä¹‹å‰éƒ½è¢«è¦†ç›–äº†ï¼Ÿ" å¦‚æœç­”æ¡ˆä¸æ˜¯è‡ªä¿¡ä¸”æ˜æ˜¾çš„
    "æ˜¯"ï¼Œåˆ™å¿…é¡»é‡æ„ä¸º `Buffer.alloc()`ã€‚
- en: â„¹ï¸Note
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: For small allocations that come from Node's internal pool (the slab), allocUnsafe()
    is very fast (essentially an O(1) slice). However, (a) if the pool is exhausted,
    a new slab or an OS allocation is required and costs increase, and (b) allocUnsafeSlow()
    does not use the pool. The time it takes isn't precisely "constant for all sizes",
    instead it's very fast for pooled/small allocations (O(1)), but behavior changes
    when a new slab or OS allocation is needed.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¥è‡ªNodeå†…éƒ¨æ± ï¼ˆslabï¼‰çš„å°åˆ†é…ï¼ŒallocUnsafe()éå¸¸å¿«ï¼ˆæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªO(1)çš„åˆ‡ç‰‡ï¼‰ã€‚ç„¶è€Œï¼Œï¼ˆaï¼‰å¦‚æœæ± è€—å°½ï¼Œåˆ™éœ€è¦ä¸€ä¸ªæ–°çš„slabæˆ–æ“ä½œç³»ç»Ÿåˆ†é…ï¼Œæˆæœ¬å¢åŠ ï¼Œå¹¶ä¸”ï¼ˆbï¼‰allocUnsafeSlow()ä¸ä½¿ç”¨æ± ã€‚æ‰€éœ€çš„æ—¶é—´å¹¶ä¸æ˜¯â€œå¯¹æ‰€æœ‰å¤§å°éƒ½æ˜¯æ’å®šçš„â€ï¼Œè€Œæ˜¯å¯¹äºæ± ä¸­å°åˆ†é…éå¸¸å¿«ï¼ˆO(1)ï¼‰ï¼Œä½†åœ¨éœ€è¦æ–°çš„slabæˆ–æ“ä½œç³»ç»Ÿåˆ†é…æ—¶è¡Œä¸ºä¼šæ”¹å˜ã€‚
- en: Memory Fragmentation and GC Pressure
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å†…å­˜ç¢ç‰‡åŒ–å’ŒGCå‹åŠ›
- en: ğŸ“ŒImportant
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“Œé‡è¦
- en: Let me save you from a mistake I've watched too many developers make. If you're
    finding yourself constantly fighting with `Buffer.allocUnsafe()` for performance,
    doing heavy binary manipulation, or running CPU-intensive data processing, you're
    probably using the wrong tool. Node.js is exceptional at handling thousands of
    concurrent I/O operations, managing network connections, and orchestrating services.
    But it runs JavaScript in a single-threaded event loop, which means CPU-bound
    work blocks everything else.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘å¸®ä½ é¿å…æˆ‘çœ‹è¿‡å¤ªå¤šå¼€å‘è€…çŠ¯çš„é”™è¯¯ã€‚å¦‚æœä½ å‘ç°è‡ªå·±ä¸€ç›´åœ¨ä¸ `Buffer.allocUnsafe()` ä½œæ–—äº‰ä»¥è·å¾—æ€§èƒ½ï¼Œè¿›è¡Œå¤§é‡çš„äºŒè¿›åˆ¶æ“ä½œï¼Œæˆ–è€…è¿è¡ŒCPUå¯†é›†å‹æ•°æ®å¤„ç†ï¼Œä½ å¾ˆå¯èƒ½ä½¿ç”¨äº†é”™è¯¯çš„å·¥å…·ã€‚Node.js
    åœ¨å¤„ç†æ•°åƒä¸ªå¹¶å‘I/Oæ“ä½œã€ç®¡ç†ç½‘ç»œè¿æ¥å’Œç¼–æ’æœåŠ¡æ–¹é¢éå¸¸å‡ºè‰²ã€‚ä½†æ˜¯ï¼Œå®ƒåœ¨å•çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡ŒJavaScriptï¼Œè¿™æ„å‘³ç€CPUå¯†é›†å‹å·¥ä½œä¼šé˜»å¡å…¶ä»–æ‰€æœ‰æ“ä½œã€‚
- en: When you're processing video streams, doing real-time image manipulation, running
    compression algorithms, or performing cryptographic operations on large datasets,
    languages like Rust, Go, or C++ will serve you far better. These languages give
    you direct memory control without garbage collection pauses, true parallelism
    across multiple CPU cores, and zero-cost abstractions that compile to highly optimized
    machine code. A video transcoding operation that makes Node.js cry will run smoothly
    in Rust. A data processing pipeline that requires careful buffer management in
    Node.js becomes straightforward in Go with its excellent concurrency primitives.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ å¤„ç†è§†é¢‘æµã€è¿›è¡Œå®æ—¶å›¾åƒå¤„ç†ã€è¿è¡Œå‹ç¼©ç®—æ³•æˆ–åœ¨å¤§å‹æ•°æ®é›†ä¸Šæ‰§è¡ŒåŠ å¯†æ“ä½œæ—¶ï¼ŒåƒRustã€Goæˆ–C++è¿™æ ·çš„è¯­è¨€å°†ä¸ºä½ æä¾›æ›´å¥½çš„æœåŠ¡ã€‚è¿™äº›è¯­è¨€æä¾›äº†ç›´æ¥å†…å­˜æ§åˆ¶ï¼Œæ²¡æœ‰åƒåœ¾å›æ”¶æš‚åœï¼Œè·¨å¤šä¸ªCPUæ ¸å¿ƒçš„çœŸæ­£å¹¶è¡Œæ€§ï¼Œä»¥åŠç¼–è¯‘ä¸ºé«˜åº¦ä¼˜åŒ–çš„æœºå™¨ä»£ç çš„æ— æˆæœ¬æŠ½è±¡ã€‚ä¸€ä¸ªè®©Node.jså“­æ³£çš„è§†é¢‘è½¬ç æ“ä½œåœ¨Rustä¸­å¯ä»¥å¹³ç¨³è¿è¡Œã€‚åœ¨Node.jsä¸­éœ€è¦ä»”ç»†ç¼“å†²åŒºç®¡ç†çš„æ•°æ®å¤„ç†ç®¡é“åœ¨Goä¸­å˜å¾—ç®€å•ï¼Œå› ä¸ºGoå…·æœ‰å‡ºè‰²çš„å¹¶å‘åŸè¯­ã€‚
- en: Here's the thing that makes great engineers great - they pick the right tool
    for each job. Do not limit yourself to a single language, learn mutliple ones.
    You can absolutely call Rust code from Node.js using native addons or WebAssembly,
    keeping Node for what it does best (handling HTTP requests, managing business
    logic) while delegating heavy computation to a language built for it. I've seen
    teams cut their processing time from minutes to seconds just by moving their hot
    paths to Rust while keeping their API layer in Node. Don't let language loyalty
    make your applications worse. Your users don't care if your entire stack is JavaScript;
    they care that your service is fast and reliable.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä½¿ä¼˜ç§€å·¥ç¨‹å¸ˆå˜å¾—ä¼Ÿå¤§çš„åŸå› â€”â€”ä»–ä»¬ä¸ºæ¯ä¸€é¡¹å·¥ä½œé€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚ä¸è¦å°†è‡ªå·±é™åˆ¶åœ¨å•ä¸€çš„è¯­è¨€ä¸Šï¼Œå­¦ä¹ å¤šç§è¯­è¨€ã€‚ä½ å¯ä»¥ç»å¯¹åœ°ä»Node.jsä¸­è°ƒç”¨Rustä»£ç ï¼Œä½¿ç”¨åŸç”Ÿæ’ä»¶æˆ–WebAssemblyï¼Œè®©Node.jsä¸“æ³¨äºå®ƒæœ€æ“…é•¿çš„äº‹æƒ…ï¼ˆå¤„ç†HTTPè¯·æ±‚ã€ç®¡ç†ä¸šåŠ¡é€»è¾‘ï¼‰ï¼ŒåŒæ—¶å°†é‡è®¡ç®—å§”æ‰˜ç»™ä¸ºå®ƒè€Œæ„å»ºçš„è¯­è¨€ã€‚æˆ‘çœ‹åˆ°è¿‡å›¢é˜Ÿé€šè¿‡å°†çƒ­ç‚¹è·¯å¾„ç§»åŠ¨åˆ°Rustï¼ˆåŒæ—¶ä¿æŒAPIå±‚åœ¨Node.jsä¸Šï¼‰å°†å¤„ç†æ—¶é—´ä»åˆ†é’Ÿç¼©çŸ­åˆ°ç§’ã€‚ä¸è¦è®©è¯­è¨€å¿ è¯šåº¦ä½¿ä½ çš„åº”ç”¨ç¨‹åºå˜å¾—æ›´å·®ã€‚ä½ çš„ç”¨æˆ·ä¸åœ¨ä¹ä½ çš„æ•´ä¸ªå †æ ˆæ˜¯å¦æ˜¯JavaScriptï¼›ä»–ä»¬å…³å¿ƒçš„æ˜¯ä½ çš„æœåŠ¡æ˜¯å¦å¿«é€Ÿä¸”å¯é ã€‚
- en: Our discussion so far has focused on CPU performance and security. But allocation
    patterns also have a profound impact on memory usage and the behavior of the garbage
    collector (GC).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢çš„è®¨è®ºä¸»è¦é›†ä¸­åœ¨CPUæ€§èƒ½å’Œå®‰å…¨ä¸Šã€‚ä½†åˆ†é…æ¨¡å¼ä¹Ÿå¯¹å†…å­˜ä½¿ç”¨å’Œåƒåœ¾æ”¶é›†å™¨ï¼ˆGCï¼‰çš„è¡Œä¸ºæœ‰æ·±è¿œçš„å½±å“ã€‚
- en: Garbage Collector Pressure
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åƒåœ¾æ”¶é›†å™¨å‹åŠ›
- en: Every Buffer object you create, no matter how large its off-heap storage is,
    has a small corresponding object that lives on the V8 heap. When you create and
    discard thousands of Buffers per second, you are creating churn for the V8 garbage
    collector. The GC has to track all these small heap objects, determine when they
    are no longer reachable, and clean them up.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åˆ›å»ºçš„æ¯ä¸ªBufferå¯¹è±¡ï¼Œæ— è®ºå…¶off-heapå­˜å‚¨æœ‰å¤šå¤§ï¼Œéƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„å°å¯¹è±¡ï¼Œå®ƒå­˜åœ¨äºV8å †ä¸Šã€‚å½“ä½ æ¯ç§’åˆ›å»ºå’Œä¸¢å¼ƒæ•°åƒä¸ªBufferæ—¶ï¼Œä½ æ­£åœ¨ä¸ºV8åƒåœ¾æ”¶é›†å™¨åˆ¶é€ éº»çƒ¦ã€‚åƒåœ¾æ”¶é›†å™¨å¿…é¡»è·Ÿè¸ªæ‰€æœ‰è¿™äº›å°å †å¯¹è±¡ï¼Œç¡®å®šå®ƒä»¬ä½•æ—¶ä¸å†å¯è¾¾ï¼Œå¹¶æ¸…ç†å®ƒä»¬ã€‚
- en: This is a relatively minor issue for `Buffer`s themselves, but it's related
    to a bigger one - temporary copies. Consider this common pattern in a streaming
    parser.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¹äº`Buffer`æœ¬èº«æ¥è¯´æ˜¯ä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„é—®é¢˜ï¼Œä½†å®ƒä¸ä¸€ä¸ªæ›´å¤§çš„é—®é¢˜æœ‰å…³â€”â€”ä¸´æ—¶å¤åˆ¶ã€‚è€ƒè™‘åœ¨æµè§£æå™¨ä¸­è¿™ä¸ªå¸¸è§çš„æ¨¡å¼ã€‚
- en: '[PRE20]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '`Buffer.concat` is convenient, but look what it does. It allocates a *new*
    buffer large enough to hold both `internalBuffer` and `chunk`, copies the data
    from both into the new buffer, and then discards the old ones. If you''re receiving
    100 small chunks to form one message, you''ve just performed 100 allocations and
    99 copy operations, creating and immediately discarding 99 intermediate buffers.
    This puts immense pressure on the GC and wastes CPU cycles on copying data. A
    better approach would be to manage a single, larger buffer and a pointer, but
    that''s a topic for another chapter. The point is, your allocation *strategy*
    (not just the allocation function) has a huge impact.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`Buffer.concat`å¾ˆæ–¹ä¾¿ï¼Œä½†çœ‹çœ‹å®ƒåšäº†ä»€ä¹ˆã€‚å®ƒåˆ†é…äº†ä¸€ä¸ªè¶³å¤Ÿå¤§çš„æ–°ç¼“å†²åŒºæ¥å®¹çº³`internalBuffer`å’Œ`chunk`ï¼Œå°†æ•°æ®ä»ä¸¤è€…å¤åˆ¶åˆ°æ–°ç¼“å†²åŒºä¸­ï¼Œç„¶åä¸¢å¼ƒæ—§çš„ç¼“å†²åŒºã€‚å¦‚æœä½ æ¥æ”¶100ä¸ªå°å—æ¥å½¢æˆä¸€ä¸ªæ¶ˆæ¯ï¼Œä½ åˆšåˆšè¿›è¡Œäº†100æ¬¡åˆ†é…å’Œ99æ¬¡å¤åˆ¶æ“ä½œï¼Œåˆ›å»ºäº†99ä¸ªä¸­é—´ç¼“å†²åŒºå¹¶ç«‹å³ä¸¢å¼ƒå®ƒä»¬ã€‚è¿™ç»™GCå¸¦æ¥äº†å·¨å¤§çš„å‹åŠ›ï¼Œå¹¶æµªè´¹äº†CPUå‘¨æœŸåœ¨å¤åˆ¶æ•°æ®ä¸Šã€‚æ›´å¥½çš„æ–¹æ³•æ˜¯å°†å•ä¸ªè¾ƒå¤§çš„ç¼“å†²åŒºå’ŒæŒ‡é’ˆè¿›è¡Œç®¡ç†ï¼Œä½†è¿™å°†æ˜¯å¦ä¸€ç« çš„ä¸»é¢˜ã€‚é‡ç‚¹æ˜¯ï¼Œä½ çš„åˆ†é…*ç­–ç•¥*ï¼ˆè€Œä¸ä»…ä»…æ˜¯åˆ†é…å‡½æ•°ï¼‰æœ‰å·¨å¤§çš„å½±å“ã€‚'
- en: Memory Fragmentation
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å†…å­˜ç¢ç‰‡åŒ–
- en: This is a bigger problem when dealing with large buffers that are not eligible
    for pooling (i.e., > 8KB). When your application is long-running and frequently
    allocates and frees large buffers of varying sizes, it can lead to memory fragmentation.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å¤„ç†ä¸é€‚ç”¨äºæ± åŒ–çš„å¤§å‹ç¼“å†²åŒºï¼ˆå³ï¼Œ> 8KBï¼‰æ—¶ï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´å¤§çš„é—®é¢˜ã€‚å½“ä½ çš„åº”ç”¨ç¨‹åºé•¿æ—¶é—´è¿è¡Œå¹¶é¢‘ç¹åœ°åˆ†é…å’Œé‡Šæ”¾ä¸åŒå¤§å°çš„ç¼“å†²åŒºæ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´å†…å­˜ç¢ç‰‡åŒ–ã€‚
- en: Let's imagine process's available memory like a long queue of empty boxes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æƒ³è±¡è¿›ç¨‹çš„å¯ç”¨å†…å­˜å°±åƒä¸€ä¸ªé•¿é•¿çš„ç©ºç®±å­é˜Ÿåˆ—ã€‚
- en: You allocate a 1MB buffer (Block A).
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ åˆ†é…äº†ä¸€ä¸ª1MBçš„ç¼“å†²åŒºï¼ˆå—Aï¼‰ã€‚
- en: You allocate a 2MB buffer (Block B).
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ åˆ†é…äº†ä¸€ä¸ª2MBçš„ç¼“å†²åŒºï¼ˆå—Bï¼‰ã€‚
- en: You allocate another 1MB buffer (Block C). Your queue now has `[A:1MB][B:2MB][C:1MB]`.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ åˆåˆ†é…äº†ä¸€ä¸ª1MBçš„ç¼“å†²åŒºï¼ˆå—Cï¼‰ã€‚ç°åœ¨ï¼Œä½ çš„é˜Ÿåˆ—æœ‰ `[A:1MB][B:2MB][C:1MB]`ã€‚
- en: Now, you free the 2MB buffer in the middle (Block B). Your shelf looks like
    `[A:1MB][---EMPTY:2MB---][C:1MB]`.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä½ é‡Šæ”¾äº†ä¸­é—´çš„2MBç¼“å†²åŒºï¼ˆå—Bï¼‰ã€‚ä½ çš„æ¶å­çœ‹èµ·æ¥åƒ `[A:1MB][---EMPTY:2MB---][C:1MB]`ã€‚
- en: You have 2MB of free memory. But if your next request is to allocate a *3MB*
    buffer, the allocation will fail (or Node will have to request more memory from
    the OS). Even though you have enough memory in total, it's not *contiguous*. You
    have a 2MB hole. This is fragmentation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æœ‰2MBçš„ç©ºé—²å†…å­˜ã€‚ä½†å¦‚æœä½ çš„ä¸‹ä¸€ä¸ªè¯·æ±‚æ˜¯åˆ†é…ä¸€ä¸ª*3MB*çš„ç¼“å†²åŒºï¼Œåˆ†é…å°†å¤±è´¥ï¼ˆæˆ–è€…Nodeå°†ä¸å¾—ä¸ä»æ“ä½œç³»ç»Ÿè¯·æ±‚æ›´å¤šå†…å­˜ï¼‰ã€‚å°½ç®¡ä½ æ€»å…±æœ‰è¶³å¤Ÿçš„å†…å­˜ï¼Œä½†å®ƒä¸æ˜¯*è¿ç»­çš„*ã€‚ä½ æœ‰ä¸€ä¸ª2MBçš„ç©ºæ´ã€‚è¿™å°±æ˜¯ç¢ç‰‡åŒ–ã€‚
- en: Over time, a long-running Node process can accumulate many such holes, leading
    to increased overall memory usage (`rss` or Resident Set Size) even if the active
    memory (`heapUsed` + `external`) is stable. This is because the C++ memory allocator
    (`malloc`) has a hard time reusing these fragmented gaps efficiently.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æ—¶é—´çš„æ¨ç§»ï¼Œé•¿æ—¶é—´è¿è¡Œçš„Nodeè¿›ç¨‹å¯ä»¥ç§¯ç´¯è®¸å¤šè¿™æ ·çš„ç©ºæ´ï¼Œå³ä½¿æ´»åŠ¨å†…å­˜ï¼ˆ`heapUsed` + `external`ï¼‰ä¿æŒç¨³å®šï¼Œä¹Ÿä¼šå¯¼è‡´æ•´ä½“å†…å­˜ä½¿ç”¨ï¼ˆ`rss`æˆ–Resident
    Set Sizeï¼‰å¢åŠ ã€‚è¿™æ˜¯å› ä¸ºC++å†…å­˜åˆ†é…å™¨ï¼ˆ`malloc`ï¼‰å¾ˆéš¾æœ‰æ•ˆåœ°é‡ç”¨è¿™äº›ç¢ç‰‡åŒ–çš„é—´éš™ã€‚
- en: How do allocation patterns affect this?
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†é…æ¨¡å¼æ˜¯å¦‚ä½•å½±å“è¿™ä¸ªçš„ï¼Ÿ
- en: '**Frequent `Buffer.alloc(largeSize)`** is the primary driver of fragmentation.
    Constantly creating and destroying large, variable-sized buffers is the worst-case
    scenario.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '**é¢‘ç¹çš„`Buffer.alloc(largeSize)`**æ˜¯ç¢ç‰‡åŒ–çš„ä¸»è¦é©±åŠ¨å› ç´ ã€‚ä¸æ–­åˆ›å»ºå’Œé”€æ¯å¤§å‹ã€å¯å˜å¤§å°çš„ç¼“å†²åŒºæ˜¯æœ€åçš„æƒ…å†µã€‚'
- en: '**Buffer Pooling** is a direct defense against fragmentation for small allocations.
    By reusing a single large slab of memory for all small buffers, Node avoids peppering
    the memory space with thousands of tiny allocations and deallocations. This is
    one of its most important but least-appreciated benefits.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç¼“å†²æ± **æ˜¯é’ˆå¯¹å°å‹åˆ†é…çš„ç›´æ¥é˜²å¾¡ç¢ç‰‡çš„æ–¹æ³•ã€‚é€šè¿‡ä¸ºæ‰€æœ‰å°å‹ç¼“å†²åŒºé‡ç”¨å•ä¸ªå¤§å‹å†…å­˜å—ï¼ŒNode é¿å…äº†åœ¨å†…å­˜ç©ºé—´ä¸­æ•£å¸ƒæˆåƒä¸Šä¸‡çš„å¾®å°åˆ†é…å’Œé‡Šæ”¾æ“ä½œã€‚è¿™æ˜¯å…¶æœ€é‡è¦çš„ä½†æœ€ä¸è¢«æ¬£èµçš„å¥½å¤„ä¹‹ä¸€ã€‚'
- en: If your service deals with large binary blobs and you see its memory footprint
    (`rss`) growing over time without a corresponding increase in `heapUsed` or `external`,
    you may be a victim of memory fragmentation. The solution is often to move to
    a more sophisticated memory management strategy, like allocating a few very large
    "arena" buffers at startup and managing the memory within them yourself, rather
    than constantly asking Node for new large buffers. This is an advanced technique,
    but it's the logical conclusion when default allocation patterns break down at
    extreme scale.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çš„æœåŠ¡å¤„ç†å¤§å‹äºŒè¿›åˆ¶å—ï¼Œå¹¶ä¸”ä½ çœ‹åˆ°å…¶å†…å­˜å ç”¨ï¼ˆ`rss`ï¼‰éšç€æ—¶é—´çš„æ¨ç§»è€Œå¢é•¿ï¼Œè€Œæ²¡æœ‰ç›¸åº”çš„ `heapUsed` æˆ– `external` å¢åŠ æ—¶ï¼Œä½ å¯èƒ½æˆä¸ºäº†å†…å­˜ç¢ç‰‡åŒ–çš„å—å®³è€…ã€‚è§£å†³æ–¹æ¡ˆé€šå¸¸æ˜¯è½¬å‘æ›´å¤æ‚çš„å†…å­˜ç®¡ç†ç­–ç•¥ï¼Œå¦‚å¯åŠ¨æ—¶åˆ†é…å‡ ä¸ªéå¸¸å¤§çš„â€œåŒºåŸŸâ€ç¼“å†²åŒºï¼Œå¹¶åœ¨å…¶ä¸­è‡ªè¡Œç®¡ç†å†…å­˜ï¼Œè€Œä¸æ˜¯ä¸æ–­å‘
    Node è¯·æ±‚æ–°çš„å¤§å‹ç¼“å†²åŒºã€‚è¿™æ˜¯ä¸€ç§é«˜çº§æŠ€æœ¯ï¼Œä½†è¿™æ˜¯åœ¨é»˜è®¤åˆ†é…æ¨¡å¼åœ¨æç«¯è§„æ¨¡ä¸‹å´©æºƒæ—¶çš„é€»è¾‘ç»“è®ºã€‚
- en: Platform Differences and Allocator Behavior
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¹³å°å·®å¼‚å’Œåˆ†é…å™¨è¡Œä¸º
- en: While Node.js provides a fantastic abstraction over the underlying operating
    system, it's important to remember that it doesn't exist in a vacuum. The behavior
    you observe, especially around performance and uninitialized memory, can be subtly
    influenced by the platform you're running on.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ Node.js åœ¨åº•å±‚æ“ä½œç³»ç»Ÿä¹‹ä¸Šæä¾›äº†ä¸€ä¸ªå‡ºè‰²çš„æŠ½è±¡ï¼Œä½†é‡è¦çš„æ˜¯è¦è®°ä½å®ƒå¹¶éå­¤ç«‹å­˜åœ¨ã€‚ä½ æ‰€è§‚å¯Ÿåˆ°çš„è¡Œä¸ºï¼Œå°¤å…¶æ˜¯åœ¨æ€§èƒ½å’Œæœªåˆå§‹åŒ–å†…å­˜æ–¹é¢ï¼Œå¯èƒ½ä¼šå—åˆ°ä½ æ‰€è¿è¡Œçš„å¹³å°æ½œç§»é»˜åŒ–çš„å½±å“ã€‚
- en: The function that Node.js ultimately calls to get memory from the OS is typically
    `malloc` or a variant of it. The implementation of `malloc` can differ between
    operating systems (like Linux, macOS, Windows) and even between different C standard
    library implementations on the same OS (like `glibc`, `musl`, `jemalloc`).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js æœ€ç»ˆè°ƒç”¨æ¥ä»æ“ä½œç³»ç»Ÿè·å–å†…å­˜çš„å‡½æ•°é€šå¸¸æ˜¯ `malloc` æˆ–å…¶å˜ä½“ã€‚`malloc` çš„å®ç°å¯èƒ½å› æ“ä½œç³»ç»Ÿï¼ˆå¦‚ Linuxã€macOSã€Windowsï¼‰è€Œå¼‚ï¼Œç”šè‡³åœ¨åŒä¸€æ“ä½œç³»ç»Ÿä¸Šçš„ä¸åŒ
    C æ ‡å‡†åº“å®ç°ä¹‹é—´ä¹Ÿæœ‰æ‰€ä¸åŒï¼ˆå¦‚ `glibc`ã€`musl`ã€`jemalloc`ï¼‰ã€‚
- en: '**But... what does this mean for you?**'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½†æ˜¯...è¿™å¯¹æ‚¨æ„å‘³ç€ä»€ä¹ˆï¼Ÿ**'
- en: What you see in a `Buffer.allocUnsafe` buffer is highly dependent on the OS
    and the allocator's strategy. Some allocators might be more likely to give you
    freshly zeroed memory from the OS if you request a large block, while others might
    be more aggressive about recycling memory from your own process. The security
    risk is always present, but the *specific data* you might leak could change from
    a developer's macOS machine to a production Linux (Alpine) container. Never assume
    that because you don't see sensitive data in your test environment, the vulnerability
    doesn't exist. Production behavior will be different.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åœ¨ `Buffer.allocUnsafe` ç¼“å†²åŒºä¸­çœ‹åˆ°çš„å†…å®¹é«˜åº¦ä¾èµ–äºæ“ä½œç³»ç»Ÿå’Œåˆ†é…å™¨çš„ç­–ç•¥ã€‚ä¸€äº›åˆ†é…å™¨åœ¨è¯·æ±‚å¤§å—å†…å­˜æ—¶å¯èƒ½ä¼šæ›´æœ‰å¯èƒ½ä»æ“ä½œç³»ç»Ÿæä¾›æ–°é›¶å†…å­˜ï¼Œè€Œå…¶ä»–åˆ†é…å™¨å¯èƒ½ä¼šæ›´ç§¯æåœ°å›æ”¶ä½ è¿›ç¨‹ä¸­çš„å†…å­˜ã€‚å®‰å…¨é£é™©å§‹ç»ˆå­˜åœ¨ï¼Œä½†ä½ å¯èƒ½æ³„éœ²çš„*å…·ä½“æ•°æ®*å¯èƒ½ä¼šä»å¼€å‘è€…çš„
    macOS æœºå™¨åˆ°ç”Ÿäº§ Linuxï¼ˆAlpineï¼‰å®¹å™¨è€Œå‘ç”Ÿå˜åŒ–ã€‚æ°¸è¿œä¸è¦å‡è®¾å› ä¸ºä½ æ²¡æœ‰åœ¨æµ‹è¯•ç¯å¢ƒä¸­çœ‹åˆ°æ•æ„Ÿæ•°æ®ï¼Œæ¼æ´å°±ä¸å­˜åœ¨ã€‚ç”Ÿäº§ç¯å¢ƒçš„è¡Œä¸ºå°†ä¸åŒã€‚
- en: While the relative difference between `alloc` (slow) and `allocUnsafe` (fast)
    will always hold, the absolute numbers can vary. An allocator like `jemalloc`
    (which is popular in high-performance applications) is heavily optimized for multi-threaded
    allocation and reducing fragmentation. A Node.js binary compiled against `jemalloc`
    might show different performance profiles for heavy allocation workloads compared
    to one using the system's default `glibc` `malloc`. This is usually in the realm
    of micro-optimization, but for hyper-scale services, it can matter.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ `alloc`ï¼ˆæ…¢é€Ÿï¼‰å’Œ `allocUnsafe`ï¼ˆå¿«é€Ÿï¼‰ä¹‹é—´çš„ç›¸å¯¹å·®å¼‚å§‹ç»ˆå­˜åœ¨ï¼Œä½†ç»å¯¹æ•°å€¼å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚åƒ `jemalloc`ï¼ˆåœ¨é«˜æ€§èƒ½åº”ç”¨ä¸­å¾ˆå—æ¬¢è¿ï¼‰è¿™æ ·çš„åˆ†é…å™¨ï¼Œå¯¹å¤šçº¿ç¨‹åˆ†é…å’Œå‡å°‘ç¢ç‰‡è¿›è¡Œäº†å¤§é‡ä¼˜åŒ–ã€‚ä¸ä½¿ç”¨ç³»ç»Ÿé»˜è®¤çš„
    `glibc` `malloc` ç›¸æ¯”ï¼Œé’ˆå¯¹ `jemalloc` ç¼–è¯‘çš„ Node.js äºŒè¿›åˆ¶æ–‡ä»¶åœ¨å¤„ç†å¤§é‡åˆ†é…å·¥ä½œè´Ÿè½½æ—¶å¯èƒ½ä¼šæ˜¾ç¤ºå‡ºä¸åŒçš„æ€§èƒ½ç‰¹å¾ã€‚è¿™é€šå¸¸å±äºå¾®ä¼˜åŒ–èŒƒç•´ï¼Œä½†å¯¹äºè¶…å¤§è§„æ¨¡æœåŠ¡æ¥è¯´ï¼Œè¿™å¯èƒ½ä¼šå¾ˆé‡è¦ã€‚
- en: Node's internal buffer pool sits on top of the system allocator. It requests
    its 8KB slab via `malloc`. The efficiency of the pool itself is consistent across
    platforms, but how the system as a whole deals with Node's requests for these
    slabs can differ.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Node çš„å†…éƒ¨ç¼“å†²æ± ä½äºç³»ç»Ÿåˆ†é…å™¨ä¹‹ä¸Šã€‚å®ƒé€šè¿‡ `malloc` è¯·æ±‚å…¶ 8KB å—ã€‚æ± æœ¬èº«çš„æ•ˆç‡åœ¨å„ä¸ªå¹³å°ä¸Šæ˜¯ä¸€è‡´çš„ï¼Œä½†æ•´ä¸ªç³»ç»Ÿå¦‚ä½•å¤„ç† Node
    å¯¹è¿™äº›å—çš„éœ€æ±‚å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚
- en: The key takeaway here is not that you need to become an expert in system memory
    allocators. It's about maintaining a healthy sense of paranoia. The convenient,
    predictable environment on your development machine is not a perfect replica of
    your production environment. A security flaw related to memory layout might be
    harder to reproduce locally, making it even more dangerous because it can lie
    dormant until it hits production traffic patterns.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„å…³é”®è¦ç‚¹ä¸æ˜¯æ‚¨éœ€è¦æˆä¸ºç³»ç»Ÿå†…å­˜åˆ†é…å™¨çš„ä¸“å®¶ã€‚è¿™æ˜¯å…³äºä¿æŒä¸€ç§å¥åº·çš„åæ‰§æ„Ÿã€‚æ‚¨å¼€å‘æœºå™¨ä¸Šçš„æ–¹ä¾¿ã€å¯é¢„æµ‹çš„ç¯å¢ƒå¹¶ä¸æ˜¯æ‚¨çš„ç”Ÿäº§ç¯å¢ƒçš„å®Œç¾å¤åˆ¶å“ã€‚ä¸å†…å­˜å¸ƒå±€ç›¸å…³çš„å®‰å…¨æ¼æ´å¯èƒ½æ›´éš¾åœ¨æœ¬åœ°é‡ç°ï¼Œè¿™ä½¿å¾—å®ƒæ›´åŠ å±é™©ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨ç”Ÿäº§æµé‡æ¨¡å¼ä¸­æ½œä¼ã€‚
- en: This reinforces the core principle - **write defensive code**. Do not rely on
    the observed behavior of `allocUnsafe` on your machine. Rely only on its documented
    contract - it returns uninitialized memory, and you are responsible for clearing
    it. This contract holds true across all platforms, even if the spooky of that
    memory change. Your code should be robust enough to be correct regardless of the
    underlying allocator's implementation details.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŠ å¼ºäº†æ ¸å¿ƒåŸåˆ™â€”â€”**ç¼–å†™é˜²å¾¡æ€§ä»£ç **ã€‚ä¸è¦ä¾èµ–äºæ‚¨æœºå™¨ä¸Š `allocUnsafe` çš„è§‚å¯Ÿè¡Œä¸ºã€‚åªä¾èµ–äºå…¶æ–‡æ¡£åŒ–çš„åˆåŒâ€”â€”å®ƒè¿”å›æœªåˆå§‹åŒ–çš„å†…å­˜ï¼Œæ‚¨è´Ÿè´£æ¸…é™¤å®ƒã€‚è¿™ä¸ªåˆåŒåœ¨æ‰€æœ‰å¹³å°ä¸Šéƒ½æˆç«‹ï¼Œå³ä½¿å†…å­˜å˜åŒ–çš„å¹½çµã€‚æ‚¨çš„ä»£ç åº”è¯¥è¶³å¤Ÿå¥å£®ï¼Œèƒ½å¤Ÿåœ¨åº•å±‚åˆ†é…å™¨çš„å®ç°ç»†èŠ‚æœªçŸ¥çš„æƒ…å†µä¸‹ä¿æŒæ­£ç¡®ã€‚
- en: Production Decision Framework
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”Ÿäº§å†³ç­–æ¡†æ¶
- en: You've seen the dangers, the performance cliffs, and the subtle complexities.
    Now, how do you make the right choice in your day-to-day work? When you're about
    to type `Buffer.`, which function should you choose?
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å·²ç»çœ‹åˆ°äº†å±é™©ã€æ€§èƒ½æ‚¬å´–å’Œå¾®å¦™çš„å¤æ‚æ€§ã€‚ç°åœ¨ï¼Œæ‚¨å¦‚ä½•åœ¨æ—¥å¸¸å·¥ä½œä¸­åšå‡ºæ­£ç¡®çš„é€‰æ‹©ï¼Ÿå½“æ‚¨å³å°†è¾“å…¥ `Buffer.` æ—¶ï¼Œæ‚¨åº”è¯¥é€‰æ‹©å“ªä¸ªå‡½æ•°ï¼Ÿ
- en: Here is a simple, safe decision framework to follow. Think of it as a mental
    flowchart.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªç®€å•ã€å®‰å…¨çš„å†³ç­–æ¡†æ¶ï¼Œæ‚¨å¯ä»¥éµå¾ªã€‚æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªå¿ƒç†æµç¨‹å›¾ã€‚
- en: '**First, start with the `Default`**'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**é¦–å…ˆï¼Œä» `Default` å¼€å§‹**'
- en: Your default, reflexive choice should always be `Buffer.alloc()`.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨çš„é»˜è®¤ã€æœ¬èƒ½çš„é€‰æ‹©åº”è¯¥æ˜¯ `Buffer.alloc()`ã€‚
- en: '**Question:** Are you allocating a buffer?'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**é—®é¢˜ï¼šæ‚¨æ˜¯å¦æ­£åœ¨åˆ†é…ç¼“å†²åŒºï¼Ÿ**'
- en: '**Answer:** Use `Buffer.alloc(size)`.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›ç­”ï¼šä½¿ç”¨ `Buffer.alloc(size)`ã€‚**'
- en: Don't think about performance. Don't think about micro-optimizations. Your primary
    goals are correctness and security. `Buffer.alloc()` provides both. For the vast
    majority of application code (parsing requests, building responses, interacting
    with databases), the performance cost of zero-filling is so small that it will
    never, ever be your bottleneck. Network latency, disk I/O, database query time,
    and even your own business logic will be orders of magnitude slower. Using `allocUnsafe`
    in these contexts is a classic case of premature optimization - the root of all
    evil.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦è€ƒè™‘æ€§èƒ½ã€‚ä¸è¦è€ƒè™‘å¾®ä¼˜åŒ–ã€‚æ‚¨çš„ä¸»è¦ç›®æ ‡æ˜¯æ­£ç¡®æ€§å’Œå®‰å…¨æ€§ã€‚`Buffer.alloc()` æä¾›äº†è¿™ä¸¤è€…ã€‚å¯¹äºç»å¤§å¤šæ•°åº”ç”¨ç¨‹åºä»£ç ï¼ˆè§£æè¯·æ±‚ã€æ„å»ºå“åº”ã€ä¸æ•°æ®åº“äº¤äº’ï¼‰ï¼Œé›¶å¡«å……çš„æ€§èƒ½æˆæœ¬éå¸¸å°ï¼Œä»¥è‡³äºå®ƒæ°¸è¿œä¸ä¼šæˆä¸ºæ‚¨çš„ç“¶é¢ˆã€‚ç½‘ç»œå»¶è¿Ÿã€ç£ç›˜
    I/Oã€æ•°æ®åº“æŸ¥è¯¢æ—¶é—´ï¼Œç”šè‡³æ‚¨è‡ªå·±çš„ä¸šåŠ¡é€»è¾‘éƒ½ä¼šæ…¢å¾—å¤šã€‚åœ¨è¿™äº›ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨ `allocUnsafe` æ˜¯ä¸€ä¸ªå…¸å‹çš„è¿‡æ—©ä¼˜åŒ–â€”â€”æ‰€æœ‰é‚ªæ¶çš„æ ¹æºã€‚
- en: '**Next, wait for the `Evidence`**'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¥ä¸‹æ¥ï¼Œç­‰å¾… `Evidence`**'
- en: Do not deviate from Step 1 unless you have concrete, undeniable evidence that
    a buffer allocation is a performance bottleneck.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤éæ‚¨æœ‰å…·ä½“ã€ä¸å¯å¦è®¤çš„è¯æ®è¡¨æ˜ç¼“å†²åŒºåˆ†é…æ˜¯æ€§èƒ½ç“¶é¢ˆï¼Œå¦åˆ™ä¸è¦åç¦»ç¬¬ä¸€æ­¥ã€‚
- en: '**Question:** What does that evidence look like?'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**é—®é¢˜ï¼šè¿™ç§è¯æ®çœ‹èµ·æ¥åƒä»€ä¹ˆï¼Ÿ**'
- en: '**Answer:** A CPU profile (from a tool like `0x`, Node''s built-in profiler,
    or a production APM tool) that clearly shows a significant amount of time being
    spent inside the `Buffer.alloc()` function call, specifically on the line of code
    you are considering changing.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›ç­”ï¼šä¸€ä¸ª CPU é…ç½®æ–‡ä»¶ï¼ˆæ¥è‡ªåƒ `0x`ã€Node å†…ç½®çš„å‰–æå™¨æˆ–ç”Ÿäº§ APM å·¥å…·è¿™æ ·çš„å·¥å…·ï¼‰ï¼Œå®ƒæ¸…æ¥šåœ°æ˜¾ç¤ºåœ¨ `Buffer.alloc()`
    å‡½æ•°è°ƒç”¨ä¸­èŠ±è´¹äº†å¤§é‡çš„æ—¶é—´ï¼Œå°¤å…¶æ˜¯åœ¨æ‚¨è€ƒè™‘æ›´æ”¹çš„ä»£ç è¡Œä¸Šã€‚**'
- en: If you don't have this profile, you are not allowed to proceed. Guesses, feelings,
    or "I think this might be faster" are not evidence.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ²¡æœ‰è¿™ä¸ªé…ç½®æ–‡ä»¶ï¼Œæ‚¨å°†ä¸è¢«å…è®¸ç»§ç»­ã€‚çŒœæµ‹ã€æ„Ÿè§‰æˆ–â€œæˆ‘è®¤ä¸ºè¿™å¯èƒ½æ›´å¿«â€éƒ½ä¸æ˜¯è¯æ®ã€‚
- en: '**Finally, if `alloc()` Is a Proven Bottleneck, consider `allocUnsafe()`**'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ€åï¼Œå¦‚æœ `alloc()` æ˜¯å·²è¯å®çš„ç“¶é¢ˆï¼Œè€ƒè™‘ä½¿ç”¨ `allocUnsafe()`**'
- en: You have a profile. `Buffer.alloc()` is lighting up like a Christmas tree and
    causing your service to miss its SLAs. Now, and only now, can you *consider* using
    `Buffer.allocUnsafe()`. To do so, you must be able to answer "YES" to the following
    question -
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æœ‰ä¸€ä¸ªé…ç½®æ–‡ä»¶ã€‚`Buffer.alloc()` åƒåœ£è¯æ ‘ä¸€æ ·é—ªçƒï¼Œå¯¼è‡´ä½ çš„æœåŠ¡é”™è¿‡æœåŠ¡çº§åˆ«åè®®ï¼ˆSLAï¼‰ã€‚ç°åœ¨ï¼Œåªæœ‰ç°åœ¨ï¼Œä½ æ‰èƒ½ *è€ƒè™‘* ä½¿ç”¨ `Buffer.allocUnsafe()`ã€‚ä¸ºæ­¤ï¼Œä½ å¿…é¡»èƒ½å¤Ÿå¯¹ä»¥ä¸‹é—®é¢˜å›ç­”â€œæ˜¯â€
    -
- en: '**Question:** After I call `Buffer.allocUnsafe(size)`, will my very next operations
    **unconditionally and completely** overwrite every single byte of that buffer,
    from index 0 to `size - 1`?'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**é—®é¢˜ï¼š** åœ¨æˆ‘è°ƒç”¨ `Buffer.allocUnsafe(size)` ä¹‹åï¼Œæˆ‘çš„ä¸‹ä¸€ä¸ªæ“ä½œå°† **æ— æ¡ä»¶ä¸”å®Œå…¨** è¦†å†™è¯¥ç¼“å†²åŒºçš„æ¯ä¸ªå­—èŠ‚ï¼Œä»ç´¢å¼•0åˆ°
    `size - 1` å—ï¼Ÿ'
- en: '"Unconditionally" means there are no `if` branches, no `try...catch` blocks,
    no loops that could exit early, that would allow any part of the buffer to be
    used before it has been fully overwritten.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: â€œæ— æ¡ä»¶â€æ„å‘³ç€æ²¡æœ‰ `if` åˆ†æ”¯ï¼Œæ²¡æœ‰ `try...catch` å—ï¼Œæ²¡æœ‰å¯èƒ½æå‰é€€å‡ºçš„å¾ªç¯ï¼Œè¿™ä¼šå…è®¸ç¼“å†²åŒºçš„ä»»ä½•éƒ¨åˆ†åœ¨å®Œå…¨è¦†ç›–ä¹‹å‰è¢«ä½¿ç”¨ã€‚
- en: '**Good Candidate -** `fs.readSync(fd, buf, ...)` where you read the full size
    of the buffer. The OS guarantees the overwrite.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è‰¯å¥½å€™é€‰è€… -** `fs.readSync(fd, buf, ...)` å…¶ä¸­ä½ è¯»å–ç¼“å†²åŒºçš„å®Œæ•´å¤§å°ã€‚æ“ä½œç³»ç»Ÿä¿è¯è¦†ç›–ã€‚'
- en: '**Good Candidate -** `buf.fill(someValue)` immediately after allocation. You
    are explicitly overwriting the memory.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è‰¯å¥½å€™é€‰è€… -** åœ¨åˆ†é…åç«‹å³ä½¿ç”¨ `buf.fill(someValue)`ã€‚ä½ æ­£åœ¨æ˜ç¡®åœ°è¦†ç›–å†…å­˜ã€‚'
- en: '**Bad Candidate -** You allocate a 1024-byte buffer, and then have a loop that
    might only write 500 bytes depending on input. This is a security hole waiting
    to happen.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸è‰¯å€™é€‰è€… -** ä½ åˆ†é…äº†ä¸€ä¸ª1024å­—èŠ‚çš„ç¼“å†²åŒºï¼Œç„¶åæœ‰ä¸€ä¸ªå¾ªç¯ï¼Œå¯èƒ½åªå†™å…¥500å­—èŠ‚ï¼Œè¿™å–å†³äºè¾“å…¥ã€‚è¿™æ˜¯ä¸€ä¸ªç­‰å¾…å‘ç”Ÿçš„å®‰å…¨æ¼æ´ã€‚'
- en: '**Bad Candidate -** You allocate a buffer, then enter a `try...catch` block
    to fill it. If an error is thrown midway through, the catch block might log or
    expose the partially-filled buffer.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸è‰¯å€™é€‰è€… -** ä½ åˆ†é…äº†ä¸€ä¸ªç¼“å†²åŒºï¼Œç„¶åè¿›å…¥ä¸€ä¸ª `try...catch` å—æ¥å¡«å……å®ƒã€‚å¦‚æœåœ¨ä¸­é—´æŠ›å‡ºé”™è¯¯ï¼Œæ•è·å—å¯èƒ½ä¼šè®°å½•æˆ–æš´éœ²éƒ¨åˆ†å¡«å……çš„ç¼“å†²åŒºã€‚'
- en: If you can't meet this strict requirement, but you still have the performance
    problem, `allocUnsafe` is not the solution. Your problem lies elsewhere. You might
    need to rethink your algorithm to avoid the allocation entirely, perhaps by using
    streams more effectively or pre-allocating a single larger work buffer.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ— æ³•æ»¡è¶³è¿™ä¸ªä¸¥æ ¼çš„è¦æ±‚ï¼Œä½†ä»ç„¶å­˜åœ¨æ€§èƒ½é—®é¢˜ï¼Œ`allocUnsafe` ä¸æ˜¯è§£å†³æ–¹æ¡ˆã€‚ä½ çš„é—®é¢˜å‡ºåœ¨å…¶ä»–åœ°æ–¹ã€‚ä½ å¯èƒ½éœ€è¦é‡æ–°æ€è€ƒä½ çš„ç®—æ³•ï¼Œä»¥é¿å…å®Œå…¨åˆ†é…ï¼Œä¾‹å¦‚é€šè¿‡æ›´æœ‰æ•ˆåœ°ä½¿ç”¨æµæˆ–é¢„åˆ†é…å•ä¸ªè¾ƒå¤§çš„å·¥ä½œç¼“å†²åŒºã€‚
- en: '**Regarding `Buffer.from()` -**'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**å…³äº `Buffer.from()` -**'
- en: The decision is based on your source data.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: å†³å®šåŸºäºä½ çš„æºæ•°æ®ã€‚
- en: '**Question:** What are you trying to do?'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '**é—®é¢˜ï¼š** ä½ è¯•å›¾åšä»€ä¹ˆï¼Ÿ'
- en: '**If creating a buffer from a string, array, or another buffer?** Use `Buffer.from()`.
    Be aware of the performance cost of transcoding/copying.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¦‚æœéœ€è¦ä»å­—ç¬¦ä¸²ã€æ•°ç»„æˆ–å…¶ä»–ç¼“å†²åŒºåˆ›å»ºç¼“å†²åŒºï¼Ÿ** ä½¿ç”¨ `Buffer.from()`ã€‚æ³¨æ„è½¬ç /å¤åˆ¶çš„æ€§èƒ½æˆæœ¬ã€‚'
- en: '**If creating a buffer from an `ArrayBuffer` or other external memory you don''t
    control?** Be extremely cautious. If you need to guarantee the buffer''s contents
    will not change, make an explicit copy using `Buffer.alloc()` and `source.copy(destination)`.
    Do not trust that `Buffer.from()` will make a copy for you. Assume it might create
    a shared-memory view and code defensively.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¦‚æœä» `ArrayBuffer` æˆ–å…¶ä»–ä½ æ— æ³•æ§åˆ¶çš„å†…å­˜åˆ›å»ºç¼“å†²åŒºï¼Ÿ** éå¸¸å°å¿ƒã€‚å¦‚æœä½ éœ€è¦ä¿è¯ç¼“å†²åŒºçš„å†…å®¹ä¸ä¼šæ”¹å˜ï¼Œè¯·ä½¿ç”¨ `Buffer.alloc()`
    å’Œ `source.copy(destination)` æ˜ç¡®å¤åˆ¶ã€‚ä¸è¦ç›¸ä¿¡ `Buffer.from()` ä¼šä¸ºä½ å¤åˆ¶ã€‚å‡è®¾å®ƒå¯èƒ½åˆ›å»ºä¸€ä¸ªå…±äº«å†…å­˜è§†å›¾ï¼Œå¹¶é˜²å¾¡æ€§åœ°ç¼–å†™ä»£ç ã€‚'
- en: This framework prioritizes safety above all else, and only allows for performance
    optimizations when they are justified by data and can be proven to be secure.
    Adhering to it will prevent 99% of the buffer-related disasters you might otherwise
    face.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¡†æ¶ä¼˜å…ˆè€ƒè™‘å®‰å…¨æ€§ï¼Œåªæœ‰åœ¨æ•°æ®è¯æ˜åˆç†ä¸”å¯ä»¥è¯æ˜æ˜¯å®‰å…¨çš„æƒ…å†µä¸‹æ‰å…è®¸æ€§èƒ½ä¼˜åŒ–ã€‚éµå¾ªå®ƒå°†é˜²æ­¢ä½ å¯èƒ½é‡åˆ°çš„99%çš„ä¸ç¼“å†²åŒºç›¸å…³çš„ç¾éš¾ã€‚
- en: Migration Patterns and Safer Defaults
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿ç§»æ¨¡å¼å’Œå®‰å…¨é»˜è®¤å€¼
- en: Let's say you've inherited a legacy codebase, or you've just read this chapter
    and are breaking out in a cold sweat. How do you find and fix these issues?
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ ç»§æ‰¿äº†é—ç•™ä»£ç åº“ï¼Œæˆ–è€…ä½ åˆšåˆšé˜…è¯»äº†è¿™ä¸€ç« ï¼Œæ­£å¤§æ±—æ·‹æ¼“ã€‚ä½ è¯¥å¦‚ä½•æ‰¾åˆ°å¹¶ä¿®å¤è¿™äº›é—®é¢˜ï¼Ÿ
- en: Your first step is to audit the codebase for the dangerous patterns. A simple
    `grep` or your text editor's global search is your best friend.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çš„ç¬¬ä¸€æ­¥æ˜¯å®¡è®¡ä»£ç åº“ä¸­çš„å±é™©æ¨¡å¼ã€‚ç®€å•çš„ `grep` æˆ–ä½ çš„æ–‡æœ¬ç¼–è¾‘å™¨çš„å…¨å±€æœç´¢æ˜¯ä½ çš„æœ€ä½³æœ‹å‹ã€‚
- en: Firstly, **search for `new Buffer()`**. This is the old, deprecated constructor.
    It was notoriously unsafe, with behavior that changed depending on the arguments.
    Its behavior is similar to a mix of `allocUnsafe` and `from`. Every single instance
    of `new Buffer()` must be removed. It's not a question of "if," it's a critical
    vulnerability. Most Node.js environments will even issue a runtime deprecation
    warning for this.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œ**æœç´¢ `new Buffer()`**ã€‚è¿™æ˜¯æ—§çš„ã€å·²å¼ƒç”¨çš„æ„é€ å‡½æ•°ã€‚å®ƒè‡­åæ˜­è‘—åœ°ä¸å®‰å…¨ï¼Œå…¶è¡Œä¸ºå–å†³äºå‚æ•°ã€‚å…¶è¡Œä¸ºç±»ä¼¼äº `allocUnsafe`
    å’Œ `from` çš„æ··åˆã€‚æ¯ä¸ª `new Buffer()` çš„å®ä¾‹éƒ½å¿…é¡»è¢«ç§»é™¤ã€‚è¿™ä¸æ˜¯ä¸€ä¸ªâ€œæ˜¯å¦â€çš„é—®é¢˜ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³é”®çš„å®‰å…¨æ¼æ´ã€‚å¤§å¤šæ•° Node.js
    ç¯å¢ƒç”šè‡³ä¼šå¯¹è¿™ä¸ªå‘å‡ºè¿è¡Œæ—¶å¼ƒç”¨è­¦å‘Šã€‚
- en: Then, **search for `Buffer.allocUnsafe`**. This is your primary target. For
    every result, you must apply the Production Decision Framework from the previous
    section.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œ**æœç´¢ `Buffer.allocUnsafe`**ã€‚è¿™æ˜¯ä½ çš„ä¸»è¦ç›®æ ‡ã€‚å¯¹äºæ¯ä¸ªç»“æœï¼Œä½ å¿…é¡»åº”ç”¨ä¸Šä¸€èŠ‚ä¸­çš„ç”Ÿäº§å†³ç­–æ¡†æ¶ã€‚
- en: Is there a profiler output justifying its use? Probably not.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ˜¯å¦æœ‰è¯æ˜å…¶ä½¿ç”¨çš„åˆ†æå™¨è¾“å‡ºï¼Ÿå¯èƒ½æ²¡æœ‰ã€‚
- en: If so, is it followed by an unconditional, complete overwrite?
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ˜¯ï¼Œå®ƒæ˜¯å¦éšåæ˜¯ä¸€ä¸ªæ— æ¡ä»¶ã€å®Œæ•´çš„è¦†ç›–ï¼Ÿ
- en: If the answer to either of these is no, it needs to be replaced.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™ä¸¤ä¸ªé—®é¢˜çš„ç­”æ¡ˆéƒ½æ˜¯å¦å®šçš„ï¼Œå®ƒéœ€è¦è¢«æ›¿æ¢ã€‚
- en: The migration path is usually straightforward.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: è¿ç§»è·¯å¾„é€šå¸¸æ˜¯ç›´æ¥çš„ã€‚
- en: '**`new Buffer(number)`** -> **`Buffer.alloc(number)`** is the most common and
    critical fix. The old constructor, when passed a number, did *not* zero-fill the
    memory. The modern, safe equivalent is `Buffer.alloc()`.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '**`new Buffer(number)`** -> **`Buffer.alloc(number)`** æ˜¯æœ€å¸¸è§ä¸”å…³é”®çš„ä¿®å¤ã€‚æ—§çš„æ„é€ å‡½æ•°åœ¨ä¼ é€’ä¸€ä¸ªæ•°å­—æ—¶ï¼Œå¹¶æ²¡æœ‰å¯¹å†…å­˜è¿›è¡Œé›¶å¡«å……ã€‚ç°ä»£ã€å®‰å…¨çš„ç­‰æ•ˆæ–¹æ³•æ˜¯
    `Buffer.alloc()`ã€‚'
- en: '[PRE21]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: From **`Buffer.allocUnsafe(size)`** to **`Buffer.alloc(size)`** if an `allocUnsafe`
    call cannot be proven to be safe, the fix is to simply switch to its safe counterpart.
    Yes, this may have a performance impact. That is the price of security. If the
    performance regression is unacceptable, it means you need to re-architect that
    piece of code to be less allocation-heavy, not that you should stick with the
    unsafe version.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ— æ³•è¯æ˜ `allocUnsafe` è°ƒç”¨æ˜¯å®‰å…¨çš„ï¼Œä» **`Buffer.allocUnsafe(size)`** åˆ° **`Buffer.alloc(size)`**
    çš„ä¿®å¤å°±æ˜¯ç®€å•åœ°åˆ‡æ¢åˆ°å…¶å®‰å…¨çš„å¯¹åº”ç‰ˆæœ¬ã€‚æ˜¯çš„ï¼Œè¿™å¯èƒ½ä¼šå½±å“æ€§èƒ½ã€‚è¿™æ˜¯å®‰å…¨æ€§çš„ä»£ä»·ã€‚å¦‚æœæ€§èƒ½å›å½’æ˜¯ä¸å¯æ¥å—çš„ï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦é‡æ„é‚£éƒ¨åˆ†ä»£ç ä»¥å‡å°‘åˆ†é…çš„é‡é‡ï¼Œè€Œä¸æ˜¯ä½ åº”è¯¥åšæŒä½¿ç”¨ä¸å®‰å…¨çš„ç‰ˆæœ¬ã€‚
- en: From **`new Buffer(string)`** to **`Buffer.from(string)`** since the old constructor
    could also take a string.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ä» **`new Buffer(string)`** åˆ° **`Buffer.from(string)`**ï¼Œå› ä¸ºæ—§çš„æ„é€ å‡½æ•°ä¹Ÿå¯ä»¥æ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚
- en: '[PRE22]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Auditing once is good, but preventing new problems is better. You should enforce
    these rules automatically using a linter. The `eslint-plugin-node` has several
    rules that are essential for this.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: å®¡è®¡ä¸€æ¬¡æ˜¯å¥½çš„ï¼Œä½†é¢„é˜²æ–°é—®é¢˜æ˜¯æ›´å¥½çš„ã€‚ä½ åº”è¯¥ä½¿ç”¨ä»£ç æ£€æŸ¥å™¨è‡ªåŠ¨æ‰§è¡Œè¿™äº›è§„åˆ™ã€‚`eslint-plugin-node` æœ‰å‡ ä¸ªå¯¹äºè¿™ä¸€ç‚¹è‡³å…³é‡è¦çš„è§„åˆ™ã€‚
- en: The rule **`node/no-deprecated-api`** will automatically flag uses of `new Buffer()`,
    preventing anyone from re-introducing it.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: è§„åˆ™ **`node/no-deprecated-api`** ä¼šè‡ªåŠ¨æ ‡è®° `new Buffer()` çš„ä½¿ç”¨ï¼Œé˜²æ­¢ä»»ä½•äººé‡æ–°å¼•å…¥å®ƒã€‚
- en: For more advanced protection, you can write a custom ESLint rule that flags
    all uses of `Buffer.allocUnsafe`. You can then use `// eslint-disable-next-line`
    comments on the few, carefully-vetted lines where its use is justified. This forces
    every developer who uses it to explicitly acknowledge the risk and provide a comment
    explaining why their use case is safe. It makes unsafe code stand out during code
    review, which is exactly what you want.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´é«˜çº§çš„ä¿æŠ¤ï¼Œä½ å¯ä»¥ç¼–å†™ä¸€ä¸ªè‡ªå®šä¹‰çš„ ESLint è§„åˆ™ï¼Œæ ‡è®°æ‰€æœ‰ `Buffer.allocUnsafe` çš„ä½¿ç”¨ã€‚ç„¶åï¼Œä½ å¯ä»¥åœ¨å°‘æ•°ç»è¿‡ä»”ç»†å®¡æŸ¥ã€å…¶ä½¿ç”¨æ˜¯åˆç†çš„è¡Œä¸Šä½¿ç”¨
    `// eslint-disable-next-line` æ³¨é‡Šã€‚è¿™è¿«ä½¿æ¯ä¸ªä½¿ç”¨å®ƒçš„å¼€å‘è€…æ˜ç¡®æ‰¿è®¤é£é™©ï¼Œå¹¶æä¾›ä¸€ä¸ªæ³¨é‡Šè§£é‡Šä¸ºä»€ä¹ˆä»–ä»¬çš„ç”¨ä¾‹æ˜¯å®‰å…¨çš„ã€‚è¿™ä½¿å¾—ä¸å®‰å…¨ä»£ç åœ¨ä»£ç å®¡æŸ¥ä¸­çªå‡ºï¼Œè¿™æ­£æ˜¯ä½ æƒ³è¦çš„ã€‚
- en: The tools and patterns exist to make the safe way the easy way. Use them.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜åœ¨å·¥å…·å’Œæ¨¡å¼å¯ä»¥ä½¿å®‰å…¨çš„æ–¹å¼å˜å¾—ç®€å•ã€‚ä½¿ç”¨å®ƒä»¬ã€‚
- en: Re-cap on the best practices
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å›é¡¾æœ€ä½³å®è·µ
- en: Let's distill everything we've discussed into a clear, actionable set of guidelines.
    This is the cheat sheet you should have pinned in your mind whenever you're working
    with binary data in Node.js.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°†æˆ‘ä»¬è®¨è®ºçš„æ‰€æœ‰å†…å®¹æç‚¼æˆä¸€å¥—æ¸…æ™°ã€å¯æ“ä½œçš„æŒ‡å—ã€‚è¿™æ˜¯ä½ åœ¨å¤„ç† Node.js ä¸­çš„äºŒè¿›åˆ¶æ•°æ®æ—¶åº”è¯¥ç‰¢è®°åœ¨å¿ƒçš„é€ŸæŸ¥è¡¨ã€‚
- en: '**Default to `Buffer.alloc()` always.** Make it muscle memory. This is the
    single most important practice. It is predictable, secure, and its performance
    is more than sufficient for the vast majority of use cases.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å§‹ç»ˆé»˜è®¤ä½¿ç”¨ `Buffer.alloc()`**ã€‚è®©å®ƒæˆä¸ºè‚Œè‚‰è®°å¿†ã€‚è¿™æ˜¯æœ€é‡è¦çš„å®è·µã€‚å®ƒæ˜¯å¯é¢„æµ‹çš„ã€å®‰å…¨çš„ï¼Œå¹¶ä¸”å…¶æ€§èƒ½å¯¹äºç»å¤§å¤šæ•°ç”¨ä¾‹æ¥è¯´å·²ç»è¶³å¤Ÿã€‚'
- en: '**Never use `Buffer.allocUnsafe()` unless you have a CPU profile proving `Buffer.alloc()`
    is your bottleneck.** Do not guess. Do not assume. Measure. If you don''t have
    a profile, you don''t have a problem that warrants an unsafe solution.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é™¤éä½ æœ‰CPUæ€§èƒ½åˆ†æè¯æ˜`Buffer.alloc()`æ˜¯ä½ çš„ç“¶é¢ˆï¼Œå¦åˆ™æ°¸è¿œä¸è¦ä½¿ç”¨`Buffer.allocUnsafe()`ã€‚** ä¸è¦çŒœæµ‹ã€‚ä¸è¦å‡è®¾ã€‚æµ‹é‡ã€‚å¦‚æœä½ æ²¡æœ‰æ€§èƒ½åˆ†æï¼Œä½ å°±ä¸å­˜åœ¨éœ€è¦ä¸å®‰å…¨è§£å†³æ–¹æ¡ˆçš„é—®é¢˜ã€‚'
- en: '**If you *must* use `Buffer.allocUnsafe()`, you *must* guarantee an immediate,
    synchronous, and complete overwrite of the entire buffer.** Any code path that
    allows the buffer to be read or used before it''s fully filled is a security vulnerability.
    Scrutinize these locations in code reviews.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¦‚æœä½ *å¿…é¡»*ä½¿ç”¨`Buffer.allocUnsafe()`ï¼Œä½ å¿…é¡»ä¿è¯ç«‹å³ã€åŒæ­¥å’Œå®Œæ•´åœ°è¦†ç›–æ•´ä¸ªç¼“å†²åŒºã€‚** ä»»ä½•å…è®¸åœ¨ç¼“å†²åŒºå®Œå…¨å¡«æ»¡ä¹‹å‰è¯»å–æˆ–ä½¿ç”¨ç¼“å†²åŒºçš„ä»£ç è·¯å¾„éƒ½æ˜¯å®‰å…¨æ¼æ´ã€‚åœ¨ä»£ç å®¡æŸ¥ä¸­ä»”ç»†æ£€æŸ¥è¿™äº›ä½ç½®ã€‚'
- en: '**Immediately remove and replace all instances of the deprecated `new Buffer()`
    constructor.** It is unsafe and has been replaced by `Buffer.alloc()` and `Buffer.from()`.
    This is non-negotiable.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç«‹å³åˆ é™¤å¹¶æ›¿æ¢æ‰€æœ‰å·²å¼ƒç”¨çš„`new Buffer()`æ„é€ å‡½æ•°å®ä¾‹ã€‚** å®ƒæ˜¯ä¸å®‰å…¨çš„ï¼Œå·²è¢«`Buffer.alloc()`å’Œ`Buffer.from()`å–ä»£ã€‚è¿™æ˜¯ä¸å¯åå•†çš„ã€‚'
- en: '**Be suspicious of `Buffer.from()` with `ArrayBuffer`s.** When receiving an
    `ArrayBuffer` from an external source, assume it creates a shared-memory view.
    If you need a stable, immutable copy, create it explicitly with `Buffer.alloc(size)`
    and `.copy()`.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¯¹`Buffer.from()`ä¸`ArrayBuffer`æŒæ€€ç–‘æ€åº¦ã€‚** å½“ä»å¤–éƒ¨æ¥æºæ¥æ”¶`ArrayBuffer`æ—¶ï¼Œå‡è®¾å®ƒåˆ›å»ºäº†ä¸€ä¸ªå…±äº«å†…å­˜è§†å›¾ã€‚å¦‚æœä½ éœ€è¦ä¸€ä¸ªç¨³å®šã€ä¸å¯å˜çš„å‰¯æœ¬ï¼Œè¯·ä½¿ç”¨`Buffer.alloc(size)`å’Œ`.copy()`æ˜¾å¼åˆ›å»ºã€‚'
- en: '**Lint for unsafe patterns.** Use ESLint plugins like `eslint-plugin-node`
    to automatically ban `new Buffer()`. Consider creating a custom rule to flag `Buffer.allocUnsafe`
    to force developers to justify its use.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ£€æŸ¥ä¸å®‰å…¨æ¨¡å¼ã€‚** ä½¿ç”¨ESLintæ’ä»¶å¦‚`eslint-plugin-node`è‡ªåŠ¨ç¦æ­¢`new Buffer()`ã€‚è€ƒè™‘åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰è§„åˆ™æ¥æ ‡è®°`Buffer.allocUnsafe`ï¼Œè¿«ä½¿å¼€å‘è€…è¯æ˜å…¶ä½¿ç”¨ç†ç”±ã€‚'
- en: '**Avoid chatty allocation patterns in hot paths.** Creating many small, short-lived
    buffers in a tight loop (e.g., using `Buffer.concat` repeatedly) can thrash the
    garbage collector and hurt performance. Look for ways to use streams or pre-allocate
    a single larger buffer to reduce allocation churn.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é¿å…åœ¨çƒ­ç‚¹è·¯å¾„ä¸­é‡‡ç”¨å¤šè¯åˆ†é…æ¨¡å¼ã€‚** åœ¨ç´§å¯†å¾ªç¯ä¸­åˆ›å»ºè®¸å¤šå°å‹ã€çŸ­æš‚å­˜åœ¨çš„ç¼“å†²åŒºï¼ˆä¾‹å¦‚ï¼Œé‡å¤ä½¿ç”¨`Buffer.concat`ï¼‰å¯èƒ½ä¼šä½¿åƒåœ¾æ”¶é›†å™¨è¿‡è½½å¹¶æŸå®³æ€§èƒ½ã€‚å¯»æ‰¾ä½¿ç”¨æµæˆ–é¢„åˆ†é…å•ä¸ªè¾ƒå¤§ç¼“å†²åŒºçš„æ–¹æ³•ä»¥å‡å°‘åˆ†é…æ³¢åŠ¨ã€‚'
- en: '**Comment dangerous code.** If you have a legitimate, benchmark-proven reason
    to use `Buffer.allocUnsafe`, leave a detailed comment explaining *why*. Link to
    the benchmark data or profiler output. The next developer (which might be you
    in six months) needs to understand the risk and the justification.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ³¨é‡Šå±é™©ä»£ç ã€‚** å¦‚æœä½ æœ‰ä¸€ä¸ªåˆæ³•çš„ã€ç»è¿‡åŸºå‡†æµ‹è¯•è¯æ˜çš„ç†ç”±ä½¿ç”¨`Buffer.allocUnsafe`ï¼Œç•™ä¸‹ä¸€ä¸ªè¯¦ç»†çš„æ³¨é‡Šè§£é‡Š*ä¸ºä»€ä¹ˆ*ã€‚é“¾æ¥åˆ°åŸºå‡†æ•°æ®æˆ–åˆ†æå™¨è¾“å‡ºã€‚ä¸‹ä¸€ä¸ªå¼€å‘è€…ï¼ˆå¯èƒ½å…­ä¸ªæœˆåå°±æ˜¯ä½ ï¼‰éœ€è¦ç†è§£é£é™©å’Œç†ç”±ã€‚'
- en: '[PRE23]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Closing
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“æŸ
- en: The choice between `alloc`, `allocUnsafe`, and `from` is about understanding
    the specific contract each function offers and matching it to the specific needs
    of your code, with a heavy bias towards safety. The speed of `allocUnsafe` is
    a powerful temptation, but the cost of failure is a catastrophic data breach.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é€‰æ‹©`alloc`ã€`allocUnsafe`å’Œ`from`ä¹‹é—´ï¼Œæ˜¯å…³äºç†è§£æ¯ä¸ªå‡½æ•°æä¾›çš„å…·ä½“åˆçº¦å¹¶å°†å…¶ä¸ä½ çš„ä»£ç çš„å…·ä½“éœ€æ±‚ç›¸åŒ¹é…ï¼Œå…¶ä¸­å¯¹å®‰å…¨æ€§çš„é‡è§†ç¨‹åº¦å¾ˆé«˜ã€‚`allocUnsafe`çš„é€Ÿåº¦æ˜¯ä¸€ä¸ªå¼ºå¤§çš„è¯±æƒ‘ï¼Œä½†å¤±è´¥çš„æˆæœ¬æ˜¯ç¾éš¾æ€§çš„æ•°æ®æ³„éœ²ã€‚
- en: You now have the knowledge and the framework to make these decisions responsibly.
    You understand the memory architecture, you've seen the real-world measurements,
    and you've felt the visceral risk of getting it wrong. Go forth and build amazing
    things, but do it safely. Profile your code, be ruthless in your code reviews,
    and always, always default to the safe path.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ç°åœ¨æ‹¥æœ‰äº†çŸ¥è¯†å’Œæ¡†æ¶æ¥è´Ÿè´£ä»»åœ°åšå‡ºè¿™äº›å†³å®šã€‚ä½ ç†è§£äº†å†…å­˜æ¶æ„ï¼Œä½ çœ‹åˆ°äº†ç°å®ä¸–ç•Œçš„æµ‹é‡ç»“æœï¼Œä½ ä¹Ÿæ„Ÿå—åˆ°äº†åšé”™äº‹çš„ç›´è§‚é£é™©ã€‚å‹‡æ•¢åœ°å»æ„å»ºä»¤äººæƒŠå¹çš„äº‹ç‰©ï¼Œä½†è¯·ç¡®ä¿å®‰å…¨ã€‚åˆ†æä½ çš„ä»£ç ï¼Œåœ¨ä»£ç å®¡æŸ¥ä¸­æ— æƒ…çš„æ‰¹åˆ¤ï¼Œå¹¶ä¸”å§‹ç»ˆï¼Œå§‹ç»ˆé»˜è®¤é€‰æ‹©å®‰å…¨è·¯å¾„ã€‚
