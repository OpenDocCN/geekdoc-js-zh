- en: The Event Loop Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äº‹ä»¶å¾ªç¯è§£æ
- en: åŸæ–‡ï¼š[https://www.thenodebook.com/node-arch/event-loop-intro](https://www.thenodebook.com/node-arch/event-loop-intro)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://www.thenodebook.com/node-arch/event-loop-intro](https://www.thenodebook.com/node-arch/event-loop-intro)'
- en: The Single-Threaded Model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å•çº¿ç¨‹æ¨¡å‹
- en: If you're here, you've probably written some Node.js code before. You live and
    breathe asynchronicity. You probably write `Promise.then()` chains in your sleep
    and use `async/await` with the kind of fluency that makes others jealous. You
    know - deep in your bones - that you must *never, ever* block the main thread.
    You get the *what* of writing non-blocking code.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ åœ¨è¿™é‡Œï¼Œä½ å¯èƒ½ä¹‹å‰å†™è¿‡ä¸€äº› Node.js ä»£ç ã€‚ä½ ç”Ÿæ´»åœ¨å¼‚æ­¥çš„ä¸–ç•Œé‡Œï¼Œå‘¼å¸ç€å¼‚æ­¥çš„æ°”æ¯ã€‚ä½ å¯èƒ½åœ¨æ¢¦ä¸­éƒ½åœ¨å†™ `Promise.then()` é“¾ï¼Œå¹¶ä¸”ä½¿ç”¨
    `async/await` çš„æµç•…åº¦è®©å…¶ä»–äººç¾¡æ…•ã€‚ä½ çŸ¥é“â€”â€”æ·±å…¥éª¨é«“â€”â€”ä½ ç»å¯¹ä¸èƒ½é˜»å¡ä¸»çº¿ç¨‹ã€‚ä½ æ˜ç™½ç¼–å†™éé˜»å¡ä»£ç çš„**æ„ä¹‰**ã€‚
- en: This chapter is about the why and the how. We're going to open up that "black
    box" you've gotten used to and take a good, hard look at the cool, complex machinery
    that make it happen.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç« æ˜¯å…³äºåŸå› å’Œæ–¹æ³•çš„ã€‚æˆ‘ä»¬å°†æ‰“å¼€ä½ ä¹ æƒ¯çš„â€œé»‘ç›’â€ï¼Œå¹¶ä»”ç»†è§‚å¯Ÿä½¿è¿™ä¸€åˆ‡å‘ç”Ÿçš„é…·ç‚«ã€å¤æ‚çš„æœºæ¢°è£…ç½®ã€‚
- en: This isn't a beginner's guide. Far from it. This is a deep dive for the practicing
    engineer who's ready to graduate from a "it just works" intuition to a precise,
    mechanical model of the Node.js runtime. Weâ€™re going to break down how Node handles
    so many things at once, getting past the simple explanations to see how it really
    works underneath.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸æ˜¯ä¸€æœ¬å…¥é—¨æŒ‡å—ã€‚è¿œéå¦‚æ­¤ã€‚è¿™æ˜¯ä¸€æœ¬é’ˆå¯¹å‡†å¤‡ä»â€œå®ƒåªæ˜¯å·¥ä½œâ€çš„ç›´è§‰è¿‡æ¸¡åˆ°ç²¾ç¡®ã€æœºæ¢°çš„ Node.js è¿è¡Œæ—¶æ¨¡å‹çš„å®è·µå·¥ç¨‹å¸ˆçš„æ·±å…¥æŒ‡å—ã€‚æˆ‘ä»¬å°†åˆ†è§£ Node
    å¦‚ä½•åŒæ—¶å¤„ç†è®¸å¤šäº‹æƒ…ï¼Œè¶…è¶Šç®€å•çš„è§£é‡Šï¼Œçœ‹çœ‹å®ƒçœŸæ­£æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚
- en: 'The central paradox of Node.js, the question that keeps people up at night,
    is this: how can it handle *tens of thousands* of simultaneous connections on
    a single thread? A single worker, with no parallel execution for your JavaScript,
    achieving that kind of scale? It sounds impossible. The answer is the ***event
    loop***. By the time weâ€™re done here, you won''t just know its name; youâ€™ll understand
    its phases, its priorities, and how it talks to the other core parts of the Node
    runtime. Youâ€™ll be able to predict the execution order of any async code with
    confidence and hunt down performance bugs that used to feel like ghosts in the
    machine.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js çš„æ ¸å¿ƒæ‚–è®ºï¼Œè®©äººä»¬å¤œä¸èƒ½å¯çš„é—®é¢˜æ˜¯è¿™æ ·çš„ï¼šå®ƒå¦‚ä½•åœ¨å•çº¿ç¨‹ä¸Šå¤„ç†**æ•°ä»¥ä¸‡è®¡**çš„å¹¶å‘è¿æ¥ï¼Ÿä¸€ä¸ªæ²¡æœ‰å¹¶è¡Œæ‰§è¡Œ JavaScript çš„å•ä¸ªå·¥ä½œå™¨ï¼Œè¾¾åˆ°è¿™æ ·çš„è§„æ¨¡ï¼Ÿè¿™å¬èµ·æ¥ä¸å¯èƒ½ã€‚ç­”æ¡ˆæ˜¯**äº‹ä»¶å¾ªç¯**ã€‚åœ¨æˆ‘ä»¬å®Œæˆè¿™é‡Œä¹‹åï¼Œä½ ä¸ä»…ä¼šçŸ¥é“å®ƒçš„åå­—ï¼›ä½ è¿˜ä¼šç†è§£å®ƒçš„é˜¶æ®µã€ä¼˜å…ˆçº§ä»¥åŠå®ƒæ˜¯å¦‚ä½•ä¸å…¶ä»–
    Node è¿è¡Œæ—¶æ ¸å¿ƒéƒ¨åˆ†äº¤æµçš„ã€‚ä½ å°†èƒ½å¤Ÿè‡ªä¿¡åœ°é¢„æµ‹ä»»ä½•å¼‚æ­¥ä»£ç çš„æ‰§è¡Œé¡ºåºï¼Œå¹¶è¿½è¸ªé‚£äº›æ›¾ç»åƒæœºå™¨ä¸­çš„å¹½çµä¸€æ ·çš„æ€§èƒ½é—®é¢˜ã€‚
- en: Let's get our hands dirty.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åŠ¨æ‰‹å®è·µä¸€ä¸‹ã€‚
- en: The Call Stack
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è°ƒç”¨æ ˆ
- en: Before we can even whisper the word "asynchronous," we have to get comfortable
    with its opposite. The bedrock of all JavaScript execution is the synchronous
    call stack. Think of it as a stack of plates. Every time you call a function,
    you're placing a new plate - a "frame" - on top of the stack. This frame holds
    all the function's arguments and local variables.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ç”šè‡³èƒ½è¯´å‡ºâ€œå¼‚æ­¥â€è¿™ä¸ªè¯ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»å…ˆç†Ÿæ‚‰å®ƒçš„å¯¹ç«‹é¢ã€‚æ‰€æœ‰ JavaScript æ‰§è¡Œçš„åŸºç¡€æ˜¯åŒæ­¥è°ƒç”¨æ ˆã€‚æŠŠå®ƒæƒ³è±¡æˆä¸€å †ç›˜å­ã€‚æ¯æ¬¡è°ƒç”¨ä¸€ä¸ªå‡½æ•°ï¼Œä½ å°±åœ¨æ ˆé¡¶æ”¾ç½®ä¸€ä¸ªæ–°çš„ç›˜å­â€”â€”ä¸€ä¸ªâ€œå¸§â€ã€‚è¿™ä¸ªå¸§åŒ…å«äº†æ‰€æœ‰å‡½æ•°çš„å‚æ•°å’Œå±€éƒ¨å˜é‡ã€‚
- en: The call stack is a classic Last-In, First-Out (LIFO) structure. The last plate
    you put on is the first one you take off. When a function finishes its job and
    returns, its frame is popped off the top of the stack.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒç”¨æ ˆæ˜¯ä¸€ä¸ªç»å…¸çš„å…ˆè¿›åå‡ºï¼ˆLIFOï¼‰ç»“æ„ã€‚ä½ æœ€åæ”¾ç½®çš„ç›˜å­æ˜¯ç¬¬ä¸€ä¸ªè¢«å–ä¸‹çš„ã€‚å½“ä¸€ä¸ªå‡½æ•°å®Œæˆå…¶å·¥ä½œå¹¶è¿”å›æ—¶ï¼Œå®ƒçš„è°ƒç”¨å¸§ä»æ ˆé¡¶å¼¹å‡ºã€‚
- en: 'Let''s trace this ridiculously simple synchronous code:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬è¿½è¸ªä¸€ä¸‹è¿™æå…¶ç®€å•çš„åŒæ­¥ä»£ç ï¼š
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This outputs:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šè¾“å‡ºï¼š
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Hereâ€™s how this works -
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å¦‚ä½•å·¥ä½œçš„â€”â€”
- en: '`first()` is called. Its frame is pushed onto the stack. `[first]`'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`first()` è¢«è°ƒç”¨ã€‚å®ƒçš„è°ƒç”¨å¸§è¢«æ¨å…¥æ ˆä¸­ã€‚`[first]`'
- en: '`first()` logs "One". Easy enough.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`first()` è¾“å‡º "One"ã€‚å¾ˆç®€å•ã€‚'
- en: '`first()` calls `second()`. `second()`''s frame is plopped right on top. `[first,
    second]`'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`first()` è°ƒç”¨ `second()`ã€‚`second()` çš„è°ƒç”¨å¸§ç›´æ¥æ”¾åœ¨ä¸Šé¢ã€‚`[first, second]`'
- en: '`second()` logs "Two".'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`second()` è¾“å‡º "Two"ã€‚'
- en: '`second()` calls `third()`. `third()`''s frame gets added to the growing tower.
    `[first, second, third]`'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`second()` è°ƒç”¨ `third()`ã€‚`third()` çš„è°ƒç”¨å¸§è¢«æ·»åŠ åˆ°ä¸æ–­å¢é•¿çš„å¡”ä¸­ã€‚`[first, second, third]`'
- en: '`third()` logs "Three". It''s all out of work, so it returns. Its frame is
    popped. `[first, second]`'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`third()` è¾“å‡º "Three"ã€‚å®ƒå·²ç»å®Œæˆäº†æ‰€æœ‰å·¥ä½œï¼Œæ‰€ä»¥å®ƒè¿”å›ã€‚å®ƒçš„è°ƒç”¨å¸§è¢«å¼¹å‡ºã€‚`[first, second]`'
- en: Control returns to `second()`. It has nothing left to do, so it returns. Its
    frame is popped. `[first]`
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ§åˆ¶æƒè¿”å›åˆ° `second()`ã€‚å®ƒæ²¡æœ‰å…¶ä»–äº‹æƒ…è¦åšï¼Œæ‰€ä»¥å®ƒè¿”å›ã€‚å®ƒçš„è°ƒç”¨å¸§è¢«å¼¹å‡ºã€‚`[first]`
- en: We're back in `first()`. It logs "Done with first", runs out of lines, and returns.
    Its frame is popped. `[]`
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å›åˆ°äº†`first()`ã€‚å®ƒè®°å½•äº†â€œå®Œæˆfirstâ€ï¼Œè¿è¡Œå®Œæ‰€æœ‰è¡Œåè¿”å›ã€‚å®ƒçš„å¸§è¢«å¼¹å‡ºã€‚`[]`
- en: 'The stack is now empty. The script is done. This is the one and only workspace
    for *all* of your JavaScript. Thereâ€™s just one call stack, and it can only do
    one thing at a time: whateverâ€™s on the very top of that stack.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ ˆç°åœ¨ä¸ºç©ºã€‚è„šæœ¬å·²å®Œæˆã€‚è¿™æ˜¯ä½ æ‰€æœ‰JavaScriptçš„å”¯ä¸€å·¥ä½œç©ºé—´ã€‚åªæœ‰ä¸€ä¸ªè°ƒç”¨æ ˆï¼Œä¸€æ¬¡åªèƒ½åšä¸€ä»¶äº‹ï¼šæ ˆé¡¶ä¸Šçš„ä»»ä½•å†…å®¹ã€‚
- en: What "Blocking" Truly Means
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: â€œé˜»å¡â€çœŸæ­£æ„å‘³ç€ä»€ä¹ˆ
- en: '"Blocking" isn''t some fuzzy, abstract concept. It''s a direct, brutal consequence
    of having a single call stack. To "block the event loop" is just a fancy way of
    saying youâ€™ve put a function on the call stack that refuses to leave. It just
    sits there, taking forever to finish its work.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: â€œé˜»å¡â€ä¸æ˜¯ä¸€ä¸ªæ¨¡ç³Šçš„ã€æŠ½è±¡çš„æ¦‚å¿µã€‚å®ƒæ˜¯ä¸€ä¸ªå•ä¸€è°ƒç”¨æ ˆçš„ç›´æ¥ã€æ®‹é…·çš„åæœã€‚è¯´â€œé˜»å¡äº‹ä»¶å¾ªç¯â€åªæ˜¯ä¸ªèŠ±å“¨çš„è¯´æ³•ï¼Œæ„æ€æ˜¯ä½ åœ¨è°ƒç”¨æ ˆä¸Šæ”¾ç½®äº†ä¸€ä¸ªæ‹’ç»ç¦»å¼€çš„å‡½æ•°ã€‚å®ƒå°±é‚£æ ·åç€ï¼Œæ°¸è¿œå®Œæˆä¸äº†å®ƒçš„å·¥ä½œã€‚
- en: And while that function's frame is hogging the top of the stack, nothing else
    - *nothing* - can run. The entire process is held hostage.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œå½“é‚£ä¸ªå‡½æ•°çš„å¸§å æ®äº†æ ˆé¡¶ï¼Œæ²¡æœ‰ä»»ä½•å…¶ä»–ä¸œè¥¿â€”â€”æ²¡æœ‰ä»»ä½•ä¸œè¥¿â€”â€”å¯ä»¥è¿è¡Œã€‚æ•´ä¸ªè¿‡ç¨‹è¢«ç»‘æ¶äº†ã€‚
- en: 'Letâ€™s look at a more realistic example: a CPU-heavy crypto operation.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªæ›´ç°å®çš„ä¾‹å­ï¼šä¸€ä¸ªCPUå¯†é›†å‹çš„åŠ å¯†æ“ä½œã€‚
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Run this, and you'll see something interesting. The `setTimeout` callback, which
    should have fired after a second, only shows up *after* "Blocking operation finished."
    What gives?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œè¿™ä¸ªè„šæœ¬ï¼Œä½ ä¼šçœ‹åˆ°ä¸€äº›æœ‰è¶£çš„äº‹æƒ…ã€‚åº”è¯¥åœ¨ç§’åè§¦å‘çš„`setTimeout`å›è°ƒï¼Œå´åªåœ¨â€œé˜»å¡æ“ä½œå®Œæˆâ€ä¹‹åå‡ºç°ã€‚è¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿ
- en: We call `setTimeout`. Nodeâ€™s APIs happily schedule a timer to go off in 1000ms.
    This is a non-blocking, fire-and-forget operation.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è°ƒç”¨`setTimeout`ã€‚Nodeçš„APIæ„‰å¿«åœ°å®‰æ’äº†ä¸€ä¸ª1000æ¯«ç§’åè§¦å‘çš„å®šæ—¶å™¨ã€‚è¿™æ˜¯ä¸€ä¸ªéé˜»å¡ã€ä¸€è§¦å³å‘çš„æ“ä½œã€‚
- en: '`hashContinuously()` gets pushed onto the call stack.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`hashContinuously()`è¢«æ¨å…¥è°ƒç”¨æ ˆã€‚'
- en: The `while` loop from hell begins. For five painful seconds, the V8 engine is
    completely consumed with hashing a value over and over. The `hashContinuously`
    frame just sits at the top of the stack.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: â€œåœ°ç‹±èˆ¬çš„â€`while`å¾ªç¯å¼€å§‹äº†ã€‚åœ¨äº”ç§’é’Ÿçš„ç—›è‹¦ä¸­ï¼ŒV8å¼•æ“å®Œå…¨è¢«æ¶ˆè€—åœ¨åå¤å“ˆå¸Œä¸€ä¸ªå€¼ã€‚`hashContinuously`å¸§å°±é™é™åœ°ååœ¨æ ˆé¡¶ã€‚
- en: At the 1-second mark, the timer patiently "fires." All this means is its callback
    function is placed into a queue, ready and waiting to be executed.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨1ç§’çš„æ ‡è®°å¤„ï¼Œå®šæ—¶å™¨è€å¿ƒåœ°â€œè§¦å‘â€ã€‚è¿™æ„å‘³ç€å®ƒçš„å›è°ƒå‡½æ•°è¢«æ”¾å…¥é˜Ÿåˆ—ä¸­ï¼Œå‡†å¤‡å¹¶ç­‰å¾…æ‰§è¡Œã€‚
- en: '**But here''s the catch:** the event loop can''t touch that queue. Why? Because
    the call stack isn''t empty! Itâ€™s still stuck with `hashContinuously()`. The event
    loop is effectively frozen, tapping on the glass, waiting for the stack to clear.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä½†æ˜¯è¿™é‡Œæœ‰ä¸ªé—®é¢˜**ï¼šäº‹ä»¶å¾ªç¯æ— æ³•è§¦åŠè¿™ä¸ªé˜Ÿåˆ—ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºè°ƒç”¨æ ˆè¿˜æ²¡æœ‰ç©ºï¼å®ƒä»ç„¶å¡åœ¨`hashContinuously()`ä¸Šã€‚äº‹ä»¶å¾ªç¯å®é™…ä¸Šè¢«å†»ç»“äº†ï¼Œå°±åƒåœ¨ç»ç’ƒä¸Šæ•²å‡»ï¼Œç­‰å¾…æ ˆæ¸…ç©ºã€‚'
- en: Finally, after five seconds, the `while` loop ends. `hashContinuously()` logs
    its last message and returns. Its frame is mercifully popped from the stack.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œäº”ç§’åï¼Œ`while`å¾ªç¯ç»“æŸã€‚`hashContinuously()`è®°å½•äº†å®ƒçš„æœ€åä¸€æ¡æ¶ˆæ¯å¹¶è¿”å›ã€‚å®ƒçš„å¸§å¹¸è¿åœ°ä»æ ˆä¸­å¼¹å‡ºã€‚
- en: At last, the call stack is empty. The event loop springs to life, grabs the
    waiting timer callback, shoves it onto the stack, and executes it.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè°ƒç”¨æ ˆä¸ºç©ºã€‚äº‹ä»¶å¾ªç¯è‹é†’è¿‡æ¥ï¼ŒæŠ“å–ç­‰å¾…çš„å®šæ—¶å™¨å›è°ƒï¼Œå°†å…¶æ¨å…¥æ ˆä¸­ï¼Œå¹¶æ‰§è¡Œå®ƒã€‚
- en: This is the dictatorship of the stack. One slow function can bring your entire
    app to a screeching halt. This is the very problem Node's entire asynchronous
    architecture was built to solve. So, if the call stack is the bottleneck, where
    does the solution come from? To answer that, we have to look under the hood, beyond
    JavaScript itself.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ ˆçš„ç‹¬è£ç»Ÿæ²»ã€‚ä¸€ä¸ªæ…¢é€Ÿå‡½æ•°å¯ä»¥è®©ä½ æ•´ä¸ªåº”ç”¨ç¬é—´åœæ­¢ã€‚è¿™æ­£æ˜¯Nodeçš„æ•´ä¸ªå¼‚æ­¥æ¶æ„æ—¨åœ¨è§£å†³çš„é—®é¢˜ã€‚æ‰€ä»¥ï¼Œå¦‚æœè°ƒç”¨æ ˆæ˜¯ç“¶é¢ˆï¼Œè§£å†³æ–¹æ¡ˆä»ä½•è€Œæ¥ï¼Ÿä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¿…é¡»æ­å¼€ç›–å­ï¼Œè¶…è¶ŠJavaScriptæœ¬èº«ã€‚
- en: V8, Libuv, and the Node.js Bindings
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V8ã€Libuvå’ŒNode.jsç»‘å®š
- en: Like you read in the previous chapter [Inside the v8 Engine](https://thenodebook.com/node-arch/v8-engine-intro),
    the thing we call the "Node.js runtime" isn't one single program. It's more like
    a supergroup - a few powerful technologies playing together in perfection. Understanding
    their distinct roles is really important.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å°±åƒä½ åœ¨ä¸Šä¸€ç« ä¸­è¯»åˆ°çš„[Inside the v8 Engine](https://thenodebook.com/node-arch/v8-engine-intro)ï¼Œæˆ‘ä»¬æ‰€è¯´çš„â€œNode.jsè¿è¡Œæ—¶â€å¹¶ä¸æ˜¯ä¸€ä¸ªå•ç‹¬çš„ç¨‹åºã€‚å®ƒæ›´åƒæ˜¯ä¸€ä¸ªè¶…çº§ç»„åˆâ€”â€”ä¸€äº›å¼ºå¤§çš„æŠ€æœ¯å®Œç¾åœ°ä¸€èµ·å·¥ä½œã€‚ç†è§£å®ƒä»¬çš„ç‹¬ç‰¹è§’è‰²éå¸¸é‡è¦ã€‚
- en: '**V8: The JavaScript Execution Engine**'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**V8ï¼šJavaScriptæ‰§è¡Œå¼•æ“**'
- en: â„¹ï¸Note
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: We talked about [v8 in a lot of depth in the previous chapter](https://thenodebook.com/node-arch/v8-engine-intro)
    and thereâ€™s also going to be a dedicated lesson with six chapters (21.1â€“21.6).
    Still, I assume some readers will jump straight to this chapter, so Iâ€™ll provide
    a brief explanation for the sake of clarity.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨å‰ä¸€ç« ä¸­æ·±å…¥æ¢è®¨äº†[v8](https://thenodebook.com/node-arch/v8-engine-intro)ï¼Œå¹¶ä¸”è¿˜å°†æœ‰ä¸€ä¸ªä¸“é—¨çš„è¯¾ç¨‹ï¼ŒåŒ…å«å…­ä¸ªç« èŠ‚ï¼ˆ21.1â€“21.6ï¼‰ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘å‡è®¾ä¸€äº›è¯»è€…ä¼šç›´æ¥è·³åˆ°è¿™ä¸€ç« ï¼Œæ‰€ä»¥ä¸ºäº†æ¸…æ™°èµ·è§ï¼Œæˆ‘å°†æä¾›ç®€è¦çš„è§£é‡Šã€‚
- en: V8 is Google's legendary open-source JavaScript engine, written in C++. If Node
    were a car, V8 would be the engine (hence the name). Itâ€™s the part that actually
    executes your JavaScript code. Its main jobs are as follwos -
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: V8 æ˜¯ Google çš„ä¼ å¥‡å¼€æº JavaScript å¼•æ“ï¼Œç”¨ C++ ç¼–å†™ã€‚å¦‚æœ Node æ˜¯ä¸€è¾†è½¦ï¼ŒV8 å°±æ˜¯å¼•æ“ï¼ˆå› æ­¤å¾—åï¼‰ã€‚å®ƒæ˜¯å®é™…æ‰§è¡Œä½ çš„
    JavaScript ä»£ç çš„éƒ¨åˆ†ã€‚å…¶ä¸»è¦å·¥ä½œå¦‚ä¸‹ -
- en: V8 grabs your raw JavaScript and, through a ridiculously smart Just-In-Time
    (JIT) compilation process, transforms it into highly optimized native machine
    code. Itâ€™s why modern JavaScript is so fast.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: V8 æ•è·ä½ çš„åŸå§‹ JavaScriptï¼Œå¹¶é€šè¿‡ä¸€ä¸ªæå…¶èªæ˜çš„å³æ—¶ç¼–è¯‘ï¼ˆJITï¼‰è¿‡ç¨‹ï¼Œå°†å…¶è½¬æ¢ä¸ºé«˜åº¦ä¼˜åŒ–çš„æœ¬åœ°æœºå™¨ä»£ç ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆç°ä»£ JavaScript
    è¿è¡Œå¦‚æ­¤ä¹‹å¿«ã€‚
- en: Just like we saw, V8 is the strict manager of the single call stack, pushing
    and popping frames.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°±åƒæˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼ŒV8 æ˜¯å•ä¸€çº¿ç¨‹æ ˆçš„ä¸¥æ ¼ç®¡ç†è€…ï¼Œè´Ÿè´£æ¨å…¥å’Œå¼¹å‡ºå¸§ã€‚
- en: V8 handles all the memory allocation for your objects and variables in a place
    called the heap. It's also the garbage collector, cleaning up messes you're done
    with.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: V8 åœ¨ä¸€ä¸ªç§°ä¸ºå †çš„åœ°æ–¹å¤„ç†ä½ çš„å¯¹è±¡å’Œå˜é‡çš„å†…å­˜åˆ†é…ã€‚å®ƒä¹Ÿæ˜¯åƒåœ¾å›æ”¶å™¨ï¼Œæ¸…ç†ä½ å®Œæˆçš„å·¥ä½œã€‚
- en: 'Now, here''s what''s absolutely critical to get: what V8 *doesn''t* do. By
    itself, V8 is clueless about the outside world. It has no concept of a file system,
    it doesn''t know how to open a network socket, and it has no idea how to set a
    timer. Functions like `setTimeout`, `fs.readFile`, and `http.createServer`? They
    aren''t part of JavaScript or V8\. They are APIs provided by browsers or, in our
    case, Node.js.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç»å¯¹å…³é”®çš„é—®é¢˜è¦å¼„æ¸…æ¥šï¼šV8 *ä¸*åšä»€ä¹ˆã€‚V8 æœ¬èº«å¯¹ç°å®ä¸–ç•Œä¸€æ— æ‰€çŸ¥ã€‚å®ƒæ²¡æœ‰æ–‡ä»¶ç³»ç»Ÿçš„æ¦‚å¿µï¼Œä¸çŸ¥é“å¦‚ä½•æ‰“å¼€ç½‘ç»œå¥—æ¥å­—ï¼Œä¹Ÿä¸çŸ¥é“å¦‚ä½•è®¾ç½®å®šæ—¶å™¨ã€‚åƒ
    `setTimeout`ã€`fs.readFile` å’Œ `http.createServer` è¿™æ ·çš„å‡½æ•°ï¼Ÿå®ƒä»¬ä¸æ˜¯ JavaScript æˆ– V8 çš„ä¸€éƒ¨åˆ†ã€‚å®ƒä»¬æ˜¯ç”±æµè§ˆå™¨æˆ–åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ç”±
    Node.js æä¾›çš„ APIã€‚
- en: Think of V8 as a brilliant linguistics professor who only speaks JavaScript.
    To do anything in the real world, it needs an interpreter and a helper.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å°† V8 æƒ³è±¡æˆä¸€ä¸ªå‡ºè‰²çš„è¯­è¨€å­¦æ•™æˆï¼Œä»–åªä¼šè¯´ JavaScriptã€‚è¦åœ¨ç°å®ä¸–ç•Œä¸­åšä»»ä½•äº‹æƒ…ï¼Œå®ƒéƒ½éœ€è¦ä¸€ä¸ªè§£é‡Šå™¨å’ŒåŠ©æ‰‹ã€‚
- en: Libuv
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Libuv
- en: 'Libuv is a C library built from the ground up for one purpose: asynchronous
    I/O. It was originally made for Node.js, and it''s the secret sauce that gives
    Node its event-driven, non-blocking superpowers. Its responsibilities are huge,
    but we can lump them into three big buckets -'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Libuv æ˜¯ä¸€ä¸ªä»å¤´å¼€å§‹æ„å»ºçš„ C åº“ï¼Œå…¶ç›®çš„åªæœ‰ä¸€ä¸ªï¼šå¼‚æ­¥ I/Oã€‚å®ƒæœ€åˆæ˜¯ä¸º Node.js åˆ¶ä½œçš„ï¼Œä¹Ÿæ˜¯èµ‹äºˆ Node äº‹ä»¶é©±åŠ¨ã€éé˜»å¡è¶…èƒ½åŠ›çš„ç§˜å¯†é…æ–¹ã€‚å®ƒçš„è´£ä»»é‡å¤§ï¼Œä½†æˆ‘ä»¬å¯ä»¥å°†å…¶å½’çº³ä¸ºä¸‰ä¸ªå¤§ç±»åˆ«
    -
- en: '**The Event Loop Itself.** That''s right. The event loop we keep talking about?
    It''s implemented and run by Libuv. The six phases we''ll get into shortly are
    all orchestrated by Libuv''s C code. When you start a Node process, it''s Libuv
    that kicks off the loop.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**äº‹ä»¶å¾ªç¯æœ¬èº«**ã€‚æ²¡é”™ã€‚æˆ‘ä»¬ä¸€ç›´è°ˆè®ºçš„äº‹ä»¶å¾ªç¯ï¼Ÿå®ƒæ˜¯é€šè¿‡ Libuv å®ç°å’Œè¿è¡Œçš„ã€‚æˆ‘ä»¬å¾ˆå¿«å°†è¦è®¨è®ºçš„å…­ä¸ªé˜¶æ®µéƒ½æ˜¯ç”± Libuv çš„ C ä»£ç ç¼–æ’çš„ã€‚å½“ä½ å¯åŠ¨
    Node è¿›ç¨‹æ—¶ï¼Œæ˜¯ Libuv å¯åŠ¨å¾ªç¯ã€‚'
- en: '**Abstracting the Operating System.** This is where the real magic happens.
    Different operating systems have their own super-efficient ways of handling async
    operations. Linux has `epoll`, macOS has `kqueue`, and Windows has its I/O Completion
    Ports (IOCP). These are kernel-level tools that let a program say, "Hey, watch
    these files and network sockets for me, and just wake me up when something interesting
    happens." Libuv provides a single, beautiful C API that works on top of all these
    different systems. This is why your `http.createServer` code runs performantly
    everywhere without you having to change a single line. When you tell Node to listen
    on a port, it''s Libuv making the right non-blocking call to the OS.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**æŠ½è±¡æ“ä½œç³»ç»Ÿ**ã€‚è¿™é‡Œçš„é­”æ³•çœŸæ­£å‘ç”Ÿäº†ã€‚ä¸åŒçš„æ“ä½œç³»ç»Ÿéƒ½æœ‰è‡ªå·±å¤„ç†å¼‚æ­¥æ“ä½œçš„é«˜æ•ˆæ–¹å¼ã€‚Linux æœ‰ `epoll`ï¼ŒmacOS æœ‰ `kqueue`ï¼ŒWindows
    æœ‰å®ƒçš„ I/O å®Œæˆç«¯å£ï¼ˆIOCPï¼‰ã€‚è¿™äº›éƒ½æ˜¯å†…æ ¸çº§åˆ«çš„å·¥å…·ï¼Œå…è®¸ç¨‹åºè¯´ï¼šâ€œå˜¿ï¼Œå¸®æˆ‘ç›‘è§†è¿™äº›æ–‡ä»¶å’Œç½‘ç»œå¥—æ¥å­—ï¼Œå½“å‘ç”Ÿæœ‰è¶£çš„äº‹æƒ…æ—¶ï¼Œå°±å”¤é†’æˆ‘ã€‚â€Libuv æä¾›äº†ä¸€ä¸ªå•ä¸€ã€ç¾ä¸½çš„
    C APIï¼Œå®ƒå¯ä»¥åœ¨æ‰€æœ‰è¿™äº›ä¸åŒçš„ç³»ç»Ÿä¸Šå·¥ä½œã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ çš„ `http.createServer` ä»£ç å¯ä»¥åœ¨ä»»ä½•åœ°æ–¹é«˜æ•ˆè¿è¡Œï¼Œè€Œæ— éœ€ä½ æ›´æ”¹ä»»ä½•ä¸€è¡Œã€‚å½“ä½ å‘Šè¯‰
    Node åœ¨ç«¯å£ä¸Šç›‘å¬æ—¶ï¼Œæ˜¯ Libuv æ­£ç¡®åœ°è°ƒç”¨æ“ä½œç³»ç»Ÿè¿›è¡Œéé˜»å¡è°ƒç”¨ã€‚'
- en: '**The Thread Pool.** Okay, this is a common point of confusion, so lean in.
    We say Node is single-threaded, but that''s only half the story. Your JavaScript
    runs on a single thread, yes. But Libuv maintains its own small, internal pool
    of threads. Why? Because as great as modern OSes are, some operations are just
    unavoidably, stubbornly blocking. This includes most file system stuff, some DNS
    lookups, and a few CPU-intensive crypto functions. If Node ran these on the main
    thread, they''d block the loop - game over. Instead, Libuv cleverly delegates
    these specific jobs to its thread pool. A worker thread from the pool makes the
    slow, blocking system call. When it''s done, it signals the main event loop, which
    can then finally execute your JavaScript callback. The default size of this pool
    is four, but you can change it with the `UV_THREADPOOL_SIZE` environment variable
    (a very handy trick to know!).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**çº¿ç¨‹æ± **ã€‚å¥½å§ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„æ··æ·†ç‚¹ï¼Œæ‰€ä»¥è¯·é è¿‘ä¸€ç‚¹ã€‚æˆ‘ä»¬è¯´ Node æ˜¯å•çº¿ç¨‹çš„ï¼Œä½†è¿™åªæ˜¯æ•…äº‹çš„ä¸€åŠã€‚ä½ çš„ JavaScript åœ¨ä¸€ä¸ªçº¿ç¨‹ä¸Šè¿è¡Œï¼Œæ˜¯çš„ã€‚ä½†æ˜¯
    Libuv ç»´æŠ¤å®ƒè‡ªå·±çš„ä¸€ä¸ªå°å‹å†…éƒ¨çº¿ç¨‹æ± ã€‚ä¸ºä»€ä¹ˆï¼Ÿå› ä¸ºå°½ç®¡ç°ä»£æ“ä½œç³»ç»Ÿå¾ˆå¼ºå¤§ï¼Œä½†æœ‰äº›æ“ä½œæ˜¯ä¸å¯é¿å…åœ°ã€å›ºæ‰§åœ°é˜»å¡çš„ã€‚è¿™åŒ…æ‹¬å¤§å¤šæ•°æ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼Œä¸€äº› DNS
    æŸ¥è¯¢ï¼Œä»¥åŠä¸€äº› CPU å¯†é›†å‹çš„åŠ å¯†å‡½æ•°ã€‚å¦‚æœ Node åœ¨ä¸»çº¿ç¨‹ä¸Šè¿è¡Œè¿™äº›æ“ä½œï¼Œå®ƒä»¬ä¼šé˜»å¡å¾ªç¯â€”â€”æ¸¸æˆç»“æŸã€‚ç›¸åï¼ŒLibuv èªæ˜åœ°å°†è¿™äº›ç‰¹å®šçš„å·¥ä½œå§”æ‰˜ç»™å®ƒçš„çº¿ç¨‹æ± ã€‚çº¿ç¨‹æ± ä¸­çš„ä¸€ä¸ªå·¥ä½œçº¿ç¨‹æ‰§è¡Œç¼“æ…¢çš„é˜»å¡ç³»ç»Ÿè°ƒç”¨ã€‚å½“å®ƒå®Œæˆæ—¶ï¼Œå®ƒä¼šå‘ä¸»äº‹ä»¶å¾ªç¯å‘å‡ºä¿¡å·ï¼Œç„¶åä¸»äº‹ä»¶å¾ªç¯æœ€ç»ˆå¯ä»¥æ‰§è¡Œä½ çš„
    JavaScript å›è°ƒã€‚è¿™ä¸ªæ± çš„é»˜è®¤å¤§å°æ˜¯å››ä¸ªï¼Œä½†ä½ å¯ä»¥ä½¿ç”¨ `UV_THREADPOOL_SIZE` ç¯å¢ƒå˜é‡æ¥æ›´æ”¹å®ƒï¼ˆè¿™æ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„æŠ€å·§ï¼ï¼‰ã€‚'
- en: Node.js C++ Bindings
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Node.js C++ ç»‘å®š
- en: So now we have two separate worlds. We have the V8 world, which speaks JavaScript,
    and the Libuv world, a C library that speaks in file descriptors and system calls.
    How on earth do they talk to each other?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰ä¸¤ä¸ªç‹¬ç«‹çš„ä¸–ç•Œã€‚æˆ‘ä»¬æœ‰ V8 ä¸–ç•Œï¼Œå®ƒä½¿ç”¨ JavaScript è¿›è¡Œäº¤æµï¼Œè¿˜æœ‰ Libuv ä¸–ç•Œï¼Œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨æ–‡ä»¶æè¿°ç¬¦å’Œç³»ç»Ÿè°ƒç”¨çš„
    C åº“ã€‚ä»–ä»¬ç©¶ç«Ÿæ˜¯å¦‚ä½•äº’ç›¸äº¤æµçš„å‘¢ï¼Ÿ
- en: They communicate through a set of C++ programs called the **Node.js bindings**.
    These bindings are the crucial translation layer, the bridge that connects the
    world of V8 to the world of Libuv.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬é€šè¿‡ä¸€ç»„ç§°ä¸º **Node.js ç»‘å®š** çš„ C++ ç¨‹åºè¿›è¡Œé€šä¿¡ã€‚è¿™äº›ç»‘å®šæ˜¯è‡³å…³é‡è¦çš„ç¿»è¯‘å±‚ï¼Œæ˜¯è¿æ¥ V8 ä¸–ç•Œå’Œ Libuv ä¸–ç•Œçš„æ¡¥æ¢ã€‚
- en: When you make a seemingly simple call like `fs.readFile('/path/to/file', callback)`,
    a whole dance happens behind the scenes -
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ è¿›è¡Œä¸€ä¸ªçœ‹ä¼¼ç®€å•çš„è°ƒç”¨ï¼Œå¦‚ `fs.readFile('/path/to/file', callback)` æ—¶ï¼Œå¹•åä¼šå‘ç”Ÿä¸€ç³»åˆ—åŠ¨ä½œâ€”â€”
- en: '**V8** sees the `fs.readFile` function call and starts executing it.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**V8** çœ‹åˆ°äº† `fs.readFile` å‡½æ•°è°ƒç”¨ï¼Œå¹¶å¼€å§‹æ‰§è¡Œå®ƒã€‚'
- en: But wait! This function isn't pure JavaScript; it's a binding. The call is immediately
    routed to a specific C++ function inside Node's source code.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½†ç­‰ç­‰ï¼è¿™ä¸ªå‡½æ•°ä¸æ˜¯çº¯ JavaScriptï¼›å®ƒæ˜¯ä¸€ä¸ªç»‘å®šã€‚è°ƒç”¨ç«‹å³è¢«è·¯ç”±åˆ° Node æºä»£ç ä¸­çš„ä¸€ä¸ªç‰¹å®š C++ å‡½æ•°ã€‚
- en: This C++ binding function acts as a translator. It takes your JavaScript arguments
    (the file path and your callback function) and packages them up into a "request"
    object that Libuv can understand.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿™ä¸ª C++ ç»‘å®šå‡½æ•°å……å½“ç¿»è¯‘è€…çš„è§’è‰²ã€‚å®ƒæ¥æ”¶ä½ çš„ JavaScript å‚æ•°ï¼ˆæ–‡ä»¶è·¯å¾„å’Œä½ çš„å›è°ƒå‡½æ•°ï¼‰ï¼Œå¹¶å°†å®ƒä»¬æ‰“åŒ…æˆä¸€ä¸ª Libuv å¯ä»¥ç†è§£çš„â€œè¯·æ±‚â€å¯¹è±¡ã€‚
- en: The binding then hands this request over to **Libuv**, telling it, "Go read
    this file for me, and please use the thread pool since this might take a while."
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åå°†è¿™ä¸ªè¯·æ±‚äº¤ç»™ **Libuv**ï¼Œå¹¶å‘Šè¯‰å®ƒï¼šâ€œå¸®æˆ‘è¯»å–è¿™ä¸ªæ–‡ä»¶ï¼Œè¯·ä½¿ç”¨çº¿ç¨‹æ± ï¼Œå› ä¸ºè¿™ä¸ªæ“ä½œå¯èƒ½éœ€è¦ä¸€æ®µæ—¶é—´ã€‚â€
- en: Libuv does its thing. Once the file is read, it puts a "completion event" on
    a queue.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Libuv åšå®ƒçš„äº‹æƒ…ã€‚ä¸€æ—¦æ–‡ä»¶è¢«è¯»å–ï¼Œå®ƒå°†åœ¨é˜Ÿåˆ—ä¸Šæ”¾ç½®ä¸€ä¸ªâ€œå®Œæˆäº‹ä»¶â€ã€‚
- en: Later, the **event loop** (which is being run by Libuv) sees this event waiting.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¹‹åï¼Œ**äº‹ä»¶å¾ªç¯**ï¼ˆç”± Libuv è¿è¡Œï¼‰çœ‹åˆ°è¿™ä¸ªäº‹ä»¶æ­£åœ¨ç­‰å¾…ã€‚
- en: The event signals back to the C++ bindings.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº‹ä»¶ä¿¡å·è¿”å›åˆ° C++ ç»‘å®šã€‚
- en: The bindings take the result (either the file data or an error), translate it
    back into something JavaScript-friendly, and then - finally! - it invokes your
    original JavaScript **callback function** with those results, pushing that callback
    onto the V8 **call stack** to be executed.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»‘å®šå°†ç»“æœï¼ˆæ— è®ºæ˜¯æ–‡ä»¶æ•°æ®è¿˜æ˜¯é”™è¯¯ï¼‰è½¬æ¢å› JavaScript å‹å¥½çš„æ ¼å¼ï¼Œç„¶åâ€”â€”æœ€ç»ˆï¼â€”â€”å®ƒä½¿ç”¨è¿™äº›ç»“æœè°ƒç”¨ä½ çš„åŸå§‹ JavaScript **å›è°ƒå‡½æ•°**ï¼Œå¹¶å°†è¿™ä¸ªå›è°ƒæ¨é€åˆ°
    V8 **è°ƒç”¨æ ˆ**ä¸Šæ‰§è¡Œã€‚
- en: Phew. That round trip - from JavaScript to C++ to Libuv to the OS and all the
    way back again - is the life story of every single async operation in Node.js.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å‘¼å¸ä¸€ä¸‹ã€‚è¿™ä¸ªå¾€è¿”â€”â€”ä» JavaScript åˆ° C++ åˆ° Libuv åˆ°æ“ä½œç³»ç»Ÿï¼Œç„¶åå†è¿”å›â€”â€”æ˜¯ Node.js ä¸­æ¯ä¸ªå¼‚æ­¥æ“ä½œçš„ç”Ÿå‘½æ•…äº‹ã€‚
- en: The Six Phases in Detail
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…­ä¸ªé˜¶æ®µçš„è¯¦ç»†è¯´æ˜
- en: ğŸ’¡Tip
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡æç¤º
- en: There's an awesome tool created by [@vagostep](https://github.com/vagostep)
    that allows you to visualize how the Event Loop works. You might want to play
    around with it. Here's the link - [NodeLoops](https://nodeloops.com/)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ä¸ªç”± [@vagostep](https://github.com/vagostep) åˆ›å»ºçš„å‡ºè‰²å·¥å…·ï¼Œå¯ä»¥è®©ä½ å¯è§†åŒ–äº‹ä»¶å¾ªç¯çš„å·¥ä½œæ–¹å¼ã€‚ä½ å¯èƒ½æƒ³å°è¯•ä¸€ä¸‹ã€‚ä»¥ä¸‹æ˜¯é“¾æ¥
    - [NodeLoops](https://nodeloops.com/)
- en: The event loop isn't just one big queue. That's a common misconception. It's
    a highly structured, multi-phase cycle. Each full lap through this cycle is called
    a "tick." Getting your head around these phases is the absolute key to understanding
    why async operations execute in the order they do. Libuv's loop is just a repeating
    journey through these six core phases.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹ä»¶å¾ªç¯ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå¤§é˜Ÿåˆ—ã€‚è¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„è¯¯è§£ã€‚å®ƒæ˜¯ä¸€ä¸ªé«˜åº¦ç»“æ„åŒ–çš„ã€å¤šé˜¶æ®µçš„å¾ªç¯ã€‚åœ¨è¿™ä¸ªå¾ªç¯ä¸­å®Œæ•´ä¸€åœˆè¢«ç§°ä¸ºä¸€ä¸ªâ€œtickâ€ã€‚ç†è§£è¿™äº›é˜¶æ®µæ˜¯ç»å¯¹çš„å…³é”®ï¼Œäº†è§£å¼‚æ­¥æ“ä½œä¸ºä»€ä¹ˆä»¥å®ƒä»¬æ‰§è¡Œçš„é¡ºåºæ‰§è¡Œã€‚Libuv
    çš„å¾ªç¯åªæ˜¯å¯¹è¿™äº›å…­ä¸ªæ ¸å¿ƒé˜¶æ®µçš„é‡å¤æ—…è¡Œã€‚
- en: 'The "Tick": An Overview of a Single Iteration'
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: â€œTickâ€ï¼šå•æ¬¡è¿­ä»£çš„æ¦‚è¿°
- en: 'First things first: a "tick" is not a unit of time. It''s just a single, complete
    progression through all the phases of the event loop. A tick doesnâ€™t necessarily
    equal a specific number of milliseconds; how long it takes depends on the work
    done during that iteration.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼šä¸€ä¸ªâ€œtickâ€ä¸æ˜¯ä¸€ä¸ªæ—¶é—´å•ä½ã€‚å®ƒåªæ˜¯äº‹ä»¶å¾ªç¯æ‰€æœ‰é˜¶æ®µçš„å•æ¬¡å®Œæ•´è¿›å±•ã€‚ä¸€ä¸ª tick ä¸ä¸€å®šç­‰äºç‰¹å®šçš„æ¯«ç§’æ•°ï¼›å®ƒæŒç»­å¤šé•¿æ—¶é—´å–å†³äºé‚£æ¬¡è¿­ä»£ä¸­å®Œæˆçš„å·¥ä½œã€‚
- en: â„¹ï¸Note
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: 'If youâ€™ve played (or developed) games, think of a tick as a frame: the event
    loop, like a game loop, repeatedly performs work once per tick.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ç©è¿‡ï¼ˆæˆ–å¼€å‘è¿‡ï¼‰æ¸¸æˆï¼Œå¯ä»¥æŠŠä¸€ä¸ª tick æƒ³è±¡æˆä¸€ä¸ªå¸§ï¼šäº‹ä»¶å¾ªç¯ï¼Œå°±åƒæ¸¸æˆå¾ªç¯ä¸€æ ·ï¼Œåœ¨æ¯ä¸ª tick é‡å¤æ‰§è¡Œä¸€æ¬¡å·¥ä½œã€‚
- en: During a tick, the loop checks the queue for each phase. If a phase's queue
    has callbacks waiting, it will execute them one by one, in First-In, First-Out
    (FIFO) order, until the queue is empty or some system-dependent limit is hit.
    Then, it shuffles along to the next phase. Simple as that.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸€ä¸ª tick æœŸé—´ï¼Œå¾ªç¯æ£€æŸ¥æ¯ä¸ªé˜¶æ®µçš„é˜Ÿåˆ—ã€‚å¦‚æœä¸€ä¸ªé˜¶æ®µçš„é˜Ÿåˆ—æœ‰ç­‰å¾…çš„å›è°ƒï¼Œå®ƒå°†æŒ‰é¡ºåºé€ä¸ªæ‰§è¡Œå®ƒä»¬ï¼Œç›´åˆ°é˜Ÿåˆ—ä¸ºç©ºæˆ–è¾¾åˆ°æŸäº›ç³»ç»Ÿä¾èµ–çš„é™åˆ¶ã€‚ç„¶åï¼Œå®ƒç»§ç»­å‰è¿›åˆ°ä¸‹ä¸€ä¸ªé˜¶æ®µã€‚å°±è¿™ä¹ˆç®€å•ã€‚
- en: 'Phase 1: Timers'
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€é˜¶æ®µï¼šè®¡æ—¶å™¨
- en: This is the first stop on our tour. The loop's only job here is to run callbacks
    scheduled by `setTimeout()` and `setInterval()`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬çš„å¯¼æ¸¸çš„ç¬¬ä¸€ç«™ã€‚å¾ªç¯åœ¨è¿™é‡Œçš„å”¯ä¸€ä»»åŠ¡æ˜¯è¿è¡Œç”± `setTimeout()` å’Œ `setInterval()` å®‰æ’çš„å›è°ƒã€‚
- en: Now, technically, a timer callback isn't guaranteed to run at the *exact* millisecond
    you specified. The delay you provide is the *minimum* time until the callback
    is eligible to run. When the loop enters this phase, it checks the clock. Has
    the time for any of our scheduled timers passed? If so, their callbacks are run.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä»æŠ€æœ¯ä¸Šè®²ï¼Œè®¡æ—¶å™¨å›è°ƒå¹¶ä¸ä¿è¯åœ¨æŒ‡å®šçš„**ç¡®åˆ‡**æ¯«ç§’è¿è¡Œã€‚ä½ æä¾›çš„å»¶è¿Ÿæ˜¯å›è°ƒå¯ä»¥è¿è¡Œçš„**æœ€å°**æ—¶é—´ã€‚å½“å¾ªç¯è¿›å…¥è¿™ä¸ªé˜¶æ®µæ—¶ï¼Œå®ƒä¼šæ£€æŸ¥æ—¶é’Ÿã€‚æˆ‘ä»¬å®‰æ’çš„ä»»ä½•è®¡æ—¶å™¨çš„æ—¶é—´æ˜¯å¦å·²ç»è¿‡å»ï¼Ÿå¦‚æœæ˜¯ï¼Œå®ƒä»¬çš„å›è°ƒå°†è¢«è¿è¡Œã€‚
- en: You might be wondering how Node can handle thousands of timers without constantly
    checking a giant list. Itâ€™s cleverer than that. Libuv uses a special data structure
    called a **min-heap**. A min-heap is a tree-like structure where the smallest
    element is always at the root. In this context, "smallest" means the timer that's
    set to expire next. This lets Libuv know how long it can "sleep" until the next
    timer is due in O(1) time - incredibly fast. This is a huge reason why Node's
    timers are so cheap.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½æƒ³çŸ¥é“ Node å¦‚ä½•å¤„ç†æ•°åƒä¸ªè®¡æ—¶å™¨è€Œä¸éœ€è¦ä¸æ–­æ£€æŸ¥ä¸€ä¸ªå·¨å¤§çš„åˆ—è¡¨ã€‚å®ƒæ¯”è¿™æ›´èªæ˜ã€‚Libuv ä½¿ç”¨ä¸€ç§ç‰¹æ®Šçš„æ•°æ®ç»“æ„ï¼Œç§°ä¸º **æœ€å°å †**ã€‚æœ€å°å †æ˜¯ä¸€ç§æ ‘çŠ¶ç»“æ„ï¼Œå…¶ä¸­æœ€å°çš„å…ƒç´ å§‹ç»ˆåœ¨æ ¹èŠ‚ç‚¹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œâ€œæœ€å°â€æ„å‘³ç€ä¸‹ä¸€ä¸ªå³å°†åˆ°æœŸçš„è®¡æ—¶å™¨ã€‚è¿™ä½¿å¾—
    Libuv èƒ½å¤ŸçŸ¥é“å®ƒå¯ä»¥åœ¨ O(1) æ—¶é—´å†…â€œç¡çœ â€å¤šä¹…ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªè®¡æ—¶å™¨åˆ°æœŸ - éå¸¸å¿«ã€‚è¿™æ˜¯ Node è®¡æ—¶å™¨å¦‚æ­¤ä¾¿å®œçš„ä¸€ä¸ªå·¨å¤§åŸå› ã€‚
- en: â„¹ï¸Note
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: Libuv uses a min-heap so the next-expiring timer can be discovered in O(1) time,
    but inserting or removing timers is O(log n). That makes timers efficient for
    large sets, but creating or canceling many timers still has non-zero cost.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Libuv ä½¿ç”¨æœ€å°å †ï¼Œå› æ­¤å¯ä»¥åœ¨ O(1) æ—¶é—´å†…å‘ç°ä¸‹ä¸€ä¸ªå³å°†åˆ°æœŸçš„è®¡æ—¶å™¨ï¼Œä½†æ’å…¥æˆ–åˆ é™¤è®¡æ—¶å™¨æ˜¯ O(log n)ã€‚è¿™ä½¿å¾—è®¡æ—¶å™¨åœ¨å¤§é›†åˆä¸­æ•ˆç‡å¾ˆé«˜ï¼Œä½†åˆ›å»ºæˆ–å–æ¶ˆè®¸å¤šè®¡æ—¶å™¨ä»ç„¶æœ‰éé›¶æˆæœ¬ã€‚
- en: 'Phase 2 & 3: Pending Callbacks and Internal Operations'
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¬¬äºŒé˜¶æ®µ & ç¬¬ä¸‰é˜¶æ®µï¼šæŒ‚èµ·å›è°ƒå’Œå†…éƒ¨æ“ä½œ
- en: After timers, the loop zips through a couple of internal phases you rarely interact
    with directly.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®¡æ—¶å™¨ä¹‹åï¼Œå¾ªç¯å¿«é€Ÿè·³è¿‡å‡ ä¸ªä½ å¾ˆå°‘ç›´æ¥ä¸ä¹‹äº¤äº’çš„å†…éƒ¨é˜¶æ®µã€‚
- en: '**Phase 2: Pending Callbacks -** This phase runs I/O callbacks that were deferred
    to the next loop iteration. A weird edge case, really. For instance, if a TCP
    socket throws an `EAGAIN` error while writing data, Node will queue the callback
    to be retried here. For 99% of developers, this phase is just background noise.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¬¬äºŒé˜¶æ®µï¼šæŒ‚èµ·å›è°ƒ** - è¿™ä¸ªé˜¶æ®µè¿è¡Œè¢«æ¨è¿Ÿåˆ°ä¸‹ä¸€æ¬¡å¾ªç¯è¿­ä»£çš„ I/O å›è°ƒã€‚è¿™æ˜¯ä¸€ä¸ªçœŸæ­£å¥‡æ€ªçš„è¾¹ç¼˜æƒ…å†µã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ª TCP å¥—æ¥å­—åœ¨å†™å…¥æ•°æ®æ—¶æŠ›å‡º
    `EAGAIN` é”™è¯¯ï¼ŒNode å°†å°†å›è°ƒæ’é˜Ÿä»¥åœ¨æ­¤å¤„é‡è¯•ã€‚å¯¹äº 99% çš„å¼€å‘è€…æ¥è¯´ï¼Œè¿™ä¸ªé˜¶æ®µåªæ˜¯èƒŒæ™¯å™ªéŸ³ã€‚'
- en: '**Phase 3: Idle, Prepare -** These are used internally by Libuv for housekeeping
    before it gets to the really important stuff. Not exposed to us in JavaScript
    land at all.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¬¬ä¸‰é˜¶æ®µï¼šç©ºé—²ã€å‡†å¤‡** - è¿™äº›æ˜¯ç”± Libuv åœ¨å¤„ç†çœŸæ­£é‡è¦çš„äº‹æƒ…ä¹‹å‰å†…éƒ¨ä½¿ç”¨çš„ã€‚åœ¨ JavaScript é¢†åŸŸå¯¹æˆ‘ä»¬å®Œå…¨ä¸å…¬å¼€ã€‚'
- en: 'Phase 4: The Poll Phase'
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¬¬ 4 é˜¶æ®µï¼šè½®è¯¢é˜¶æ®µ
- en: â„¹ï¸Note
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: '**Poll**(ing) generally means asking â€œis there anything ready?â€ repeatedly.
    For example, asking the kernel which I/O handles (file descriptors, sockets, etc.)
    are ready to perform I/O.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**è½®è¯¢**é€šå¸¸æ„å‘³ç€åå¤è¯¢é—®â€œæ˜¯å¦æœ‰ä»»ä½•å‡†å¤‡å°±ç»ªï¼Ÿâ€ä¾‹å¦‚ï¼Œè¯¢é—®å†…æ ¸å“ªäº› I/O å¤„ç†ç¨‹åºï¼ˆæ–‡ä»¶æè¿°ç¬¦ã€å¥—æ¥å­—ç­‰ï¼‰å‡†å¤‡å¥½æ‰§è¡Œ I/Oã€‚'
- en: Alright, pay attention, because this is the big one. The poll phase is arguably
    the most important and complex part of the whole loop. It does two main things
    -
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œè¯·æ³¨æ„ï¼Œè¿™æ˜¯æœ€é‡è¦çš„ä¸€ä¸ªã€‚è½®è¯¢é˜¶æ®µå¯ä»¥è¯´æ˜¯æ•´ä¸ªå¾ªç¯ä¸­æœ€é‡è¦å’Œæœ€å¤æ‚çš„éƒ¨åˆ†ã€‚å®ƒåšä¸¤ä»¶ä¸»è¦çš„äº‹æƒ… -
- en: '**Calculating Wait Time and Polling for I/O.** The loop figures out how long
    it can afford to wait for new I/O events. It looks at when the next timer is due
    and other factors, and then it makes a call to the OS''s notification system (like
    `epoll_wait` on Linux). This is the only "blocking" part of the event loop, but
    it''s a good kind of blocking. The process uses zero CPU, just patiently waiting
    for the kernel to tap it on the shoulder and say, "Hey, that file you were reading
    is done," or "You''ve got a new network connection."'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è®¡ç®—ç­‰å¾…æ—¶é—´å’Œè½®è¯¢ I/Oã€‚** å¾ªç¯ç¡®å®šå®ƒå¯ä»¥ä¸ºæ–°çš„ I/O äº‹ä»¶ç­‰å¾…å¤šé•¿æ—¶é—´ã€‚å®ƒæŸ¥çœ‹ä¸‹ä¸€ä¸ªè®¡æ—¶å™¨ä½•æ—¶åˆ°æœŸä»¥åŠå…¶ä»–å› ç´ ï¼Œç„¶åè°ƒç”¨æ“ä½œç³»ç»Ÿçš„é€šçŸ¥ç³»ç»Ÿï¼ˆä¾‹å¦‚
    Linux ä¸Šçš„ `epoll_wait`ï¼‰ã€‚è¿™æ˜¯äº‹ä»¶å¾ªç¯ä¸­å”¯ä¸€çš„â€œé˜»å¡â€éƒ¨åˆ†ï¼Œä½†è¿™æ˜¯è‰¯å¥½ç±»å‹çš„é˜»å¡ã€‚è¿›ç¨‹ä½¿ç”¨é›¶ CPUï¼Œåªæ˜¯è€å¿ƒåœ°ç­‰å¾…å†…æ ¸è½»æ‹å®ƒçš„è‚©è†€è¯´ï¼Œâ€œå˜¿ï¼Œä½ æ­£åœ¨è¯»å–çš„é‚£ä¸ªæ–‡ä»¶å·²ç»å®Œæˆäº†ï¼Œâ€æˆ–è€…â€œä½ æœ‰ä¸€ä¸ªæ–°çš„ç½‘ç»œè¿æ¥ã€‚â€'
- en: '**Processing the Poll Queue.** When the wait is over (either because time''s
    up or an I/O event happened), the loop processes the poll queue. This queue holds
    the callbacks for almost all of your I/O operations: a network connection being
    established, data read from a socket, or a file read (from the thread pool) finishing
    up.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¤„ç†è½®è¯¢é˜Ÿåˆ—ã€‚** å½“ç­‰å¾…ç»“æŸï¼ˆæ— è®ºæ˜¯æ—¶é—´åˆ°äº†è¿˜æ˜¯å‘ç”Ÿäº† I/O äº‹ä»¶ï¼‰ï¼Œå¾ªç¯å¤„ç†è½®è¯¢é˜Ÿåˆ—ã€‚è¿™ä¸ªé˜Ÿåˆ—æŒæœ‰å‡ ä¹æ‰€æœ‰ I/O æ“ä½œçš„å›è°ƒï¼šç½‘ç»œè¿æ¥å»ºç«‹ã€ä»å¥—æ¥å­—è¯»å–æ•°æ®ï¼Œæˆ–æ–‡ä»¶è¯»å–ï¼ˆä»çº¿ç¨‹æ± ï¼‰å®Œæˆã€‚'
- en: The behavior here is smart. If the poll queue is **not empty**, the loop will
    churn through its callbacks until the queue is drained. But if the poll queue
    **is empty**, the loop's behavior changes -
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„è¡Œä¸ºå¾ˆèªæ˜ã€‚å¦‚æœè½®è¯¢é˜Ÿåˆ—**ä¸ä¸ºç©º**ï¼Œå¾ªç¯å°†å¤„ç†å…¶å›è°ƒï¼Œç›´åˆ°é˜Ÿåˆ—æ¸…ç©ºã€‚ä½†å¦‚æœè½®è¯¢é˜Ÿåˆ—**ä¸ºç©º**ï¼Œå¾ªç¯çš„è¡Œä¸ºä¼šæ”¹å˜ -
- en: If any scripts have been scheduled with `setImmediate()`, the loop will immediately
    end the poll phase and move on to the [check phase](#phase-5-the-check-phase)
    to run them.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæœ‰ä»»ä½•è„šæœ¬ä½¿ç”¨ `setImmediate()` è¢«å®‰æ’ï¼Œå¾ªç¯å°†ç«‹å³ç»“æŸè½®è¯¢é˜¶æ®µï¼Œè¿›å…¥ [æ£€æŸ¥é˜¶æ®µ](#phase-5-the-check-phase)
    æ¥è¿è¡Œå®ƒä»¬ã€‚
- en: If there are no `setImmediate()`s waiting, the loop will just hang out here,
    waiting for new I/O events to arrive. When they do, their callbacks will be executed
    right away.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœæ²¡æœ‰ç­‰å¾…çš„ `setImmediate()`ï¼Œå¾ªç¯å°†åœ¨è¿™é‡ŒæŒ‚èµ·ï¼Œç­‰å¾…æ–°çš„ I/O äº‹ä»¶åˆ°æ¥ã€‚å½“å®ƒä»¬åˆ°æ¥æ—¶ï¼Œå®ƒä»¬çš„å›è°ƒå°†ç«‹å³æ‰§è¡Œã€‚
- en: This phase is also where a Node process can decide it's time to die. If the
    event loop enters the poll phase and sees no pending I/O, no active timers, no
    immediates, and no other handles keeping it alive, it concludes thereâ€™s no more
    work to do, and the process gracefully exits.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé˜¶æ®µä¹Ÿæ˜¯ Node è¿›ç¨‹å†³å®šä½•æ—¶æ­»äº¡çš„æ—¶å€™ã€‚å¦‚æœäº‹ä»¶å¾ªç¯è¿›å…¥è½®è¯¢é˜¶æ®µï¼Œçœ‹åˆ°æ²¡æœ‰æŒ‚èµ·çš„ I/Oã€æ²¡æœ‰æ´»è·ƒçš„è®¡æ—¶å™¨ã€æ²¡æœ‰ç«‹å³æ‰§è¡Œçš„ä»»åŠ¡ï¼Œä¹Ÿæ²¡æœ‰å…¶ä»–ä¿æŒå…¶å­˜æ´»çš„å¤„ç†ç¨‹åºï¼Œå®ƒå°±ä¼šå¾—å‡ºç»“è®ºï¼Œæ²¡æœ‰æ›´å¤šå·¥ä½œè¦åšï¼Œè¿›ç¨‹ä¼˜é›…åœ°é€€å‡ºã€‚
- en: 'Phase 5: The Check Phase'
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¬¬ 5 é˜¶æ®µï¼šæ£€æŸ¥é˜¶æ®µ
- en: 'This phase is wonderfully simple. It has one job and one job only: execute
    callbacks scheduled by `setImmediate()`. If you need to run some code immediately
    after the poll phase is done with its events, this is your tool.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé˜¶æ®µéå¸¸ç®€å•ã€‚å®ƒåªæœ‰ä¸€ä¸ªä»»åŠ¡ï¼šæ‰§è¡Œç”± `setImmediate()` å®‰æ’çš„å›è°ƒã€‚å¦‚æœä½ éœ€è¦åœ¨è½®è¯¢é˜¶æ®µå®Œæˆå…¶äº‹ä»¶åç«‹å³è¿è¡Œä¸€äº›ä»£ç ï¼Œè¿™æ˜¯ä½ çš„å·¥å…·ã€‚
- en: 'A use case: A Food Delivery App''s Order Confirmation'
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç”¨ä¾‹ï¼šé£Ÿå“é…é€åº”ç”¨çš„è®¢å•ç¡®è®¤
- en: âš ï¸Warning
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: âš ï¸è­¦å‘Š
- en: '`setImmediate()` decouples work for latency reasons but is not durable - it
    executes only while the process is alive. For critical or guaranteed background
    tasks use a persistent job queue (RabbitMQ, Redis queues, Kafka, or a database
    job table) or an external worker to ensure retries and durability. I''m using
    it here as an example to illustrate the event loop.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`setImmediate()` ç”±äºå»¶è¿ŸåŸå› è§£è€¦äº†å·¥ä½œï¼Œä½†ä¸æ˜¯æŒä¹…çš„ - å®ƒä»…åœ¨è¿›ç¨‹å­˜æ´»æ—¶æ‰§è¡Œã€‚å¯¹äºå…³é”®æˆ–ä¿è¯çš„åå°ä»»åŠ¡ï¼Œè¯·ä½¿ç”¨æŒä¹…ä½œä¸šé˜Ÿåˆ—ï¼ˆRabbitMQã€Redis
    é˜Ÿåˆ—ã€Kafka æˆ–æ•°æ®åº“ä½œä¸šè¡¨ï¼‰æˆ–å¤–éƒ¨å·¥ä½œå‘˜ä»¥ç¡®ä¿é‡è¯•å’ŒæŒä¹…æ€§ã€‚æˆ‘åœ¨è¿™é‡Œä½¿ç”¨å®ƒä½œä¸ºç¤ºä¾‹æ¥é˜è¿°äº‹ä»¶å¾ªç¯ã€‚'
- en: Imagine you are building the backend for a food delivery service like Uber Eats
    or Zomato. When a user places an order, two main things need to happen -
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä½ æ­£åœ¨æ„å»ºåƒ Uber Eats æˆ– Zomato è¿™æ ·çš„é£Ÿå“é…é€æœåŠ¡çš„åç«¯ã€‚å½“ç”¨æˆ·ä¸‹å•æ—¶ï¼Œéœ€è¦å‘ç”Ÿä¸¤ä»¶ä¸»è¦çš„äº‹æƒ… -
- en: '**Confirm the order -** Write the order details to your main database. This
    is a critical I/O operation and must be completed successfully.'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç¡®è®¤è®¢å•** - å°†è®¢å•è¯¦æƒ…å†™å…¥ä½ çš„ä¸»æ•°æ®åº“ã€‚è¿™æ˜¯ä¸€ä¸ªå…³é”®çš„I/Oæ“ä½œï¼Œå¿…é¡»æˆåŠŸå®Œæˆã€‚'
- en: '**Notify the restaurant -** Send a notification to the restaurant''s tablet
    or system. This is a separate action and should not delay the user''s confirmation.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é€šçŸ¥é¤å…** - å‘é¤å…çš„å¹³æ¿ç”µè„‘æˆ–ç³»ç»Ÿå‘é€é€šçŸ¥ã€‚è¿™æ˜¯ä¸€ä¸ªå•ç‹¬çš„æ“ä½œï¼Œä¸åº”å»¶è¿Ÿç”¨æˆ·çš„ç¡®è®¤ã€‚'
- en: You want to tell the user their order is confirmed as soon as the database write
    is complete. The restaurant notification can happen a split second later; it doesn't
    need to be part of the same database transaction.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æƒ³åœ¨æ•°æ®åº“å†™å…¥å®Œæˆåç«‹å³å‘Šè¯‰ç”¨æˆ·ä»–ä»¬çš„è®¢å•å·²ç¡®è®¤ã€‚é¤å…é€šçŸ¥å¯ä»¥åœ¨å‡ ç§’é’Ÿåå‘ç”Ÿï¼›å®ƒä¸éœ€è¦æˆä¸ºåŒä¸€æ•°æ®åº“äº‹åŠ¡çš„ä¸€éƒ¨åˆ†ã€‚
- en: How `setImmediate()` Solves This
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '`setImmediate()`å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜'
- en: You would use `setImmediate()` to decouple the restaurant notification from
    the database confirmation.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¼šä½¿ç”¨`setImmediate()`æ¥è§£è€¦é¤å…é€šçŸ¥å’Œæ•°æ®åº“ç¡®è®¤ã€‚
- en: The system receives an order and calls a function to save it to the database
    (an I/O operation). This callback will run in the **Poll phase** of the event
    loop.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ç³»ç»Ÿæ¥æ”¶ä¸€ä¸ªè®¢å•å¹¶è°ƒç”¨ä¸€ä¸ªå‡½æ•°å°†å…¶ä¿å­˜åˆ°æ•°æ®åº“ä¸­ï¼ˆä¸€ä¸ªI/Oæ“ä½œï¼‰ã€‚è¿™ä¸ªå›è°ƒå°†åœ¨äº‹ä»¶å¾ªç¯çš„**è½®è¯¢é˜¶æ®µ**è¿è¡Œã€‚
- en: Inside the callback for the database operation, once you know the order is saved
    successfully, you immediately schedule the restaurant notification using `setImmediate()`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®åº“æ“ä½œçš„å›è°ƒå†…éƒ¨ï¼Œä¸€æ—¦ä½ çŸ¥é“è®¢å•å·²æˆåŠŸä¿å­˜ï¼Œä½ ç«‹å³ä½¿ç”¨`setImmediate()`å®‰æ’é¤å…é€šçŸ¥ã€‚
- en: The event loop finishes the Poll phase and immediately moves to the **Check
    phase**, where it executes the `setImmediate()` callback, sending the notification
    to the restaurant.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹ä»¶å¾ªç¯å®Œæˆè½®è¯¢é˜¶æ®µï¼Œå¹¶ç«‹å³è¿›å…¥**æ£€æŸ¥é˜¶æ®µ**ï¼Œåœ¨é‚£é‡Œæ‰§è¡Œ`setImmediate()`å›è°ƒï¼Œå‘é¤å…å‘é€é€šçŸ¥ã€‚
- en: This ensures that the core, user-facing task (confirming the order in the database)
    is completed as fast as possible. The secondary, internal task (notifying the
    restaurant) is reliably scheduled to happen right after, without slowing down
    the primary one.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç¡®ä¿äº†æ ¸å¿ƒçš„ç”¨æˆ·ä»»åŠ¡ï¼ˆåœ¨æ•°æ®åº“ä¸­ç¡®è®¤è®¢å•ï¼‰å°½å¯èƒ½å¿«åœ°å®Œæˆã€‚æ¬¡è¦çš„å†…éƒ¨ä»»åŠ¡ï¼ˆé€šçŸ¥é¤å…ï¼‰è¢«å¯é åœ°å®‰æ’åœ¨ä¹‹åå‘ç”Ÿï¼Œè€Œä¸ä¼šå‡æ…¢ä¸»è¦ä»»åŠ¡ã€‚
- en: Here is what the simplified code logic would look like -
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€åŒ–çš„ä»£ç é€»è¾‘çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ -
- en: '[PRE3]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Phase 6: Close Callbacks**'
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**é˜¶æ®µ6ï¼šå…³é—­å›è°ƒ**'
- en: The final phase of a tick is for cleanup. It handles "close" events. For example,
    if you abruptly destroy a socket with `socket.destroy()`, the `'close'` event's
    callback will be fired off in this phase.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: èœ±è™«çš„æœ€ç»ˆé˜¶æ®µæ˜¯æ¸…ç†ã€‚å®ƒå¤„ç†â€œå…³é—­â€äº‹ä»¶ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨`socket.destroy()`çªç„¶é”€æ¯ä¸€ä¸ªå¥—æ¥å­—ï¼Œé‚£ä¹ˆåœ¨è¿™ä¸ªé˜¶æ®µå°†ä¼šè§¦å‘`'close'`äº‹ä»¶çš„å›è°ƒã€‚
- en: After this, the loop checks if there's anything left keeping it alive. If there
    is, the whole cycle starts over again, returning to the timers phase for the next
    tick. And on and on it goes.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå¾ªç¯æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä»»ä½•ä¸œè¥¿è®©å®ƒä¿æŒæ´»è·ƒã€‚å¦‚æœæœ‰ï¼Œæ•´ä¸ªå‘¨æœŸå°†é‡æ–°å¼€å§‹ï¼Œå›åˆ°ä¸‹ä¸€ä¸ªtickçš„è®¡æ—¶å™¨é˜¶æ®µã€‚å°±è¿™æ ·ä¸€ç›´è¿›è¡Œä¸‹å»ã€‚
- en: 'The Express Lane: Microtasks vs. Macrotasks'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¿«è½¦é“ï¼šå¾®ä»»åŠ¡ä¸å®ä»»åŠ¡
- en: So, we've just laid out the six-lane highway of the event loop. But it turns
    out there's another, higher-priority express lane that operates outside of this
    whole system. Understanding it is really crucial for predicting execution order.
    I welcome to the world of microtasks.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬åˆšåˆšæ¦‚è¿°äº†äº‹ä»¶å¾ªç¯çš„å…­è½¦é“é«˜é€Ÿå…¬è·¯ã€‚ä½†äº‹å®ä¸Šï¼Œè¿˜æœ‰ä¸€ä¸ªæ›´é«˜ä¼˜å…ˆçº§çš„å¿«é€Ÿè½¦é“ï¼Œå®ƒåœ¨è¿™ä¸ªç³»ç»Ÿä¹‹å¤–è¿è¡Œã€‚ç†è§£è¿™ä¸€ç‚¹å¯¹äºé¢„æµ‹æ‰§è¡Œé¡ºåºè‡³å…³é‡è¦ã€‚æ¬¢è¿æ¥åˆ°å¾®ä»»åŠ¡çš„ä¸–ç•Œã€‚
- en: What even are these?
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¿™äº›ç©¶ç«Ÿæ˜¯ä»€ä¹ˆï¼Ÿ
- en: To get this right, we need to be a little more formal with our terms.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ­£ç¡®ç†è§£ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æˆ‘ä»¬çš„æœ¯è¯­æ›´åŠ æ­£å¼ä¸€äº›ã€‚
- en: '**Macrotask (or Task) -** This is any callback that gets placed into one of
    the queues for the six event loop phases. A timer callback? That''s a macrotask.
    An I/O callback? Macrotask. An immediate callback? You guessed it, macrotask.
    The event loop processes macrotasks from *one* phase''s queue per tick.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å®ä»»åŠ¡ï¼ˆæˆ–ä»»åŠ¡ï¼‰** - è¿™æ˜¯æŒ‡è¢«æ”¾å…¥å…­ä¸ªäº‹ä»¶å¾ªç¯é˜¶æ®µä¹‹ä¸€çš„é˜Ÿåˆ—ä¸­çš„ä»»ä½•å›è°ƒã€‚å®šæ—¶å™¨å›è°ƒï¼Ÿé‚£æ˜¯å®ä»»åŠ¡ã€‚I/Oå›è°ƒï¼Ÿå®ä»»åŠ¡ã€‚ç«‹å³å›è°ƒï¼Ÿæ²¡é”™ï¼Œå®ä»»åŠ¡ã€‚äº‹ä»¶å¾ªç¯åœ¨æ¯ä¸ªtickä¸­ä»æ¯ä¸ªé˜¶æ®µçš„é˜Ÿåˆ—ä¸­å¤„ç†å®ä»»åŠ¡ã€‚'
- en: '**Microtask -** This is a callback that gets placed in a special, high-priority
    queue that lives outside the main loop phases. In Node, there are two of these:
    the `nextTick` queue and the Promise Jobs queue.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¾®ä»»åŠ¡** - è¿™æ˜¯æŒ‡è¢«æ”¾å…¥ä¸€ä¸ªç‰¹æ®Šçš„é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—ä¸­çš„å›è°ƒï¼Œè¯¥é˜Ÿåˆ—å­˜åœ¨äºä¸»å¾ªç¯é˜¶æ®µä¹‹å¤–ã€‚åœ¨Nodeä¸­ï¼Œæœ‰ä¸¤ä¸ªè¿™æ ·çš„é˜Ÿåˆ—ï¼š`nextTick`é˜Ÿåˆ—å’ŒPromise
    Jobsé˜Ÿåˆ—ã€‚'
- en: 'Here is the Golden Rule of execution order, the one you should tattoo on your
    brain: After **any single macrotask** from any phase is executed, the runtime
    will immediately execute **every single task** currently in the microtask queues
    before it even thinks about moving on to the next macrotask.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¿™é‡Œæ˜¯æ‰§è¡Œé¡ºåºçš„é‡‘ç§‘ç‰å¾‹ï¼Œä½ åº”è¯¥å°†å…¶çº¹åœ¨è„‘ä¸­ï¼šåœ¨ **ä»»ä½•å•ä¸€é˜¶æ®µçš„å®ä»»åŠ¡** æ‰§è¡Œå®Œæ¯•åï¼Œè¿è¡Œæ—¶ä¼šç«‹å³æ‰§è¡Œå¾®ä»»åŠ¡é˜Ÿåˆ—ä¸­å½“å‰çš„æ‰€æœ‰ä»»åŠ¡ï¼Œç„¶åå†è€ƒè™‘ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªå®ä»»åŠ¡ã€‚ '
- en: This is huge. It means microtasks can cut in line and execute in between macrotasks
    from the very same phase.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éå¸¸é‡è¦ã€‚è¿™æ„å‘³ç€å¾®ä»»åŠ¡å¯ä»¥åœ¨å®ä»»åŠ¡ä¹‹é—´æ’é˜Ÿå¹¶æ‰§è¡Œï¼Œç”šè‡³æ¥è‡ªåŒä¸€é˜¶æ®µçš„å®ä»»åŠ¡ã€‚
- en: 'The `process.nextTick()` Queue: The Highest Priority'
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`process.nextTick()` é˜Ÿåˆ—ï¼šæœ€é«˜ä¼˜å…ˆçº§'
- en: The callbacks you schedule with `process.nextTick()` live in the VIP lounge
    of microtask queues. The name is a bit of a lie; it doesn't run on the "next tick."
    It runs *immediately* after the current operations on the call stack finishes,
    before the event loop is even allowed to proceed to the next phase or the next
    macrotask. It's the most aggressive "cut in line" you can do.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä½¿ç”¨ `process.nextTick()` å®‰æ’çš„å›è°ƒç”Ÿæ´»åœ¨å¾®ä»»åŠ¡é˜Ÿåˆ—çš„VIPä¼‘æ¯å®¤ã€‚è¿™ä¸ªåå­—æœ‰ç‚¹è¯¯å¯¼ï¼›å®ƒä¸æ˜¯åœ¨â€œä¸‹ä¸€ä¸ªtickâ€ä¸Šè¿è¡Œã€‚å®ƒåœ¨è°ƒç”¨æ ˆä¸Šçš„å½“å‰æ“ä½œå®Œæˆåç«‹å³è¿è¡Œï¼Œç”šè‡³åœ¨äº‹ä»¶å¾ªç¯è¢«å…è®¸è¿›å…¥ä¸‹ä¸€ä¸ªé˜¶æ®µæˆ–ä¸‹ä¸€ä¸ªå®ä»»åŠ¡ä¹‹å‰ã€‚è¿™æ˜¯æœ€æ¿€è¿›çš„â€œæ’é˜Ÿâ€æ–¹å¼ã€‚
- en: This gives it incredible power, but also makes it incredibly dangerous. Because
    the `nextTick` queue is processed in its entirety before the loop can move on,
    a recursive `process.nextTick()` call can starve the event loop, preventing any
    I/O or timers from ever running.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™èµ‹äºˆå®ƒå·¨å¤§çš„åŠ›é‡ï¼Œä½†ä¹Ÿä½¿å…¶å˜å¾—æå…¶å±é™©ã€‚å› ä¸º `nextTick` é˜Ÿåˆ—åœ¨å¾ªç¯å¯ä»¥ç»§ç»­ä¹‹å‰ä¼šå…¨éƒ¨å¤„ç†ï¼Œé€’å½’çš„ `process.nextTick()`
    è°ƒç”¨å¯ä»¥é¥¿æ­»äº‹ä»¶å¾ªç¯ï¼Œé˜²æ­¢ä»»ä½• I/O æˆ–å®šæ—¶å™¨è¿è¡Œã€‚
- en: I once spent half a day debugging a server that was completely unresponsive
    to network requests but wasn't crashing. The culprit? A library was accidentally
    calling `process.nextTick` recursively under a specific error condition. The loop
    was spinning forever, just processing microtasks.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ›¾ç»èŠ±äº†ä¸€æ•´å¤©çš„æ—¶é—´è°ƒè¯•ä¸€ä¸ªå®Œå…¨å¯¹ç½‘ç»œè¯·æ±‚æ— å“åº”ä½†å¹¶æœªå´©æºƒçš„æœåŠ¡å™¨ã€‚ç½ªé­ç¥¸é¦–ï¼Ÿä¸€ä¸ªåº“åœ¨ç‰¹å®šçš„é”™è¯¯æ¡ä»¶ä¸‹æ„å¤–åœ°é€’å½’è°ƒç”¨ `process.nextTick`ã€‚å¾ªç¯æ°¸è¿œåœ¨å¤„ç†å¾®ä»»åŠ¡ã€‚
- en: '[PRE4]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Run that code. It will just print "Starvation call..." forever. The `setTimeout`
    callback will never get a chance because the event loop is perpetually stuck,
    unable to get to the timers phase.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œé‚£æ®µä»£ç ã€‚å®ƒå°†æ°¸è¿œæ‰“å°â€œStarvation call...â€ã€‚`setTimeout` å›è°ƒæ°¸è¿œä¸ä¼šå¾—åˆ°æœºä¼šï¼Œå› ä¸ºäº‹ä»¶å¾ªç¯æ°¸è¿œå¡ä½ï¼Œæ— æ³•åˆ°è¾¾å®šæ—¶å™¨é˜¶æ®µã€‚
- en: So, Why Does This Happen?
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆä¼šå‘ç”Ÿå‘¢ï¼Ÿ
- en: Let's walk through the execution of that code to see how it traps the event
    loop in a never-ending cycle.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡æ‰§è¡Œé‚£æ®µä»£ç æ¥äº†è§£å®ƒæ˜¯å¦‚ä½•å°†äº‹ä»¶å¾ªç¯å›°åœ¨æ°¸æ— æ­¢å¢ƒçš„å¾ªç¯ä¸­çš„ã€‚
- en: '`let count = 0;` We start by setting up a simple counter. This is just to prove
    that our function is, in fact, running over and over again.'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`let count = 0;` æˆ‘ä»¬é¦–å…ˆè®¾ç½®ä¸€ä¸ªç®€å•çš„è®¡æ•°å™¨ã€‚è¿™åªæ˜¯ä¸ºäº†è¯æ˜æˆ‘ä»¬çš„å‡½æ•°ç¡®å®åœ¨åå¤è¿è¡Œã€‚'
- en: '`function starveTheLoop() { ... }` This is the code in question. We define
    the function, but nothing happens yet. It''s just sitting in memory, waiting to
    be called.'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`function starveTheLoop() { ... }` è¿™æ˜¯æˆ‘ä»¬è¦è®¨è®ºçš„ä»£ç ã€‚æˆ‘ä»¬å®šä¹‰äº†å‡½æ•°ï¼Œä½†è¿˜æ²¡æœ‰å‘ç”Ÿä»»ä½•äº‹æƒ…ã€‚å®ƒåªæ˜¯é™é™åœ°ååœ¨å†…å­˜ä¸­ï¼Œç­‰å¾…è¢«è°ƒç”¨ã€‚'
- en: '`setTimeout(() => { ... }, 1000);` We schedule a timer. Node.js sees this and
    says, "Okay, cool. In about one second, I''ll put this callback into the **timers
    queue** (a macrotask queue) to be executed." It then moves on immediately. It
    doesn''t wait for the second to pass.'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`setTimeout(() => { ... }, 1000);` æˆ‘ä»¬å®‰æ’äº†ä¸€ä¸ªå®šæ—¶å™¨ã€‚Node.js çœ‹åˆ°è¿™ä¸ªå¹¶è¯´ï¼šâ€œå¥½å§ï¼Œé…·ã€‚å¤§çº¦ä¸€ç§’åï¼Œæˆ‘ä¼šæŠŠè¿™ä¸ªå›è°ƒæ”¾å…¥
    **å®šæ—¶å™¨é˜Ÿåˆ—**ï¼ˆä¸€ä¸ªå®ä»»åŠ¡é˜Ÿåˆ—ï¼‰ä»¥æ‰§è¡Œã€‚â€ç„¶åå®ƒç«‹å³ç»§ç»­ã€‚å®ƒä¸ä¼šç­‰å¾…ç¬¬äºŒç§’è¿‡å»ã€‚'
- en: '`console.log("Starting the starvation...");` This is the first piece of code
    that actually runs. It''s a synchronous operation. It gets pushed onto the call
    stack, prints its message to the console, and pops off. Easy.'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`console.log("Starting the starvation...");` è¿™æ˜¯å®é™…è¿è¡Œçš„ç¬¬ä¸€ä¸ªä»£ç ç‰‡æ®µã€‚è¿™æ˜¯ä¸€ä¸ªåŒæ­¥æ“ä½œã€‚å®ƒè¢«æ¨å…¥è°ƒç”¨æ ˆï¼Œå°†å…¶æ¶ˆæ¯æ‰“å°åˆ°æ§åˆ¶å°ï¼Œç„¶åå¼¹å‡ºã€‚å¾ˆç®€å•ã€‚'
- en: '`starveTheLoop();` This is where the trap is sprung. We make the first call
    to our function. The following happens -'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`starveTheLoop();` è¿™å°±æ˜¯é™·é˜±è¢«è§¦å‘çš„ä½ç½®ã€‚æˆ‘ä»¬ç¬¬ä¸€æ¬¡è°ƒç”¨æˆ‘ä»¬çš„å‡½æ•°ã€‚æ¥ä¸‹æ¥å‘ç”Ÿçš„æƒ…å†µæ˜¯ -'
- en: '`starveTheLoop` is pushed onto the call stack.'
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`starveTheLoop` è¢«æ¨å…¥è°ƒç”¨æ ˆã€‚'
- en: 'It prints `Starvation call: ${++count}`. The console now shows "Starvation
    call: 1".'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'å®ƒæ‰“å° `Starvation call: ${++count}`ã€‚ç°åœ¨æ§åˆ¶å°æ˜¾ç¤ºâ€œStarvation call: 1â€ã€‚'
- en: 'Now for the critical part: it calls **`process.nextTick(starveTheLoop)`**.
    This doesn''t call the function right away. Instead, it places the `starveTheLoop`
    function into the high-priority `nextTick` queue.'
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯å…³é”®éƒ¨åˆ†ï¼šå®ƒè°ƒç”¨ **`process.nextTick(starveTheLoop)`**ã€‚è¿™å¹¶ä¸ä¼šç«‹å³è°ƒç”¨å‡½æ•°ã€‚ç›¸åï¼Œå®ƒå°† `starveTheLoop`
    å‡½æ•°æ”¾å…¥é«˜ä¼˜å…ˆçº§çš„ `nextTick` é˜Ÿåˆ—ä¸­ã€‚
- en: The first `starveTheLoop` call finishes and is popped off the call stack.
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ¬¡ `starveTheLoop` è°ƒç”¨å®Œæˆå¹¶è¢«å¼¹å‡ºè°ƒç”¨æ ˆã€‚
- en: 'The main script has now finished executing, and the call stack is empty. The
    event loop is ready to take over. Its job is to check the queues for pending tasks.
    It''s supposed to work through its phases: check timers, check I/O, etc. **BUT**,
    before it can move to *any* phase, it has a strict rule: **"I must process the
    entire `process.nextTick()` queue until it is empty."**'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸»è„šæœ¬ç°åœ¨å·²æ‰§è¡Œå®Œæ¯•ï¼Œè°ƒç”¨æ ˆä¸ºç©ºã€‚äº‹ä»¶å¾ªç¯å‡†å¤‡æ¥ç®¡ã€‚å®ƒçš„ä»»åŠ¡æ˜¯æ£€æŸ¥å¾…å¤„ç†ä»»åŠ¡çš„é˜Ÿåˆ—ã€‚å®ƒåº”è¯¥æŒ‰é˜¶æ®µå·¥ä½œï¼šæ£€æŸ¥è®¡æ—¶å™¨ï¼Œæ£€æŸ¥ I/O ç­‰ã€‚**ä½†æ˜¯**ï¼Œåœ¨å®ƒèƒ½å¤Ÿç§»åŠ¨åˆ°
    *ä»»ä½•* é˜¶æ®µä¹‹å‰ï¼Œå®ƒæœ‰ä¸€ä¸ªä¸¥æ ¼çš„è§„åˆ™ï¼š**"æˆ‘å¿…é¡»å¤„ç†æ•´ä¸ª `process.nextTick()` é˜Ÿåˆ—ï¼Œç›´åˆ°å®ƒä¸ºç©ºã€‚"**
- en: The Unwinnable Cycle Begins
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ— è§£å¾ªç¯å¼€å§‹
- en: The event loop looks at the `nextTick` queue and sees our `starveTheLoop` function
    waiting there.
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: äº‹ä»¶å¾ªç¯æŸ¥çœ‹ `nextTick` é˜Ÿåˆ—ï¼Œçœ‹åˆ°æˆ‘ä»¬çš„ `starveTheLoop` å‡½æ•°åœ¨é‚£é‡Œç­‰å¾…ã€‚
- en: 'It pulls it out and executes it (this is call #2).'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'å®ƒå°†å…¶æ‹‰å‡ºå¹¶æ‰§è¡Œå®ƒï¼ˆè¿™æ˜¯ç¬¬ #2 æ¬¡è°ƒç”¨ï¼‰ã€‚'
- en: 'The function prints "Starvation call: 2".'
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡½æ•°æ‰“å° "é¥¥é¥¿è°ƒç”¨ï¼š2"ã€‚
- en: And... it schedules *another* `starveTheLoop` callback in the `nextTick` queue.
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç„¶å...å®ƒåœ¨ `nextTick` é˜Ÿåˆ—ä¸­å®‰æ’äº† *å¦ä¸€ä¸ª* `starveTheLoop` å›è°ƒã€‚
- en: This second call finishes. The event loop checks the `nextTick` queue again.
    Is it empty? **Nope!** There's a new task waiting.
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¬¬äºŒæ¬¡è°ƒç”¨å®Œæˆã€‚äº‹ä»¶å¾ªç¯å†æ¬¡æ£€æŸ¥ `nextTick` é˜Ÿåˆ—ã€‚å®ƒæ˜¯ç©ºçš„å—ï¼Ÿ**ä¸æ˜¯ï¼** æœ‰ä¸€ä¸ªæ–°çš„ä»»åŠ¡åœ¨ç­‰å¾…ã€‚
- en: 'So, it runs `starveTheLoop` a third time, which prints "Starvation call: 3"
    and puts a *fourth* one right back in the queue.'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå®ƒç¬¬ä¸‰æ¬¡è¿è¡Œ `starveTheLoop`ï¼Œæ‰“å° "é¥¥é¥¿è°ƒç”¨ï¼š3" å¹¶å°†ä¸€ä¸ª *ç¬¬å››ä¸ª* ä½œä¸šæ”¾å›é˜Ÿåˆ—ä¸­ã€‚
- en: The event loop is completely stuck. It can never finish processing the `nextTick`
    queue because every time it processes one item, that item puts another one right
    back in. The poor `setTimeout` callback is sitting in the timers queue, waiting
    patiently for its turn, but the event loop never gets past the `nextTick` phase
    to even look at the timers. It has been effectively **starved**.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹ä»¶å¾ªç¯å®Œå…¨å¡ä½äº†ã€‚å®ƒæ°¸è¿œæ— æ³•å®Œæˆå¤„ç† `nextTick` é˜Ÿåˆ—ï¼Œå› ä¸ºæ¯æ¬¡å®ƒå¤„ç†ä¸€ä¸ªé¡¹ç›®ï¼Œè¯¥é¡¹ç›®å°±ä¼šå°†å¦ä¸€ä¸ªé¡¹ç›®æ”¾å›é˜Ÿåˆ—ä¸­ã€‚å¯æ€œçš„ `setTimeout`
    å›è°ƒååœ¨è®¡æ—¶å™¨é˜Ÿåˆ—ä¸­ï¼Œè€å¿ƒåœ°ç­‰å¾…å®ƒçš„è½®æ¬¡ï¼Œä½†äº‹ä»¶å¾ªç¯æ°¸è¿œä¸ä¼šé€šè¿‡ `nextTick` é˜¶æ®µå»æŸ¥çœ‹è®¡æ—¶å™¨ã€‚å®ƒå·²ç»è¢«æœ‰æ•ˆåœ° **é¥¿æ­»**ã€‚
- en: The Promise Jobs Queue
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Promise ä½œä¸šé˜Ÿåˆ—
- en: The second microtask queue is for Promises. Whenever a Promise resolves or rejects,
    any callbacks attached via `.then()`, `.catch()`, or `.finally()` are scheduled
    as microtasks in this queue. And yes, our beloved `async/await` is just syntactic
    sugar that uses this very same mechanism.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªå¾®ä»»åŠ¡é˜Ÿåˆ—ç”¨äº Promiseã€‚æ¯å½“ Promise è§£å†³æˆ–æ‹’ç»æ—¶ï¼Œé€šè¿‡ `.then()`ã€`.catch()` æˆ– `.finally()`
    æ·»åŠ çš„ä»»ä½•å›è°ƒéƒ½ä¼šä½œä¸ºå¾®ä»»åŠ¡åœ¨æ­¤é˜Ÿåˆ—ä¸­å®‰æ’ã€‚æ˜¯çš„ï¼Œæˆ‘ä»¬å–œçˆ±çš„ `async/await` åªä¸è¿‡æ˜¯ä¸€ç§ä½¿ç”¨è¿™ä¸ªæœºåˆ¶çš„åŒä¹‰è¯çš„è¯­æ³•ç³–ã€‚
- en: 'This queue has a slightly lower priority than `process.nextTick()`. The order
    of operations is always:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤é˜Ÿåˆ—çš„ä¼˜å…ˆçº§ç•¥ä½äº `process.nextTick()`ã€‚æ“ä½œé¡ºåºå§‹ç»ˆæ˜¯ï¼š
- en: Execute the current macrotask.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰§è¡Œå½“å‰å®ä»»åŠ¡ã€‚
- en: Drain the *entire* `nextTick` queue.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¸…ç©ºæ•´ä¸ª `nextTick` é˜Ÿåˆ—ã€‚
- en: Drain the *entire* Promise Jobs queue.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¸…ç©ºæ•´ä¸ª Promise ä½œä¸šé˜Ÿåˆ—ã€‚
- en: Okay, *now* we can proceed to the next macrotask.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œ**ç°åœ¨**æˆ‘ä»¬å¯ä»¥ç»§ç»­åˆ°ä¸‹ä¸€ä¸ªå®ä»»åŠ¡ã€‚
- en: When you `await` something, you're effectively splitting your `async` function
    in two. Everything *before* the `await` runs synchronously. The rest of the function
    gets wrapped in a `.then()` and scheduled as a microtask on the Promise Jobs queue,
    to be executed after the awaited promise settles.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½  `await` ä»€ä¹ˆæ—¶ï¼Œä½ å®é™…ä¸Šæ˜¯åœ¨å°†ä½ çš„ `async` å‡½æ•°åˆ†æˆä¸¤éƒ¨åˆ†ã€‚`await` ä¹‹å‰çš„ä¸€åˆ‡éƒ½æ˜¯åŒæ­¥è¿è¡Œçš„ã€‚å‡½æ•°çš„å…¶ä½™éƒ¨åˆ†è¢«åŒ…è£…åœ¨ `.then()`
    ä¸­ï¼Œå¹¶ä½œä¸ºå¾®ä»»åŠ¡åœ¨æ­¤é˜Ÿåˆ—ä¸­å®‰æ’ï¼Œä»¥ä¾¿åœ¨ç­‰å¾…çš„æ‰¿è¯ºè§£å†³åæ‰§è¡Œã€‚
- en: A Complex Execution Order Analysis
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¤æ‚æ‰§è¡Œé¡ºåºåˆ†æ
- en: Let's put this all together with a scary-looking code snippet that will test
    our new mental model.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªçœ‹èµ·æ¥ä»¤äººææƒ§çš„ä»£ç ç‰‡æ®µå°†è¿™äº›å†…å®¹ç»¼åˆèµ·æ¥ï¼Œä»¥æµ‹è¯•æˆ‘ä»¬æ–°çš„æ€ç»´æ¨¡å‹ã€‚
- en: '[PRE5]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output here is always, deterministically: `1, 9, 4, 3, 2, 5, 7, 8, 6`.
    Let''s walk through why, step by step:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤„çš„è¾“å‡ºæ€»æ˜¯ï¼Œç¡®å®šæ€§åœ°ï¼š`1, 9, 4, 3, 2, 5, 7, 8, 6`ã€‚è®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥åœ°åˆ†æåŸå› ï¼š
- en: '`''1\. Start''` and `''9\. End''` are logged synchronously. All the async stuff
    is scheduled.'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`''1. å¼€å§‹''` å’Œ `''9. ç»“æŸ''` æ˜¯åŒæ­¥è®°å½•çš„ã€‚æ‰€æœ‰å¼‚æ­¥å†…å®¹éƒ½è¢«å®‰æ’ã€‚'
- en: 'The main script ends. The call stack is empty. **Golden Rule time: drain the
    microtask queues!**'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸»è„šæœ¬ç»“æŸã€‚è°ƒç”¨æ ˆä¸ºç©ºã€‚**é»„é‡‘æ³•åˆ™æ—¶é—´ï¼šæ¸…ç©ºå¾®ä»»åŠ¡é˜Ÿåˆ—ï¼**
- en: The `nextTick` queue always goes first. We log `'4\. nextTick'`.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`nextTick` é˜Ÿåˆ—æ€»æ˜¯é¦–å…ˆæ‰§è¡Œã€‚æˆ‘ä»¬è®°å½• `''4. nextTick''`ã€‚'
- en: The Promise Jobs queue is next. We log `'3\. Promise'`.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥æ˜¯ Promise ä½œä¸šé˜Ÿåˆ—ã€‚æˆ‘ä»¬è®°å½• `'3. Promise'`ã€‚
- en: Microtask queues are now empty. The event loop can finally begin its first tick.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¾®ä»»åŠ¡é˜Ÿåˆ—ç°åœ¨ä¸ºç©ºã€‚äº‹ä»¶å¾ªç¯ç»ˆäºå¯ä»¥å¼€å§‹å®ƒçš„ç¬¬ä¸€æ¬¡æ»´ç­”ã€‚
- en: '**Phase 1: Timers.** Our `setTimeout(..., 0)` is ready. The macrotask runs,
    and we log `''2\. Timeout''`.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é˜¶æ®µ 1ï¼šè®¡æ—¶å™¨ã€‚** æˆ‘ä»¬çš„ `setTimeout(..., 0)` å·²å‡†å¤‡å¥½ã€‚å®ä»»åŠ¡è¿è¡Œï¼Œæˆ‘ä»¬è®°å½• `''2. Timeout''`ã€‚'
- en: The loop zips through the next few phases.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¾ªç¯å¿«é€Ÿé€šè¿‡æ¥ä¸‹æ¥çš„å‡ ä¸ªé˜¶æ®µã€‚
- en: '**Phase 4: Poll.** The loop waits for I/O. Eventually, the `fs.readFile` finishes.
    Its callback is now a macrotask in the poll queue, ready to go.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é˜¶æ®µ4ï¼šè½®è¯¢**ã€‚å¾ªç¯ç­‰å¾…I/Oã€‚æœ€ç»ˆï¼Œ`fs.readFile`å®Œæˆã€‚å®ƒçš„å›è°ƒç°åœ¨åœ¨è½®è¯¢é˜Ÿåˆ—ä¸­ä½œä¸ºä¸€ä¸ªå®ä»»åŠ¡ï¼Œå‡†å¤‡å°±ç»ªã€‚'
- en: The macrotask is executed. We log `'5\. I/O Callback'`. Inside this function,
    a new immediate, nextTick, and promise are scheduled.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ä»»åŠ¡è¢«æ‰§è¡Œã€‚æˆ‘ä»¬è®°å½•`'5\. I/O Callback'`ã€‚åœ¨è¿™ä¸ªå‡½æ•°å†…éƒ¨ï¼Œå®‰æ’äº†ä¸€ä¸ªæ–°çš„ç«‹å³æ‰§è¡Œã€nextTickå’Œpromiseã€‚
- en: The I/O macrotask finishes. What happens now? **Golden Rule time again! We must
    drain microtasks before moving on.**
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: I/Oå®ä»»åŠ¡å®Œæˆã€‚æ¥ä¸‹æ¥ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ**é»„é‡‘æ³•åˆ™å†æ¬¡é€‚ç”¨ï¼æˆ‘ä»¬å¿…é¡»åœ¨ç»§ç»­ä¹‹å‰æ¸…ç©ºå¾®ä»»åŠ¡**ã€‚
- en: Check the `nextTick` queue. We find one and log `'7\. nextTick from I/O'`.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥`nextTick`é˜Ÿåˆ—ã€‚æˆ‘ä»¬æ‰¾åˆ°ä¸€ä¸ªå¹¶è®°å½•`'7\. nextTick from I/O'`ã€‚
- en: Check the Promise Jobs queue. We find one and log `'8\. Promise from I/O'`.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥Promiseä½œä¸šé˜Ÿåˆ—ã€‚æˆ‘ä»¬æ‰¾åˆ°ä¸€ä¸ªå¹¶è®°å½•`'8\. Promise from I/O'`ã€‚
- en: Microtask queues are empty again. The loop can now proceed from where it left
    off in the poll phase.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¾®ä»»åŠ¡é˜Ÿåˆ—å†æ¬¡ä¸ºç©ºã€‚å¾ªç¯ç°åœ¨å¯ä»¥ä»è½®è¯¢é˜¶æ®µç¦»å¼€çš„åœ°æ–¹ç»§ç»­è¿›è¡Œã€‚
- en: '**Phase 5: Check.** The loop sees the `setImmediate` we scheduled. The macrotask
    runs, and we log `''6\. Immediate from I/O''`.'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é˜¶æ®µ5ï¼šæ£€æŸ¥**ã€‚å¾ªç¯çœ‹åˆ°äº†æˆ‘ä»¬å®‰æ’çš„`setImmediate`ã€‚å®ä»»åŠ¡è¿è¡Œï¼Œæˆ‘ä»¬è®°å½•`''6\. Immediate from I/O''`ã€‚'
- en: The loop finishes its tick, finds nothing else to do, and the process exits.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¾ªç¯å®Œæˆå…¶tickï¼Œæ²¡æœ‰å…¶ä»–äº‹æƒ…å¯åšï¼Œè¿›ç¨‹é€€å‡ºã€‚
- en: See? Not magic. Just rules.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹è§äº†å—ï¼Ÿè¿™ä¸æ˜¯é­”æ³•ã€‚åªæ˜¯è§„åˆ™ã€‚
- en: '3Ps: Performance, Patterns, and Pitfalls'
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3Psï¼šæ€§èƒ½ã€æ¨¡å¼å’Œé™·é˜±
- en: This isn't just an academic exercise. Really understanding the event loop's
    guts directly affects how you write good code and, more importantly, how you debug
    the bad code.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ä»…ä»…æ˜¯ä¸€ä¸ªå­¦æœ¯ç»ƒä¹ ã€‚çœŸæ­£ç†è§£äº‹ä»¶å¾ªç¯çš„å†…éƒ¨ç»“æ„ç›´æ¥å½±å“åˆ°ä½ ç¼–å†™å¥½ä»£ç çš„æ–¹å¼ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå¦‚ä½•è°ƒè¯•åä»£ç ã€‚
- en: Obvious and Subtle Blockers
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ˜æ˜¾å’Œå¾®å¦™çš„é˜»å¡å™¨
- en: 'We''ve already beaten the obvious blockers to death: synchronous APIs like
    `fs.readFileSync` and long, CPU-bound loops. But I''ve seen even senior developers
    get tripped up by more subtle blockers that can poison an application''s performance.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»æŠŠæ˜æ˜¾çš„é˜»å¡å™¨æ‰“å¾—ä½“æ— å®Œè‚¤ï¼šåŒæ­¥APIå¦‚`fs.readFileSync`å’Œé•¿ã€CPUå¯†é›†å‹å¾ªç¯ã€‚ä½†æˆ‘ç”šè‡³çœ‹åˆ°æœ‰ç»éªŒä¸°å¯Œçš„å¼€å‘è€…è¢«æ›´å¾®å¦™çš„é˜»å¡å™¨ç»Šå€’ï¼Œè¿™äº›é˜»å¡å™¨å¯èƒ½ä¼šæ¯’å®³åº”ç”¨ç¨‹åºçš„æ€§èƒ½ã€‚
- en: '**Large JSON Operations**. Here''s a sneaky one. `JSON.parse()` and `JSON.stringify()`
    are 100% synchronous, blocking operations. If you''re handling an API request
    with a massive JSON payload (think tens or hundreds of megabytes), the time it
    takes to parse that can be huge - easily tens or hundreds of milliseconds where
    your loop is completely frozen. If you find yourself in this situation, look into
    streaming JSON parsers like `stream-json`.'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¤§å‹JSONæ“ä½œ**ã€‚è¿™æ˜¯ä¸€ä¸ªç‹¡çŒ¾çš„ä¾‹å­ã€‚`JSON.parse()`å’Œ`JSON.stringify()`æ˜¯100%åŒæ­¥ã€é˜»å¡çš„æ“ä½œã€‚å¦‚æœä½ æ­£åœ¨å¤„ç†ä¸€ä¸ªå¸¦æœ‰å¤§é‡JSONæœ‰æ•ˆè´Ÿè½½çš„APIè¯·æ±‚ï¼ˆæƒ³æƒ³åæˆ–æ•°ç™¾å…†å­—èŠ‚ï¼‰ï¼Œè§£ææ‰€éœ€çš„æ—¶é—´å¯èƒ½éå¸¸é•¿â€”â€”ä½ çš„å¾ªç¯å®Œå…¨å†»ç»“æ—¶ï¼Œå¯èƒ½éœ€è¦æ•°åæˆ–æ•°ç™¾æ¯«ç§’ã€‚å¦‚æœä½ å‘ç°è‡ªå·±å¤„äºè¿™ç§æƒ…å†µï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ç±»ä¼¼`stream-json`çš„æµå¼JSONè§£æå™¨ã€‚'
- en: '**Complex Regular Expressions**. A poorly written regex is another ticking
    time bomb. There''s a nasty phenomenon called "Catastrophic Backtracking" that
    can cause a regex engine to take an exponentially long time to process certain
    strings. A single malicious user input can trigger this, causing a regex match
    to block the CPU for seconds or even minutes. This is a classic Denial of Service
    (DoS) vector. Always, *always* test your regex against "evil" strings and consider
    using libraries that offer protection.'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¤æ‚æ­£åˆ™è¡¨è¾¾å¼**ã€‚ç¼–å†™ä¸è‰¯çš„æ­£åˆ™è¡¨è¾¾å¼å°±åƒä¸€é¢—å®šæ—¶ç‚¸å¼¹ã€‚å­˜åœ¨ä¸€ç§è¢«ç§°ä¸ºâ€œç¾éš¾æ€§å›æº¯â€çš„è®¨åŒç°è±¡ï¼Œå®ƒå¯èƒ½å¯¼è‡´æ­£åˆ™è¡¨è¾¾å¼å¼•æ“å¤„ç†æŸäº›å­—ç¬¦ä¸²æ—¶èŠ±è´¹æŒ‡æ•°çº§çš„æ—¶é—´ã€‚å•ä¸ªæ¶æ„ç”¨æˆ·è¾“å…¥å°±èƒ½è§¦å‘è¿™ç§æƒ…å†µï¼Œå¯¼è‡´æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…é˜»å¡CPUæ•°ç§’ç”šè‡³æ•°åˆ†é’Ÿã€‚è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰å‘é‡ã€‚å§‹ç»ˆï¼Œ**å§‹ç»ˆ**æµ‹è¯•ä½ çš„æ­£åˆ™è¡¨è¾¾å¼å¯¹â€œé‚ªæ¶â€å­—ç¬¦ä¸²ï¼Œå¹¶è€ƒè™‘ä½¿ç”¨æä¾›ä¿æŠ¤çš„åº“ã€‚'
- en: The Libuv Thread Pool Revisited
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å†æ¬¡æ¢è®¨Libuvçº¿ç¨‹æ± 
- en: Remember that Libuv thread pool? Don't worry if you don't, our next chapter
    is going to be a deep dive into Libuv itself! It's crucial to remember it's a
    global, shared resource, and by default, it only has four threads. While functions
    like `fs.readFile` and `crypto.pbkdf2` *feel* asynchronous from your JavaScript's
    perspective, they're all waiting in line for a very small number of actual threads.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½é‚£ä¸ªLibuvçº¿ç¨‹æ± å—ï¼Ÿå¦‚æœä½ ä¸è®°å¾—ï¼Œæˆ‘ä»¬çš„ä¸‹ä¸€ç« å°†æ·±å…¥æ¢è®¨Libuvæœ¬èº«ï¼é‡è¦çš„æ˜¯è¦è®°ä½å®ƒæ˜¯ä¸€ä¸ªå…¨å±€ã€å…±äº«çš„èµ„æºï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒåªæœ‰å››ä¸ªçº¿ç¨‹ã€‚è™½ç„¶ä»JavaScriptçš„è§’åº¦æ¥çœ‹ï¼Œåƒ`fs.readFile`å’Œ`crypto.pbkdf2`è¿™æ ·çš„å‡½æ•°*æ„Ÿè§‰*æ˜¯å¼‚æ­¥çš„ï¼Œä½†å®ƒä»¬éƒ½åœ¨ç­‰å¾…éå¸¸å°‘çš„å®é™…çº¿ç¨‹ã€‚
- en: This can create some surprising bottlenecks. Imagine a server that gets a request
    and needs to both read a file from a slow network drive (`fs.readFile`) and verify
    a password (`crypto.pbkdf2`). Now, imagine five of these requests hit at the exact
    same time.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½ä¼šäº§ç”Ÿä¸€äº›ä»¤äººæƒŠè®¶çš„ç“¶é¢ˆã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œä¸€ä¸ªæœåŠ¡å™¨æ¥æ”¶åˆ°ä¸€ä¸ªè¯·æ±‚ï¼Œéœ€è¦ä»æ…¢é€Ÿç½‘ç»œé©±åŠ¨å™¨ä¸­è¯»å–ä¸€ä¸ªæ–‡ä»¶ï¼ˆ`fs.readFile`ï¼‰å¹¶éªŒè¯å¯†ç ï¼ˆ`crypto.pbkdf2`ï¼‰ã€‚ç°åœ¨ï¼Œæƒ³è±¡ä¸€ä¸‹äº”ä¸ªè¿™æ ·çš„è¯·æ±‚åŒæ—¶åˆ°è¾¾ã€‚
- en: The first four requests will each dispatch a task to the thread pool (let's
    say the file reads get there first). All four threads are now busy.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‰å››ä¸ªè¯·æ±‚å°†å„è‡ªå‘çº¿ç¨‹æ± æ´¾é£ä¸€ä¸ªä»»åŠ¡ï¼ˆå‡è®¾æ–‡ä»¶è¯»å–å…ˆåˆ°è¾¾ï¼‰ã€‚ç°åœ¨æ‰€æœ‰å››ä¸ªçº¿ç¨‹éƒ½åœ¨å¿™ç¢Œã€‚
- en: The fifth request's `fs.readFile` call is made. Libuv tries to hand it off,
    but the pool is full. This fifth task now has to wait in a queue.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¬¬äº”ä¸ªè¯·æ±‚çš„ `fs.readFile` è°ƒç”¨è¢«å‘èµ·ã€‚Libuv å°è¯•å°†å…¶ä¼ é€’å‡ºå»ï¼Œä½†æ± å·²æ»¡ã€‚ç°åœ¨è¿™ä¸ªç¬¬äº”ä¸ªä»»åŠ¡å¿…é¡»ç­‰å¾…åœ¨é˜Ÿåˆ—ä¸­ã€‚
- en: What about the password hashing for the first four requests? They *also* have
    to wait in that same queue until one of the file reads finishes and frees up a
    thread.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆå‰å››ä¸ªè¯·æ±‚çš„å¯†ç æ•£åˆ—æ€ä¹ˆåŠï¼Ÿå®ƒä»¬ä¹Ÿå¿…é¡»ç­‰å¾…åœ¨é‚£ä¸ªç›¸åŒçš„é˜Ÿåˆ—ä¸­ï¼Œç›´åˆ°å…¶ä¸­ä¸€ä¸ªæ–‡ä»¶è¯»å–å®Œæˆå¹¶é‡Šæ”¾ä¸€ä¸ªçº¿ç¨‹ã€‚
- en: Suddenly, your slow file system is making your authentication latency skyrocket.
    Everything that uses the thread pool is connected. If you have an app that's heavy
    on file I/O, DNS, and crypto, you might seriously need to consider increasing
    the thread pool size with the `UV_THREADPOOL_SIZE` environment variable to avoid
    this kind of logjam.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: çªç„¶ä¹‹é—´ï¼Œä½ çš„æ…¢é€Ÿæ–‡ä»¶ç³»ç»Ÿä½¿ä½ çš„è®¤è¯å»¶è¿Ÿæ€¥å‰§ä¸Šå‡ã€‚æ‰€æœ‰ä½¿ç”¨çº¿ç¨‹æ± çš„åº”ç”¨ç¨‹åºéƒ½æ˜¯ç›¸è¿çš„ã€‚å¦‚æœä½ æœ‰ä¸€ä¸ªåœ¨æ–‡ä»¶ I/Oã€DNS å’ŒåŠ å¯†æ–¹é¢è´Ÿæ‹…è¾ƒé‡çš„åº”ç”¨ç¨‹åºï¼Œä½ å¯èƒ½éœ€è¦è®¤çœŸè€ƒè™‘é€šè¿‡
    `UV_THREADPOOL_SIZE` ç¯å¢ƒå˜é‡å¢åŠ çº¿ç¨‹æ± å¤§å°ï¼Œä»¥é¿å…è¿™ç§ç±»å‹çš„æ‹¥å µã€‚
- en: Profiling and Debugging the Event Loop
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åˆ†æå’Œè°ƒè¯•äº‹ä»¶å¾ªç¯
- en: So how do you know if your loop is struggling? You have to measure it. Don't
    guess, measure.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆä½ å¦‚ä½•çŸ¥é“ä½ çš„å¾ªç¯æ˜¯å¦åœ¨æŒ£æ‰ï¼Ÿä½ å¿…é¡»æµ‹é‡å®ƒã€‚ä¸è¦çŒœæµ‹ï¼Œè¦æµ‹é‡ã€‚
- en: '**Method 1: The Poor Man''s Latency Checker.** This is low-tech and feels ''hack''ish
    but surprisingly effective for a quick gut check.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–¹æ³• 1ï¼šç©·äººçš„å»¶è¿Ÿæ£€æŸ¥å™¨ã€‚** è¿™æ˜¯ä¸€ç§ä½æŠ€æœ¯æ‰‹æ®µï¼Œæ„Ÿè§‰æœ‰ç‚¹â€œé»‘å®¢â€é£æ ¼ï¼Œä½†å‡ºäººæ„æ–™åœ°æœ‰æ•ˆï¼Œå¯ä»¥å¿«é€Ÿè¿›è¡Œç›´è§‚æ£€æŸ¥ã€‚'
- en: '[PRE6]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you start seeing warnings, it means a simple `setInterval` macrotask was
    delayed, which is a screaming sign that something else was hogging the CPU.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¼€å§‹çœ‹åˆ°è­¦å‘Šï¼Œè¿™æ„å‘³ç€ä¸€ä¸ªç®€å•çš„ `setInterval` å®ä»»åŠ¡è¢«å»¶è¿Ÿäº†ï¼Œè¿™æ˜¯ä¸€ä¸ªè¡¨æ˜å…¶ä»–ä¸œè¥¿æ­£åœ¨å ç”¨ CPU çš„æ˜æ˜¾ä¿¡å·ã€‚
- en: '**Method 2: `perf_hooks.monitorEventLoopDelay`.** For a more professional approach,
    Node has a built-in, high-resolution tool for this exact purpose.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–¹æ³• 2ï¼š`perf_hooks.monitorEventLoopDelay`ã€‚** å¯¹äºæ›´ä¸“ä¸šçš„æ–¹æ³•ï¼ŒNode æä¾›äº†ä¸€ä¸ªå†…ç½®çš„é«˜åˆ†è¾¨ç‡å·¥å…·æ¥å®Œæˆè¿™ä¸ªç‰¹å®šçš„ç›®çš„ã€‚'
- en: '[PRE7]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This is far more accurate and has lower overhead than the `setInterval` hack.
    Use this one in production.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¿™æ¯” `setInterval` è¯¡è®¡æ›´å‡†ç¡®ï¼Œå¹¶ä¸”å¼€é”€æ›´ä½ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨è¿™ä¸ªã€‚
- en: '**Method 3: `async_hooks`.** This is the big gun. For super advanced debugging,
    the `async_hooks` module lets you trace the entire lifecycle of every async resource
    in your app. It''s incredibly powerful but also complex. You''d typically only
    reach for this if you were building developer tools or an APM (Application Performance
    Management) solution.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–¹æ³• 3ï¼š`async_hooks`ã€‚** è¿™æ˜¯é‡å‹æ­¦å™¨ã€‚å¯¹äºè¶…çº§é«˜çº§è°ƒè¯•ï¼Œ`async_hooks` æ¨¡å—å…è®¸ä½ è¿½è¸ªä½ åº”ç”¨ç¨‹åºä¸­æ¯ä¸ªå¼‚æ­¥èµ„æºçš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸã€‚å®ƒéå¸¸å¼ºå¤§ï¼Œä½†ä¹Ÿéå¸¸å¤æ‚ã€‚ä½ é€šå¸¸åªæœ‰åœ¨æ„å»ºå¼€å‘è€…å·¥å…·æˆ–
    APMï¼ˆåº”ç”¨ç¨‹åºæ€§èƒ½ç®¡ç†ï¼‰è§£å†³æ–¹æ¡ˆæ—¶æ‰ä¼šä½¿ç”¨å®ƒã€‚'
- en: Strategies for CPU-Bound and Parallel Work
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CPU å¯†é›†å‹å’Œå¹¶è¡Œå·¥ä½œçš„ç­–ç•¥
- en: Sometimes you just have a task that is genuinely CPU-intensive. No amount of
    clever async tricks will fix it. The solution isn't to block the loop; it's to
    move the work off the loop entirely.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶å€™ä½ æœ‰ä¸€ä¸ªçœŸæ­£å¯†é›†çš„ CPU ä»»åŠ¡ã€‚æ— è®ºå¤šä¹ˆå·§å¦™çš„å¼‚æ­¥æŠ€å·§éƒ½æ— æ³•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è§£å†³æ–¹æ¡ˆä¸æ˜¯é˜»å¡å¾ªç¯ï¼›è€Œæ˜¯å°†å·¥ä½œå®Œå…¨ä»å¾ªç¯ä¸­ç§»é™¤ã€‚
- en: Offloading to the Loop
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å°†ä»»åŠ¡å¸è½½åˆ°å¾ªç¯ä¸­
- en: For tasks that are long but can be chopped into smaller pieces, you can use
    a clever trick to avoid blocking. The idea is to do one chunk of work, then schedule
    the next chunk using `setImmediate()`. This effectively yields control back to
    the event loop between chunks, allowing it to handle I/O and stay responsive.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¯ä»¥åˆ†å‰²æˆæ›´å°éƒ¨åˆ†çš„é•¿ä»»åŠ¡ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå·§å¦™çš„æŠ€å·§æ¥é¿å…é˜»å¡ã€‚æƒ³æ³•æ˜¯å®Œæˆä¸€å—å·¥ä½œï¼Œç„¶åä½¿ç”¨ `setImmediate()` å®‰æ’ä¸‹ä¸€å—å·¥ä½œã€‚è¿™å®é™…ä¸Šåœ¨å—ä¹‹é—´å°†æ§åˆ¶æƒäº¤è¿˜ç»™äº‹ä»¶å¾ªç¯ï¼Œå…è®¸å®ƒå¤„ç†
    I/O å¹¶ä¿æŒå“åº”ã€‚
- en: '[PRE8]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This pattern is great for keeping your app from freezing, but notice that it
    doesn't actually speed up the total computation time. For that, we need real parallelism.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ¨¡å¼å¯¹äºé˜²æ­¢ä½ çš„åº”ç”¨ç¨‹åºå†»ç»“éå¸¸æœ‰æ•ˆï¼Œä½†è¯·æ³¨æ„ï¼Œå®ƒå®é™…ä¸Šå¹¶æ²¡æœ‰åŠ å¿«æ€»è®¡ç®—æ—¶é—´ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦çœŸæ­£çš„å¹¶è¡Œå¤„ç†ã€‚
- en: 'True Parallelism: `worker_threads`'
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: çœŸæ­£çš„å¹¶è¡Œå¤„ç†ï¼š`worker_threads`
- en: â„¹ï¸Note
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: We have an entire lesson dedicated to `worker_threads` - including 7 chapters.
    This section is just a quick overview. So, don't worry if you don't get all the
    details here. Just understand the big picture.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ä¸€ä¸ªä¸“é—¨çš„è¯¾ç¨‹ä¸“é—¨è®²è§£`worker_threads`â€”â€”åŒ…æ‹¬7ä¸ªç« èŠ‚ã€‚æœ¬èŠ‚åªæ˜¯ä¸€ä¸ªå¿«é€Ÿæ¦‚è¿°ã€‚æ‰€ä»¥ï¼Œå¦‚æœä½ åœ¨è¿™é‡Œæ²¡æœ‰å®Œå…¨ç†è§£æ‰€æœ‰ç»†èŠ‚ï¼Œè¯·ä¸è¦æ‹…å¿ƒã€‚åªéœ€ç†è§£å¤§å±€å³å¯ã€‚
- en: The `worker_threads` module (stable since node v12) is the modern, definitive
    answer for CPU-bound work. A worker thread is not a thread from the Libuv pool.
    It's a completely separate V8 instance, running on its own thread, with its own
    event loop and its own isolated memory.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`worker_threads`æ¨¡å—ï¼ˆè‡ªnode v12èµ·ç¨³å®šï¼‰æ˜¯é’ˆå¯¹CPUå¯†é›†å‹å·¥ä½œçš„ç°ä»£ã€æƒå¨çš„è§£å†³æ–¹æ¡ˆã€‚å·¥ä½œçº¿ç¨‹ä¸æ˜¯æ¥è‡ªLibuvæ± çš„çº¿ç¨‹ã€‚å®ƒæ˜¯ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„V8å®ä¾‹ï¼Œåœ¨è‡ªå·±çš„çº¿ç¨‹ä¸Šè¿è¡Œï¼Œæ‹¥æœ‰è‡ªå·±çš„äº‹ä»¶å¾ªç¯å’Œéš”ç¦»çš„å†…å­˜ã€‚'
- en: That isolation is the killer feature. Because memory isn't shared, you sidestep
    all the classic headaches of multi-threaded programming like race conditions and
    deadlocks. You communicate between the main thread and worker threads safely through
    a message-passing channel.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§éš”ç¦»æ˜¯æ€æ‰‹çº§ç‰¹æ€§ã€‚å› ä¸ºå†…å­˜ä¸å…±äº«ï¼Œä½ å¯ä»¥é¿å¼€æ‰€æœ‰å¤šçº¿ç¨‹ç¼–ç¨‹çš„ç»å…¸å¤´ç—›é—®é¢˜ï¼Œå¦‚ç«æ€æ¡ä»¶å’Œæ­»é”ã€‚ä½ å¯ä»¥é€šè¿‡æ¶ˆæ¯ä¼ é€’é€šé“å®‰å…¨åœ°åœ¨ä¸»çº¿ç¨‹å’Œå·¥ä½œçº¿ç¨‹ä¹‹é—´è¿›è¡Œé€šä¿¡ã€‚
- en: '[PRE9]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Here, that awful `for` loop runs on a completely separate CPU core, leaving
    our main thread's event loop free and clear to keep handling web requests or whatever
    else it needs to do.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œé‚£ä¸ªç³Ÿç³•çš„`for`å¾ªç¯åœ¨ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„CPUæ ¸å¿ƒä¸Šè¿è¡Œï¼Œè®©æˆ‘ä»¬çš„ä¸»çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯ä¿æŒç©ºé—²ï¼Œå¯ä»¥ç»§ç»­å¤„ç†Webè¯·æ±‚æˆ–å®ƒéœ€è¦åšçš„å…¶ä»–äº‹æƒ…ã€‚
- en: The `cluster` Module
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`cluster`æ¨¡å—'
- en: It's super important not to confuse `worker_threads` with the older `cluster`
    module. They solve different problems. `cluster` isn't for offloading one heavy
    task. It's a tool for scaling an entire I/O-bound application - like an HTTP server
    - across all of your machine's CPU cores.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦çš„æ˜¯ä¸è¦æ··æ·†`worker_threads`å’Œè¾ƒæ—§çš„`cluster`æ¨¡å—ã€‚å®ƒä»¬è§£å†³ä¸åŒçš„é—®é¢˜ã€‚`cluster`ä¸æ˜¯ç”¨äºå¸è½½ä¸€ä¸ªé‡ä»»åŠ¡ã€‚å®ƒæ˜¯ç”¨äºåœ¨æ•´ä¸ªæœºå™¨çš„CPUæ ¸å¿ƒä¸Šæ‰©å±•æ•´ä¸ªI/Oå¯†é›†å‹åº”ç”¨ç¨‹åºï¼ˆå¦‚HTTPæœåŠ¡å™¨ï¼‰çš„å·¥å…·ã€‚
- en: It works by forking your main Node process into multiple child processes. The
    master process grabs a port (say, 8000) and then acts as a load balancer, handing
    out incoming TCP connections to the worker processes. Each worker is a full copy
    of your Node app with its own independent event loop. This lets an 8-core machine
    run 8 instances of your server, effectively multiplying its capacity to handle
    concurrent connections.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒé€šè¿‡å°†ä¸»Nodeè¿›ç¨‹åˆ†å‰æˆå¤šä¸ªå­è¿›ç¨‹æ¥å·¥ä½œã€‚ä¸»è¿›ç¨‹è·å–ä¸€ä¸ªç«¯å£ï¼ˆæ¯”å¦‚ï¼Œ8000ï¼‰ï¼Œç„¶åå……å½“è´Ÿè½½å‡è¡¡å™¨ï¼Œå°†ä¼ å…¥çš„TCPè¿æ¥åˆ†é…ç»™å·¥ä½œè¿›ç¨‹ã€‚æ¯ä¸ªå·¥ä½œè¿›ç¨‹éƒ½æ˜¯ä½ Nodeåº”ç”¨çš„å®Œæ•´å‰¯æœ¬ï¼Œæ‹¥æœ‰è‡ªå·±çš„ç‹¬ç«‹äº‹ä»¶å¾ªç¯ã€‚è¿™ä½¿å¾—8æ ¸æœºå™¨å¯ä»¥è¿è¡Œ8ä¸ªä½ çš„æœåŠ¡å™¨å®ä¾‹ï¼Œæœ‰æ•ˆåœ°å¢åŠ äº†å¤„ç†å¹¶å‘è¿æ¥çš„èƒ½åŠ›ã€‚
- en: â„¹ï¸Note
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: â„¹ï¸æ³¨æ„
- en: 'Think of their primary scaling strategies this way: `worker_threads` are for
    offloading a specific, long-running CPU-bound task from a single event loop to
    prevent that loop from blocking. The `cluster` module, on the other hand, is for
    scaling your entire application across multiple CPU cores by running multiple,
    independent process instances of it. This is highly effective for your servers,
    as it allows you to handle a much larger number of concurrent connections by distributing
    them across multiple event loops. These tools are not mutually exclusive and can
    be powerfully combined.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹å®ƒä»¬çš„åˆçº§æ‰©å±•ç­–ç•¥æ˜¯è¿™æ ·çš„ï¼š`worker_threads`ç”¨äºå°†ç‰¹å®šçš„ã€é•¿æ—¶é—´è¿è¡Œçš„CPUå¯†é›†å‹ä»»åŠ¡ä»å•ä¸ªäº‹ä»¶å¾ªç¯å¸è½½ï¼Œä»¥é˜²æ­¢è¯¥å¾ªç¯é˜»å¡ã€‚å¦ä¸€æ–¹é¢ï¼Œ`cluster`æ¨¡å—æ˜¯ç”¨äºé€šè¿‡è¿è¡Œå¤šä¸ªç‹¬ç«‹è¿›ç¨‹å®ä¾‹æ¥æ‰©å±•æ•´ä¸ªåº”ç”¨ç¨‹åºï¼Œä½¿å…¶è·¨è¶Šå¤šä¸ªCPUæ ¸å¿ƒã€‚è¿™å¯¹äºä½ çš„æœåŠ¡å™¨æ¥è¯´éå¸¸æœ‰æ•ˆï¼Œå› ä¸ºå®ƒå…è®¸ä½ é€šè¿‡å°†å®ƒä»¬åˆ†é…åˆ°å¤šä¸ªäº‹ä»¶å¾ªç¯æ¥å¤„ç†æ›´å¤šçš„å¹¶å‘è¿æ¥ã€‚è¿™äº›å·¥å…·ä¸æ˜¯äº’æ–¥çš„ï¼Œå¯ä»¥å¼ºå¤§åœ°ç»“åˆä½¿ç”¨ã€‚
- en: Stuff that people often get wrong
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: äººä»¬å¸¸çŠ¯çš„é”™è¯¯
- en: Let's wrap up with a couple of classic brain-teasers that really test whether
    you've internalized how the loop works.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»¥å‡ ä¸ªç»å…¸çš„è„‘ç­‹æ€¥è½¬å¼¯æ¥ç»“æŸï¼Œè¿™äº›è„‘ç­‹æ€¥è½¬å¼¯çœŸæ­£è€ƒéªŒä½ æ˜¯å¦å·²ç»å†…åŒ–äº†å¾ªç¯çš„å·¥ä½œæ–¹å¼ã€‚
- en: 7.1 `setTimeout(..., 0)` vs. `setImmediate()`
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 `setTimeout(..., 0)` ä¸ `setImmediate()`
- en: 'This is a famous interview question: which of these runs first? The answer,
    maddeningly, is **it depends**.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªè‘—åçš„é¢è¯•é—®é¢˜ï¼šè¿™äº›å“ªä¸ªå…ˆè¿è¡Œï¼Ÿç­”æ¡ˆæ˜¯ä»¤äººæ²®ä¸§çš„ï¼š**è¿™å–å†³äº**ã€‚
- en: '**Case 1: Called from the Main Module**'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¡ˆä¾‹1ï¼šä»ä¸»æ¨¡å—è°ƒç”¨**'
- en: '[PRE10]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: When you run this directly in a script, the execution order is **non-deterministic**.
    You might get Timeout then Immediate, or the other way around. The reason is subtle.
    When the script is processed, the timer and immediate are scheduled. The event
    loop then starts up. The `setTimeout(..., 0)` doesn't really have a 0ms delay;
    it's constrained by a system minimum, often around 1ms. When the loop enters the
    timers phase, it checks if that 1ms has elapsed. If the initial startup of the
    loop took more than 1ms (which is totally possible on a busy system), the timer
    will fire first. If startup was super fast, the loop will fly past the (still
    empty) timers phase, hit the poll phase, and then the check phase, running the
    `setImmediate` first. It's a race condition.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ ç›´æ¥åœ¨è„šæœ¬ä¸­è¿è¡Œæ—¶ï¼Œæ‰§è¡Œé¡ºåºæ˜¯**éç¡®å®šæ€§çš„**ã€‚ä½ å¯èƒ½ä¼šå…ˆå¾—åˆ°Timeoutç„¶åæ˜¯Immediateï¼Œæˆ–è€…åè¿‡æ¥ã€‚åŸå› æ˜¯å¾®å¦™çš„ã€‚å½“è„šæœ¬è¢«å¤„ç†æ—¶ï¼Œè®¡æ—¶å™¨å’ŒImmediateè¢«å®‰æ’ã€‚ç„¶åäº‹ä»¶å¾ªç¯å¯åŠ¨ã€‚`setTimeout(...,
    0)`å®é™…ä¸Šå¹¶æ²¡æœ‰0msçš„å»¶è¿Ÿï¼›å®ƒå—ç³»ç»Ÿæœ€å°å€¼çš„é™åˆ¶ï¼Œé€šå¸¸åœ¨1mså·¦å³ã€‚å½“å¾ªç¯è¿›å…¥è®¡æ—¶å™¨é˜¶æ®µæ—¶ï¼Œå®ƒä¼šæ£€æŸ¥1msæ˜¯å¦å·²ç»è¿‡å»ã€‚å¦‚æœå¾ªç¯çš„åˆå§‹å¯åŠ¨æ—¶é—´è¶…è¿‡1msï¼ˆåœ¨ç¹å¿™çš„ç³»ç»Ÿä¸Šè¿™æ˜¯å®Œå…¨å¯èƒ½çš„ï¼‰ï¼Œè®¡æ—¶å™¨ä¼šé¦–å…ˆè§¦å‘ã€‚å¦‚æœå¯åŠ¨éå¸¸å¿«ï¼Œå¾ªç¯ä¼šé£è¿‡ï¼ˆä»ç„¶ä¸ºç©ºçš„ï¼‰è®¡æ—¶å™¨é˜¶æ®µï¼Œè¿›å…¥è½®è¯¢é˜¶æ®µï¼Œç„¶åæ˜¯æ£€æŸ¥é˜¶æ®µï¼Œé¦–å…ˆè¿è¡Œ`setImmediate`ã€‚è¿™æ˜¯ä¸€ä¸ªç«äº‰æ¡ä»¶ã€‚
- en: '**Case 2: Called from within an I/O Callback**'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¡ˆä¾‹2ï¼šåœ¨I/Oå›è°ƒä¸­è°ƒç”¨**'
- en: '[PRE11]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, the order is **always, 100% deterministic. `setImmediate` will execute
    first.** Why the certainty? The I/O callback itself runs in the poll phase. When
    it schedules the timer and the immediate, the loop is *currently in the poll phase*.
    What's the very next phase? The check phase. So the `setImmediate` callback is
    guaranteed to run. The timer callback has to wait until the loop completes its
    full cycle and comes back around to the timers phase on the *next tick*.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œé¡ºåºæ˜¯**å§‹ç»ˆï¼Œ100%ç¡®å®šæ€§çš„**ã€‚`setImmediate`å°†é¦–å…ˆæ‰§è¡Œã€‚**ä¸ºä»€ä¹ˆè¿™ä¹ˆç¡®å®šï¼Ÿ**I/Oå›è°ƒæœ¬èº«åœ¨è½®è¯¢é˜¶æ®µè¿è¡Œã€‚å½“å®ƒå®‰æ’è®¡æ—¶å™¨å’ŒImmediateæ—¶ï¼Œå¾ªç¯æ­£å¤„äºè½®è¯¢é˜¶æ®µã€‚ä¸‹ä¸€ä¸ªé˜¶æ®µæ˜¯ä»€ä¹ˆï¼Ÿæ£€æŸ¥é˜¶æ®µã€‚æ‰€ä»¥`setImmediate`å›è°ƒæœ‰ä¿è¯ä¼šè¿è¡Œã€‚è®¡æ—¶å™¨å›è°ƒå¿…é¡»ç­‰å¾…å¾ªç¯å®Œæˆæ•´ä¸ªå‘¨æœŸï¼Œå¹¶åœ¨*ä¸‹ä¸€ä¸ªtick*å›åˆ°è®¡æ—¶å™¨é˜¶æ®µã€‚
- en: Garbage Collection and its Impact on the Loop
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åƒåœ¾å›æ”¶åŠå…¶å¯¹å¾ªç¯çš„å½±å“
- en: 'There''s one last, invisible source of blocking we need to talk about: V8''s
    garbage collector (GC). To clean up memory from objects you''re no longer using,
    the GC has to periodically pause the execution of your JavaScript. This is often
    called a "stop-the-world" event, and it''s as dramatic as it sounds.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦è®¨è®ºçš„ä¸€ä¸ªæœ€åã€çœ‹ä¸è§çš„é˜»å¡æ¥æºæ˜¯V8çš„åƒåœ¾å›æ”¶å™¨ï¼ˆGCï¼‰ã€‚ä¸ºäº†æ¸…ç†ä¸å†ä½¿ç”¨çš„å¯¹è±¡å ç”¨çš„å†…å­˜ï¼ŒGCå¿…é¡»å®šæœŸæš‚åœä½ çš„JavaScriptæ‰§è¡Œã€‚è¿™é€šå¸¸è¢«ç§°ä¸ºâ€œåœæ­¢ä¸–ç•Œâ€äº‹ä»¶ï¼Œå®ƒå¬èµ·æ¥å°±åƒå®ƒå¬èµ·æ¥é‚£æ ·æˆå‰§æ€§ã€‚
- en: While V8's GC is a marvel of engineering, a major GC cycle in an app with high
    memory pressure can still freeze your event loop for tens or even hundreds of
    milliseconds. During that pause, nothing happens. No JavaScript runs. Your server
    is just as unresponsive as if it were blocked by synchronous code. This is why
    good memory management - like using streams instead of buffering huge files -
    is so critical in Node. It keeps those GC pauses short and sweet.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶V8çš„GCæ˜¯å·¥ç¨‹å¥‡è¿¹ï¼Œä½†åœ¨å†…å­˜å‹åŠ›å¤§çš„åº”ç”¨ç¨‹åºä¸­ï¼Œä¸€ä¸ªä¸»è¦çš„GCå‘¨æœŸä»ç„¶å¯ä»¥ä½¿ä½ çš„äº‹ä»¶å¾ªç¯å†»ç»“æ•°åæ¯«ç§’ç”šè‡³æ•°ç™¾æ¯«ç§’ã€‚åœ¨è¿™æ®µæš‚åœæœŸé—´ï¼Œä»€ä¹ˆéƒ½æ²¡æœ‰å‘ç”Ÿã€‚æ²¡æœ‰JavaScriptè¿è¡Œã€‚ä½ çš„æœåŠ¡å™¨å°±åƒè¢«åŒæ­¥ä»£ç é˜»å¡ä¸€æ ·æ— å“åº”ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨Nodeä¸­è‰¯å¥½çš„å†…å­˜ç®¡ç†â€”â€”æ¯”å¦‚ä½¿ç”¨æµè€Œä¸æ˜¯ç¼“å†²å¤§æ–‡ä»¶â€”â€”æ˜¯å¦‚æ­¤å…³é”®ã€‚å®ƒä½¿é‚£äº›GCæš‚åœå˜å¾—çŸ­æš‚è€Œç”œèœœã€‚
- en: Final words
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœ€åçš„è¯
- en: Whew. We've gone from the simple call stack to the dance between V8 and Libuv,
    through the loop's six phases, and into the VIP status of microtasks.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: å‘¼å‘¼ã€‚æˆ‘ä»¬å·²ç»ä»ç®€å•çš„è°ƒç”¨æ ˆè¿‡æ¸¡åˆ°äº†V8å’ŒLibuvä¹‹é—´çš„èˆè¹ˆï¼Œç»å†äº†å¾ªç¯çš„å…­ä¸ªé˜¶æ®µï¼Œè¿›å…¥äº†å¾®ä»»åŠ¡çš„VIPåœ°ä½ã€‚
- en: Mastering the event loop isn't about memorizing the names of the six phases
    for a trivia night. It's about building a solid, reliable mental model that lets
    you reason about how your code will actually behave. This model is a superpower.
    It lets you write screamingly fast, non-blocking apps. It helps you diagnose the
    trickiest performance bugs. And it gives you a true appreciation for what makes
    Node.js such a powerful and unique environment.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: æŒæ¡äº‹ä»¶å¾ªç¯ä¸ä»…ä»…æ˜¯è®°ä½å…­ä¸ªé˜¶æ®µçš„åç§°æ¥å‚åŠ çŸ¥è¯†ç«èµ›ã€‚è¿™æ˜¯å…³äºæ„å»ºä¸€ä¸ªç¨³å›ºã€å¯é çš„æ€ç»´æ¨¡å‹ï¼Œè®©ä½ èƒ½å¤Ÿæ¨ç†ä½ çš„ä»£ç å°†å¦‚ä½•å®é™…è¿è¡Œã€‚è¿™ä¸ªæ¨¡å‹æ˜¯ä¸€ç§è¶…çº§èƒ½åŠ›ã€‚å®ƒè®©ä½ èƒ½å¤Ÿå†™å‡ºæå¿«ã€éé˜»å¡çš„åº”ç”¨ç¨‹åºã€‚å®ƒå¸®åŠ©ä½ è¯Šæ–­æœ€æ£˜æ‰‹çš„æ€§èƒ½é—®é¢˜ã€‚å¹¶ä¸”å®ƒè®©ä½ çœŸæ­£æ¬£èµåˆ°æ˜¯ä»€ä¹ˆè®©Node.jsæˆä¸ºä¸€ä¸ªå¦‚æ­¤å¼ºå¤§å’Œç‹¬ç‰¹çš„ç¯å¢ƒã€‚
- en: With this model in your head, you're not just *using* Node.js anymore. You're
    *thinking* in it. Now go write some code, `console.log` everything, and see if
    you can predict the outcome. Thatâ€™s how this really sinks in. Happy coding.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è„‘æµ·ä¸­æœ‰äº†è¿™ä¸ªæ¨¡å‹ï¼Œä½ ä¸å†ä»…ä»…æ˜¯*ä½¿ç”¨* Node.jsã€‚ä½ å¼€å§‹*æ€è€ƒ*å®ƒã€‚ç°åœ¨å»å†™ä¸€äº›ä»£ç ï¼Œ`console.log`ä¸€åˆ‡ï¼Œçœ‹çœ‹ä½ æ˜¯å¦èƒ½é¢„æµ‹ç»“æœã€‚è¿™å°±æ˜¯çœŸæ­£ç†è§£å®ƒçš„æ–¹æ³•ã€‚å¿«ä¹ç¼–ç ã€‚
